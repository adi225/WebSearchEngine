a video or an image sequence represented as a third order tensor of column x row x time for multilinear subspace learning multilinear subspace learning msl aims to learn a specific small part of a large space of multidimensional objects having a particular desired property it is a dimensionality reduction approach for finding a low dimensional representation with certain preferred characteristics of high dimensional tensor data through direct mapping without going through vectorization 1 2 the term tensor in msl refers to multidimensional arrays examples of tensor data include images 2d 3d video sequences 3d 4d and hyperspectral cubes 3d 4d the mapping from a high dimensional tensor space to a low dimensional tensor space or vector space is named as multilinear projection 1 3 msl methods are higher order generalizations of linear subspace learning methods such as principal component analysis pca and linear discriminant analysis lda in the literature msl is also referred to as tensor subspace learning or tensor subspace analysis 2 research on msl has progressed from heuristic exploration in 2000s decade to systematic investigation in 2010s contents 1 background 2 multilinear projection 2 1 tensor to tensor projection ttp 2 2 tensor to vector projection tvp 3 typical approach in msl 4 pros and cons 5 algorithms 6 pedagogical resources 7 code 8 tensor data sets 9 see also 10 references edit background with the advances in data acquisition and storage technology big data or massive data sets are being generated on a daily basis in a wide range of emerging applications most of these big data are multidimensional moreover they are usually very high dimensional with a large amount of redundancy and only occupying a part of the input space therefore dimensionality reduction is frequently employed to map high dimensional data to a low dimensional space while retaining as much information as possible linear subspace learning algorithms are traditional dimensionality reduction techniques that represent input data as vectors and solve for an optimal linear mapping to a lower dimensional space unfortunately they often become inadequate when dealing with massive multidimensional data they result in very high dimensional vectors lead to the estimation of a large number of parameters and also break the natural structure and correlation in the original data 1 2 4 5 msl is closely related to tensor decompositions 6 they both employ multilinear algebra tools the difference is that tensor decomposition focuses on factor analysis while msl focuses on dimensionality reduction msl belongs to tensor based computation 7 and it can be seen as a tensor level computational thinking of machine learning edit multilinear projection multilinear projection to transform a tensor to a low dimensional representation for multilinear subspace learning elementary multilinear projection emp tensor to vector projection tvp and tensor to tensor projection ttp a multilinear subspace is defined through a multilinear projection that maps the input tensor data from one space to another lower dimensional space the original idea is due to hitchcock in 1927 8 edit tensor to tensor projection ttp a ttp is a direct projection of a high dimensional tensor to a low dimensional tensor of the same order using n projection matrices for an n th order tensor it can be performed in n steps with each step performing a tensor matrix multiplication product the n steps are exchangeable 9 this projection is an extension of the higher order singular value decomposition 9 hosvd to subspace learning 4 hence its origin is traced back to the tucker decomposition 10 in 1960s edit tensor to vector projection tvp a tvp is a direct projection of a high dimensional tensor to a low dimensional vector which is also referred to as the rank one projections as tvp projects a tensor to a vector it can be viewed as multiple projections from a tensor to a scalar thus the tvp of a tensor to a p dimensional vector consists of p projections from the tensor to a scalar the projection from a tensor to a scalar is an elementary multilinear projection emp in emp a tensor is projected to a point through n unit projection vectors it is the projection of a tensor on a single line resulting a scalar with one projection vector in each mode thus the tvp of a tensor object to a vector in a p dimensional vector space consists of p emps this projection is an extension of the canonical decomposition 11 also known as the parallel factors parafac decomposition 12 edit typical approach in msl there are n sets of parameters to be solved one in each mode the solution to one set often depends on the other sets except when n 1 the linear case therefore the suboptimal iterative procedure in 13 is followed initialization of the projections in each mode for each mode fixing the projection in all the other mode and solve for the projection in the current mode do the mode wise optimization for a few iterations or until convergence this is originated from the alternating least square method for multi way data analysis 14 edit pros and cons this figure compares the number of parameters to be estimated for the same amount of dimension reduction by vector to vector projection vvp i e linear projection tensor to vector projection tvp and tensor to tensor projection ttp multilinear projections require much fewer parameters and the representations obtained are more compact this figure is produced based on table 3 of the survey paper 1 the advantages of msl are 1 2 4 5 it operates on natural tensorial representation of multidimensional data so the structure and correlation in the original data are preserved the number of parameters to be estimated is much smaller than in the linear case it has fewer problems in the small sample size scenario the disadvantages of msl are 1 2 4 5 most msl algorithm are iterative they may be affected by initialization method and have convergence problem the solution obtained is local optimum edit algorithms multilinear extension of pca ttp based multilinear principal component analysis mpca 4 tvp based uncorrelated multilinear principal component analysis umpca 15 multilinear extension of lda ttp based discriminant analysis with tensor representation dater 5 ttp based general tensor discriminant analysis gtda 16 tvp based uncorrelated multilinear discriminant analysis umlda 17 edit pedagogical resources survey a survey of multilinear subspace learning for tensor data open access version lecture video lecture on umpca at the 25th international conference on machine learning icml 2008 edit code matlab tensor toolbox by sandia national laboratories the mpca algorithm written in matlab mpca lda included the umpca algorithm written in matlab data included the umlda algorithm written in matlab data included edit tensor data sets 3d gait data third order tensors 128x88x20 21 2m 64x44x20 9 9m 32x22x10 3 2m edit see also cp decomposition edit references a b c d e f lu haiping plataniotis k n venetsanopoulos a n 2011 a survey of multilinear subspace learning for tensor data pattern recognition 44 7 1540 1551 doi 10 1016 j patcog 2011 01 004 http www dsp utoronto ca haiping publication surveymsl pr2011 pdf a b c d e x he d cai p niyogi tensor subspace analysis in advances in neural information processing systemsc 18 nips 2005 vasilescu m a o terzopoulos d 2007 multilinear projection for appearance based recognition in the tensor framework ieee 11th international conference on computer visioncc pp 160 1 8 doi 10 1109 iccv 2007 4409067 a b c d e h lu k n plataniotis and a n venetsanopoulos mpca multilinear principal component analysis of tensor objects ieee trans neural netw vol 19 no 1 pp 18 39 january 2008 a b c d s yan d xu q yang l zhang x tang and h j zhang discriminant analysis with tensor representation in proc ieee conference on computer vision and pattern recognition vol i june 2005 pp 526 532 t g kolda b w bader tensor decompositions and applications siam review 51 3 2009 455 500 future directions in tensor based computation and modeling may 2009 http www cs cornell edu cv tenwork finalreport pdf f l hitchcock 1927 the expression of a tensor or a polyadic as a sum of products journal of mathematics and physics 6 164 189 a b l d lathauwer b d moor j vandewalle a multilinear singular value decomposition siam journal of matrix analysis and applications vol 21 no 4 pp 1253 1278 2000 ledyard r tucker september 1966 some mathematical notes on three mode factor analysis psychometrika 31 3 279 311 doi 10 1007 bf02289464 j d carroll amp j chang 1970 analysis of individual differences in multidimensional scaling via an n way generalization of eckart young decomposition psychometrika 35 283 319 doi 10 1007 bf02310791 r a harshman foundations of the parafac procedure models and conditions for an explanatory multi modal factor analysis ucla working papers in phonetics 16 pp 1 84 1970 l d lathauwer b d moor j vandewalle on the best rank 1 and rank r1 r2 rn approximation of higher order tensors siam journal of matrix analysis and applications 21 4 2000 1324 1342 p m kroonenberg and j de leeuw principal component analysis of three mode data by means of alternating least squares algorithms psychometrika 45 1980 pp 69 97 h lu k n plataniotis and a n venetsanopoulos uncorrelated multilinear principal component analysis for unsupervised multilinear subspace learning ieee trans neural netw vol 20 no 11 pp 1820 1836 november 2009 d tao x li x wu and s j maybank general tensor discriminant analysis and gabor features for gait recognition ieee trans pattern anal mach intell vol 29 no 10 pp 1700 1715 october 2007 h lu k n plataniotis and a n venetsanopoulos uncorrelated multilinear discriminant analysis with regularization and aggregation for tensor object recognition ieee trans neural netw vol 20 no 1 pp 103 123 january 2009 