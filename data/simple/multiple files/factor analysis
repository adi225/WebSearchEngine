factor analysis is a statistical method used to describe variability among observed correlated variables in terms of a potentially lower number of unobserved variables called factors in other words it is possible for example that variations in three or four observed variables mainly reflect the variations in fewer unobserved variables factor analysis searches for such joint variations in response to unobserved latent variables the observed variables are modeled as linear combinations of the potential factors plus error terms the information gained about the interdependencies between observed variables can be used later to reduce the set of variables in a dataset computationally this technique is equivalent to low rank approximation of the matrix of observed variables factor analysis originated in psychometrics and is used in behavioral sciences social sciences marketing product management operations research and other applied sciences that deal with large quantities of data factor analysis is related to principal component analysis pca but the two are not identical latent variable models including factor analysis use regression modelling techniques to test hypotheses producing error terms while pca is a descriptive statistical technique 1 there has been significant controversy in the field over the equivalence or otherwise of the two techniques see exploratory factor analysis versus principal components analysis citation needed contents 1 statistical model 1 1 definition 1 2 example 1 3 mathematical model of the same example 2 practical implementation 2 1 type of factor analysis 2 2 types of factoring 2 3 terminology 2 4 criteria for determining the number of factors 2 5 rotation methods 3 factor analysis in psychometrics 3 1 history 3 2 applications in psychology 3 3 advantages 3 4 disadvantages 4 exploratory factor analysis versus principal components analysis 4 1 arguments contrasting pca and efa 4 2 variance versus covariance 4 3 differences in procedure and results 5 factor analysis in marketing 5 1 information collection 5 2 analysis 5 3 advantages 5 4 disadvantages 6 factor analysis in physical sciences 7 factor analysis in microarray analysis 8 implementation 9 see also 10 references 11 further reading 12 external links edit statistical model edit definition suppose we have a set of observable random variables with means suppose for some unknown constants and unobserved random variables where and where we have here the are independently distributed error terms with zero mean and finite variance which may not be the same for all let so that we have in matrix terms we have if we have observations then we will have the dimensions and each column of and denote values for one particular observation and matrix does not vary across observations also we will impose the following assumptions on and are independent to make sure that the factors are uncorrelated any solution of the above set of equations following the constraints for is defined as the factors and as the loading matrix suppose then note that from the conditions just imposed on we have or or note that for any orthogonal matrix if we set and the criteria for being factors and factor loadings still hold hence a set of factors and factor loadings is identical only up to orthogonal transformation edit example the following example is for expository purposes and should not be taken as being realistic suppose a psychologist proposes a theory that there are two kinds of intelligence verbal intelligence and mathematical intelligence neither of which is directly observed evidence for the theory is sought in the examination scores from each of 10 different academic fields of 1000 students if each student is chosen randomly from a large population then each student s 10 scores are random variables the psychologist s theory may say that for each of the 10 academic fields the score averaged over the group of all students who share some common pair of values for verbal and mathematical intelligences is some constant times their level of verbal intelligence plus another constant times their level of mathematical intelligence i e it is a linear combination of those two factors the numbers for a particular subject by which the two kinds of intelligence are multiplied to obtain the expected score are posited by the theory to be the same for all intelligence level pairs and are called factor loadings for this subject for example the theory may hold that the average student s aptitude in the field of taxonomy is 10 the student s verbal intelligence 6 the student s mathematical intelligence the numbers 10 and 6 are the factor loadings associated with taxonomy other academic subjects may have different factor loadings two students having identical degrees of verbal intelligence and identical degrees of mathematical intelligence may have different aptitudes in taxonomy because individual aptitudes differ from average aptitudes that difference is called the error a statistical term that means the amount by which an individual differs from what is average for his or her levels of intelligence see errors and residuals in statistics the observable data that go into factor analysis would be 10 scores of each of the 1000 students a total of 10 000 numbers the factor loadings and levels of the two kinds of intelligence of each student must be inferred from the data edit mathematical model of the same example in the example above for i 1 1 000 the i th student s scores are where x k i is the i th student s score for the k th subject is the mean of the students scores for the k th subject assumed to be zero for simplicity in the example as described above which would amount to a simple shift of the scale used v i is the i th student s verbal intelligence m i is the i th student s mathematical intelligence are the factor loadings for the k th subject for j 1 2 k i is the difference between the i th student s score in the k th subject and the average score in the k th subject of all students whose levels of verbal and mathematical intelligence are the same as those of the i th student in matrix notation we have where n is 1000 students x is a 10 1 000 matrix of observable random variables is a 10 1 column vector of unobservable constants in this case constants are quantities not differing from one individual student to the next and random variables are those assigned to individual students the randomness arises from the random way in which the students are chosen l is a 10 2 matrix of factor loadings unobservable constants ten academic topics each with two intelligence parameters that determine success in that topic f is a 2 1 000 matrix of unobservable random variables two intelligence parameters for each of 1000 students is a 10 1 000 matrix of unobservable random variables observe that by doubling the scale on which verbal intelligence the first component in each column of f is measured and simultaneously halving the factor loadings for verbal intelligence makes no difference to the model thus no generality is lost by assuming that the standard deviation of verbal intelligence is 1 likewise for mathematical intelligence moreover for similar reasons no generality is lost by assuming the two factors are uncorrelated with each other the errors are taken to be independent of each other the variances of the errors associated with the 10 different subjects are not assumed to be equal note that since any rotation of a solution is also a solution this makes interpreting the factors difficult see disadvantages below in this particular example if we do not know beforehand that the two types of intelligence are uncorrelated then we cannot interpret the two factors as the two different types of intelligence even if they are uncorrelated we cannot tell which factor corresponds to verbal intelligence and which corresponds to mathematical intelligence without an outside argument the values of the loadings l the averages and the variances of the errors must be estimated given the observed data x and f the assumption about the levels of the factors is fixed for a given f edit practical implementation this section needs additional citations for verification please help improve this article by adding citations to reliable sources unsourced material may be challenged and removed april 2012 edit type of factor analysis exploratory factor analysis efa is used to uncover the underlying structure of a relatively large set of variables the researcher s a priori assumption is that any indicator may be associated with any factor this is the most common form of factor analysis there is no prior theory and one uses factor loadings to intuit the factor structure of the data confirmatory factor analysis cfa seeks to determine if the number of factors and the loadings of measured indicator variables on them conform to what is expected on the basis of pre established theory indicator variables are selected on the basis of prior theory and factor analysis is used to see if they load as predicted on the expected number of factors the researcher s a priori assumption is that each factor the number and labels of which may be specified a priori is associated with a specified subset of indicator variables a minimum requirement of confirmatory factor analysis is that one hypothesizes beforehand the number of factors in the model but usually also the researcher will posit expectations about which variables will load on which factors the researcher seeks to determine for instance if measures created to represent a latent variable really belong together edit types of factoring principal component analysis pca pca seeks a linear combination of variables such that the maximum variance is extracted from the variables it then removes this variance and seeks a second linear combination which explains the maximum proportion of the remaining variance and so on this is called the principal axis method and results in orthogonal uncorrelated factors canonical factor analysis also called rao s canonical factoring is a different method of computing the same model as pca which uses the principal axis method canonical factor analysis seeks factors which have the highest canonical correlation with the observed variables canonical factor analysis is unaffected by arbitrary rescaling of the data common factor analysis also called principal factor analysis pfa or principal axis factoring paf seeks the least number of factors which can account for the common variance correlation of a set of variables image factoring based on the correlation matrix of predicted variables rather than actual variables where each variable is predicted from the others using multiple regression alpha factoring based on maximizing the reliability of factors assuming variables are randomly sampled from a universe of variables all other methods assume cases to be sampled and variables fixed factor regression model a combinatorial model of factor model and regression model or alternatively it can be viewed as the hybrid factor model 2 whose factors are partially known edit terminology factor loadings the factor loadings also called component loadings in pca are the correlation coefficients between the variables rows and factors columns analogous to pearson s r the squared factor loading is the percent of variance in that indicator variable explained by the factor to get the percent of variance in all the variables accounted for by each factor add the sum of the squared factor loadings for that factor column and divide by the number of variables note the number of variables equals the sum of their variances as the variance of a standardized variable is 1 this is the same as dividing the factor s eigenvalue by the number of variables interpreting factor loadings by one rule of thumb in confirmatory factor analysis loadings should be 7 or higher to confirm that independent variables identified a priori are represented by a particular factor on the rationale that the 7 level corresponds to about half of the variance in the indicator being explained by the factor however the 7 standard is a high one and real life data may well not meet this criterion which is why some researchers particularly for exploratory purposes will use a lower level such as 4 for the central factor and 25 for other factors call loadings above 6 high and those below 4 low in any event factor loadings must be interpreted in the light of theory not by arbitrary cutoff levels in oblique rotation one gets both a pattern matrix and a structure matrix the structure matrix is simply the factor loading matrix as in orthogonal rotation representing the variance in a measured variable explained by a factor on both a unique and common contributions basis the pattern matrix in contrast contains coefficients which just represent unique contributions the more factors the lower the pattern coefficients as a rule since there will be more common contributions to variance explained for oblique rotation the researcher looks at both the structure and pattern coefficients when attributing a label to a factor communality the sum of the squared factor loadings for all factors for a given variable row is the variance in that variable accounted for by all the factors and this is called the communality the communality measures the percent of variance in a given variable explained by all the factors jointly and may be interpreted as the reliability of the indicator spurious solutions if the communality exceeds 1 0 there is a spurious solution which may reflect too small a sample or the researcher has too many or too few factors uniqueness of a variable that is uniqueness is the variability of a variable minus its communality eigenvalues characteristic roots the eigenvalue for a given factor measures the variance in all the variables which is accounted for by that factor the ratio of eigenvalues is the ratio of explanatory importance of the factors with respect to the variables if a factor has a low eigenvalue then it is contributing little to the explanation of variances in the variables and may be ignored as redundant with more important factors eigenvalues measure the amount of variation in the total sample accounted for by each factor extraction sums of squared loadings initial eigenvalues and eigenvalues after extraction listed by spss as extraction sums of squared loadings are the same for pca extraction but for other extraction methods eigenvalues after extraction will be lower than their initial counterparts spss also prints rotation sums of squared loadings and even for pca these eigenvalues will differ from initial and extraction eigenvalues though their total will be the same factor scores also called component scores in pca are the scores of each case row on each factor column to compute the factor score for a given case for a given factor one takes the case s standardized score on each variable multiplies by the corresponding factor loading of the variable for the given factor and sums these products computing factor scores allows one to look for factor outliers also factor scores may be used as variables in subsequent modeling edit criteria for determining the number of factors using one or more of the methods below the researcher determines an appropriate range of solutions to investigate methods may not agree for instance the kaiser criterion may suggest five factors and the scree test may suggest two so the researcher may request 3 4 and 5 factor solutions discuss each in terms of their relation to external data and theory comprehensibility a purely subjective criterion would be to retain those factors whose meaning is comprehensible to the researcher this is not recommended citation needed kaiser criterion the kaiser rule is to drop all components with eigenvalues under 1 0 this being the eigenvalue equal to the information accounted for by an average single item the kaiser criterion is the default in spss and most statistical software but is not recommended when used as the sole cut off criterion for estimating the number of factors as it tends to overextract factors 3 variance explained criteria some researchers simply use the rule of keeping enough factors to account for 90 sometimes 80 of the variation where the researcher s goal emphasizes parsimony explaining variance with as few factors as possible the criterion could be as low as 50 scree plot the cattell scree test plots the components as the x axis and the corresponding eigenvalues as the y axis as one moves to the right toward later components the eigenvalues drop when the drop ceases and the curve makes an elbow toward less steep decline cattell s scree test says to drop all further components after the one starting the elbow this rule is sometimes criticised for being amenable to researcher controlled fudging that is as picking the elbow can be subjective because the curve has multiple elbows or is a smooth curve the researcher may be tempted to set the cut off at the number of factors desired by his or her research agenda horn s parallel analysis pa a monte carlo based simulation method that compares the observed eigenvalues with those obtained from uncorrelated normal variables a factor or component is retained if the associated eigenvalue is bigger than the 95th of the distribution of eigenvalues derived from the random data pa is one of the most recommendable rules for determining the number of components to retain citation needed but only few programs include this option 4 before dropping a factor below one s cut off however the researcher should check its correlation with the dependent variable a very small factor can have a large correlation with the dependent variable in which case it should not be dropped edit rotation methods the unrotated output maximises the variance accounted for by the first and subsequent factors and forcing the factors to be orthogonal this data compression comes at the cost of having most items load on the early factors and usually of having many items load substantially on more than one factor rotation serves to make the output more understandable by seeking so called simple structure a pattern of loadings where items load most strongly on one factor and much more weakly on the other factors rotations can be orthogonal or oblique allowing the factors to correlate varimax rotation is an orthogonal rotation of the factor axes to maximize the variance of the squared loadings of a factor column on all the variables rows in a factor matrix which has the effect of differentiating the original variables by extracted factor each factor will tend to have either large or small loadings of any particular variable a varimax solution yields results which make it as easy as possible to identify each variable with a single factor this is the most common rotation option however the orthogonality i e independence of factors is often an unrealistic assumption oblique rotations are inclusive of orthogonal rotation and for that reason oblique rotations are a preferred method 5 quartimax rotation is an orthogonal alternative which minimizes the number of factors needed to explain each variable this type of rotation often generates a general factor on which most variables are loaded to a high or medium degree such a factor structure is usually not helpful to the research purpose equimax rotation is a compromise between varimax and quartimax criteria direct oblimin rotation is the standard method when one wishes a non orthogonal oblique solution that is one in which the factors are allowed to be correlated this will result in higher eigenvalues but diminished interpretability of the factors see below clarification needed promax rotation is an alternative non orthogonal oblique rotation method which is computationally faster than the direct oblimin method and therefore is sometimes used for very large datasets edit factor analysis in psychometrics see also g factor edit history charles spearman pioneered the use of factor analysis in the field of psychology and is sometimes credited with the invention of factor analysis he discovered that school children s scores on a wide variety of seemingly unrelated subjects were positively correlated which led him to postulate that a general mental ability or g underlies and shapes human cognitive performance his postulate now enjoys broad support in the field of intelligence research where it is known as the g theory raymond cattell expanded on spearman s idea of a two factor theory of intelligence after performing his own tests and factor analysis he used a multi factor theory to explain intelligence cattell s theory addressed alternate factors in intellectual development including motivation and psychology cattell also developed several mathematical methods for adjusting psychometric graphs such as his scree test and similarity coefficients his research led to the development of his theory of fluid and crystallized intelligence as well as his 16 personality factors theory of personality cattell was a strong advocate of factor analysis and psychometrics he believed that all theory should be derived from research which supports the continued use of empirical observation and objective testing to study human intelligence edit applications in psychology factor analysis is used to identify factors that explain a variety of results on different tests for example intelligence research found that people who get a high score on a test of verbal ability are also good on other tests that require verbal abilities researchers explained this by using factor analysis to isolate one factor often called crystallized intelligence or verbal intelligence which represents the degree to which someone is able to solve problems involving verbal skills factor analysis in psychology is most often associated with intelligence research however it also has been used to find factors in a broad range of domains such as personality attitudes beliefs etc it is linked to psychometrics as it can assess the validity of an instrument by finding if the instrument indeed measures the postulated factors edit advantages reduction of number of variables by combining two or more variables into a single factor for example performance at running ball throwing batting jumping and weight lifting could be combined into a single factor such as general athletic ability usually in an item by people matrix factors are selected by grouping related items in the q factor analysis technique the matrix is transposed and factors are created by grouping related people for example liberals libertarians conservatives and socialists could form separate groups identification of groups of inter related variables to see how they are related to each other for example carroll used factor analysis to build his three stratum theory he found that a factor called broad visual perception relates to how good an individual is at visual tasks he also found a broad auditory perception factor relating to auditory task capability furthermore he found a global factor called g or general intelligence that relates to both broad visual perception and broad auditory perception this means someone with a high g is likely to have both a high visual perception capability and a high auditory perception capability and that g therefore explains a good part of why someone is good or bad in both of those domains edit disadvantages each orientation is equally acceptable mathematically but different factorial theories proved to differ as much in terms of the orientations of factorial axes for a given solution as in terms of anything else so that model fitting did not prove to be useful in distinguishing among theories sternberg 1977 6 this means all rotations represent different underlying processes but all rotations are equally valid outcomes of standard factor analysis optimization therefore it is impossible to pick the proper rotation using factor analysis alone factor analysis can be only as good as the data allows in psychology where researchers often have to rely on less valid and reliable measures such as self reports this can be problematic interpreting factor analysis is based on using a heuristic which is a solution that is convenient even if not absolutely true 7 more than one interpretation can be made of the same data factored the same way and factor analysis cannot identify causality edit exploratory factor analysis versus principal components analysis see also principal component analysis 160 and exploratory factor analysis while exploratory factor analysis and principal component analysis are treated as synonymous techniques in some fields of statistics this has been criticised e g fabrigar et al 1999 8 suhr 2009 9 in factor analysis the researcher makes the assumption that an underlying causal model exists whereas pca is simply a variable reduction technique 10 researchers have argued that the distinctions between the two techniques may mean that there are objective benefits for preferring one over the other based on the analytic goal edit arguments contrasting pca and efa fabrigar et al 1999 8 address a number of reasons used to suggest that principal components analysis is equivalent to factor analysis it is sometimes suggested that principal components analysis is computationally quicker and requires fewer resources than factor analysis fabrigar et al suggest that the ready availability of computer resources have rendered this practical concern irrelevant 8 pca and factor analysis can produce similar results this point is also addressed by fabrigar et al in certain cases whereby the communalities are low e g 40 the two techniques produce divergent results in fact fabrigar et al argue that in cases where the data correspond to assumptions of the common factor model the results of pca are inaccurate results 8 there are certain cases where factor analysis leads to heywood cases these encompass situations whereby 100 or more of the variance in a measured variable is estimated to be accounted for by the model fabrigar et al suggest that these cases are actually informative to the researcher indicating a misspecified model or a violation of the common factor model the lack of heywood cases in the pca approach may mean that such issues pass unnoticed 8 researchers gain extra information from a pca approach such as an individual s score on a certain component such information is not yielded from factor analysis however as fabrigar et al contend the typical aim of factor analysis i e to determine the factors accounting for the structure of the correlations between measured variables does not require knowledge of factor scores and thus this advantage is negated 8 it is also possible to compute factor scores from a factor analysis edit variance versus covariance factor analysis takes into account the random error that is inherent in measurement whereas pca fails to do so this point is exemplified by brown 2009 11 who indicated that in respect to the correlation matrices involved in the calculations in pca 1 00s are put in the diagonal meaning that all of the variance in the matrix is to be accounted for including variance unique to each variable variance common among variables and error variance that would therefore by definition include all of the variance in the variables in contrast in efa the communalities are put in the diagonal meaning that only the variance shared with other variables is to be accounted for excluding variance unique to each variable and error variance that would therefore by definition include only variance that is common among the variables brown 2009 principal components analysis and exploratory factor analysis definitions differences and choices for this reason brown 2009 recommends using factor analysis when theoretical ideas about relationships between variables exist whereas pca should be used if the goal of the researcher is to explore patterns in their data edit differences in procedure and results the differences between principal components analysis and factor analysis are further illustrated by suhr 2009 pca results in principal components that account for a maximal amount of variance for observed variables fa account for common variance in the data 9 pca inserts ones on the diagonals of the correlation matrix fa adjusts the diagonals of the correlation matrix with the unique factors 9 pca minimizes the sum of squared perpendicular distance to the component axis fa estimates factors which influence responses on observed variables 9 the component scores in pca represent a linear combination of the observed variables weighted by eigenvectors the observed variables in fa are linear combinations of the underlying and unique factors 9 in pca the components yielded are uninterpretable i e they do not represent underlying constructs in fa the underlying constructs can be labeled and readily interpreted given an accurate model specification 9 edit factor analysis in marketing the basic steps are identify the salient attributes consumers use to evaluate products in this category use quantitative marketing research techniques such as surveys to collect data from a sample of potential customers concerning their ratings of all the product attributes input the data into a statistical program and run the factor analysis procedure the computer will yield a set of underlying attributes or factors use these factors to construct perceptual maps and other product positioning devices edit information collection the data collection stage is usually done by marketing research professionals survey questions ask the respondent to rate a product sample or descriptions of product concepts on a range of attributes anywhere from five to twenty attributes are chosen they could include things like ease of use weight accuracy durability colourfulness price or size the attributes chosen will vary depending on the product being studied the same question is asked about all the products in the study the data for multiple products is coded and input into a statistical program such as r spss sas stata statistica jmp and systat edit analysis the analysis will isolate the underlying factors that explain the data using a matrix of associations 12 factor analysis is an interdependence technique the complete set of interdependent relationships is examined there is no specification of dependent variables independent variables or causality factor analysis assumes that all the rating data on different attributes can be reduced down to a few important dimensions this reduction is possible because some attributes may be related to each other the rating given to any one attribute is partially the result of the influence of other attributes the statistical algorithm deconstructs the rating called a raw score into its various components and reconstructs the partial scores into underlying factor scores the degree of correlation between the initial raw score and the final factor score is called a factor loading edit advantages both objective and subjective attributes can be used provided the subjective attributes can be converted into scores factor analysis can identify latent dimensions or constructs that direct analysis may not it is easy and inexpensive edit disadvantages usefulness depends on the researchers ability to collect a sufficient set of product attributes if important attributes are excluded or neglected the value of the procedure is reduced if sets of observed variables are highly similar to each other and distinct from other items factor analysis will assign a single factor to them this may obscure factors that represent more interesting relationships clarification needed naming factors may require knowledge of theory because seemingly dissimilar attributes can correlate strongly for unknown reasons edit factor analysis in physical sciences factor analysis has also been widely used in physical sciences such as geochemistry ecology and hydrochemistry 13 in groundwater quality management it is important to relate the spatial distribution of different chemical parameters to different possible sources which have different chemical signatures for example a sulfide mine is likely to be associated with high levels of acidity dissolved sulfates and transition metals these signatures can be identified as factors through r mode factor analysis and the location of possible sources can be suggested by contouring the factor scores 14 in geochemistry different factors can correspond to different mineral associations and thus to mineralisation 15 edit factor analysis in microarray analysis factor analysis can be used for summarizing high density oligonucleotide dna microarrays data at probe level for affymetrix genechips in this case the latent variable corresponds to the rna concentration in a sample 16 edit implementation factor analysis has been implemented in several statistical analysis programs since the 1980s sas bmdp and spss 17 it is also implemented in the r programming language with the factanal function and in openopt rotations are implemented in the gparotation r package edit see also design of experiments formal concept analysis higher order factor analysis independent component analysis multilinear pca multilinear subspace learning non negative matrix factorization perceptual mapping product management q methodology recommendation system varimax rotation edit references bartholomew d j steele f galbraith j moustaki i 2008 analysis of multivariate social science data statistics in the social and behavioral sciences series 2nd ed taylor amp francis isbn 160 1584889608 meng j 2011 uncover cooperative gene regulations by micrornas and transcription factors in glioblastoma using a nonnegative hybrid factor model international conference on acoustics speech and signal processing http www cmsworldwide com icassp2011 papers viewpapers asp papernum 4439 bandalos d l boehm kaufman m r 2008 four common misconceptions in exploratory factor analysis in lance charles e vandenberg robert j statistical and methodological myths and urban legends doctrine verity and fable in the organizational and social sciences taylor amp francis pp 160 61 87 isbn 160 978 0 8058 6237 9 http books google com books id kfankvqd8cgc amp pg pa61 ledesma r d valero mora p 2007 determining the number of factors to retain in efa an easy to use computer program for carrying out parallel analysis practical assessment research amp evaluation 12 2 1 11 http pareonline net getvn asp v 12 amp n 2 russell d w december 2002 in search of underlying dimensions the use and abuse of factor analysis in personality and social psychology bulletin personality and social psychology bulletin 28 12 1629 46 doi 10 1177 014616702237645 http psp sagepub com content 28 12 1629 short sternberg r j 1977 metaphors of mind conceptions of the nature of intelligence new york cambridge pp 160 85 111 richard b darlington 2004 factor analysis http comp9 psych cornell edu darlington factor htm retrieved july 22 2004 a b c d e f fabrigar et al 1999 evaluating the use of exploratory factor analysis in psychological research psychological methods http www statpower net content 312 handout fabrigar1999 pdf a b c d e f suhr diane 2009 principal component analysis vs exploratory factor analysis sugi 30 proceedings http www2 sas com proceedings sugi30 203 30 pdf retrieved 5 april 2012 sas statistics principal components analysis sas support textbook http support sas com publishing pubcat chaps 55129 pdf brown j d principal components analysis and exploratory factor analysis definitions differences and choices shiken jalt testing amp evaluation sig newsletter http jalt org test pdf brown29 pdf retrieved 16 april 2012 ritter n 2012 a comparison of distribution free and non distribution free methods in factor analysis paper presented at southwestern educational research association sera conference 2012 new orleans la ed529153 subbarao c subbarao n v chandu s n december 1996 characterisation of groundwater contamination using factor analysis environmental geology 28 4 175 180 doi 10 1007 s002540050091 http www springerlink com content yqhnrjhdlq8yctj2 love d hallbauer d k amos a hranova r k 2004 factor analysis as a tool in groundwater quality management two southern african case studies physics and chemistry of the earth 29 1135 43 doi 10 1016 j pce 2004 09 027 barton e s hallbauer d k 1996 trace element and u pb isotope compositions of pyrite types in the proterozoic black reef transvaal sequence south africa implications on genesis and age chemical geology 133 173 199 doi 10 1016 s0009 2541 96 00075 7 hochreiter sepp clevert djork arn obermayer klaus 2006 a new summarization method for affymetrix probe level data bioinformatics 22 8 943 9 doi 10 1093 bioinformatics btl033 pmid 160 16473874 http bioinformatics oxfordjournals org content 22 8 943 full maccallum robert june 1983 a comparison of factor analysis programs in spss bmdp and sas psychometrika 48 48 doi 10 1007 bf02294017 edit further reading child dennis 2006 the essentials of factor analysis 3rd ed continuum international isbn 160 978 0 8264 8000 2 http books google com books id rq2vdjgohh0c fabrigar l r wegener d t maccallum r c strahan e j september 1999 evaluating the use of exploratory factor analysis in psychological research psychological methods 4 3 272 299 doi 10 1037 1082 989x 4 3 272 http psycnet apa org journals met 4 3 272 thompson b 2004 exploratory and confirmatory factor analysis understanding concepts and applications washington dc american psychological association isbn 160 1591470935 edit external links factor analysis retrieved july 23 2004 from http www2 chass ncsu edu garson pa765 factor htm raymond cattell retrieved july 22 2004 from http www indiana edu intell rcattell shtml exploratory factor analysis a book manuscript by tucker l amp maccallum r 1993 retrieved june 8 2006 from http www unc edu rcm book factornew htm garson g david factor analysis from statnotes topics in multivariate analysis retrieved on april 13 2009 from http www2 chass ncsu edu garson pa765 statnote htm factor analysis at 100 conference material farms factor analysis for robust microarray summarization an r package software 