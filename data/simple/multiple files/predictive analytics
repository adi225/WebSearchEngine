this article needs additional citations for verification please help improve this article by adding citations to reliable sources unsourced material may be challenged and removed june 2011 predictive analytics encompasses a variety of techniques from statistics modeling machine learning and data mining that analyze current and historical facts to make predictions about future events 1 2 in business predictive models exploit patterns found in historical and transactional data to identify risks and opportunities models capture relationships among many factors to allow assessment of risk or potential associated with a particular set of conditions guiding decision making for candidate transactions predictive analytics is used in actuarial science 3 marketing 4 financial services 5 insurance telecommunications 6 retail 7 travel 8 healthcare 9 pharmaceuticals 10 and other fields one of the most well known applications is credit scoring 1 which is used throughout financial services scoring models process a customer s credit history loan application customer data etc in order to rank order individuals by their likelihood of making future credit payments on time a well known example is the fico score contents 1 definition 2 types 2 1 predictive models 2 2 descriptive models 2 3 decision models 3 applications 3 1 analytical customer relationship management crm 3 2 clinical decision support systems 3 3 collection analytics 3 4 cross sell 3 5 customer retention 3 6 direct marketing 3 7 fraud detection 3 8 portfolio product or economy level prediction 3 9 risk management 3 10 underwriting 4 technology and big data influences on predictive analytics 5 statistical techniques 5 1 regression models 5 1 1 linear regression model 5 2 discrete choice models 5 2 1 logistic regression 5 2 2 multinomial logistic regression 5 2 3 probit regression 5 2 4 logit versus probit 5 3 time series models 5 4 survival or duration analysis 5 5 classification and regression trees 5 6 multivariate adaptive regression splines 5 7 machine learning techniques 5 7 1 neural networks 5 7 2 radial basis functions 5 7 3 support vector machines 5 7 4 na ve bayes 5 7 5 k nearest neighbours 5 7 6 geospatial predictive modeling 6 tools 6 1 pmml 7 see also 8 references 8 1 further reading edit definition predictive analytics is an area of statistical analysis that deals with extracting information from data and using it to predict future trends and behavior patterns the core of predictive analytics relies on capturing relationships between explanatory variables and the predicted variables from past occurrences and exploiting them to predict future outcomes it is important to note however that the accuracy and usability of results will depend greatly on the level of data analysis and the quality of assumptions edit types generally the term predictive analytics is used to mean predictive modeling scoring data with predictive models and forecasting however people are increasingly using the term to refer to related analytical disciplines such as descriptive modeling and decision modeling or optimization these disciplines also involve rigorous data analysis and are widely used in business for segmentation and decision making but have different purposes and the statistical techniques underlying them vary edit predictive models predictive models analyze past performance to assess how likely a customer is to exhibit a specific behavior in the future in order to improve marketing effectiveness this category also encompasses models that seek out subtle data patterns to answer questions about customer performance such as fraud detection models predictive models often perform calculations during live transactions for example to evaluate the risk or opportunity of a given customer or transaction in order to guide a decision with advancements in computing speed individual agent modeling systems have become capable of simulating human behaviors or reactions to given stimuli or scenarios the new term for animating data specifically linked to an individual in a simulated environment is avatar analytics edit descriptive models descriptive models quantify relationships in data in a way that is often used to classify customers or prospects into groups unlike predictive models that focus on predicting a single customer behavior such as credit risk descriptive models identify many different relationships between customers or products descriptive models do not rank order customers by their likelihood of taking a particular action the way predictive models do instead descriptive models can be used for example to categorize customers by their product preferences and life stage descriptive modeling tools can be utilized to develop further models that can simulate large number of individualized agents and make predictions edit decision models decision models describe the relationship between all the elements of a decision the known data including results of predictive models the decision and the forecast results of the decision in order to predict the results of decisions involving many variables these models can be used in optimization maximizing certain outcomes while minimizing others decision models are generally used to develop decision logic or a set of business rules that will produce the desired action for every customer or circumstance edit applications although predictive analytics can be put to use in many applications we outline a few examples where predictive analytics has shown positive impact in recent years edit analytical customer relationship management crm analytical customer relationship management is a frequent commercial application of predictive analysis methods of predictive analysis are applied to customer data to pursue crm objectives which involve constructing a holistic view of the customer no matter where their information resides in the company or the department involved crm uses predictive analysis in applications for marketing campaigns sales and customer services to name a few these tools are required in order for a company to posture and focus their efforts effectively across the breadth of their customer base they must analyze and understand the products in demand or have the potential for high demand predict customers buying habits in order to promote relevant products at multiple touch points and proactively identify and mitigate issues that have the potential to lose customers or reduce their ability to gain new ones edit clinical decision support systems experts use predictive analysis in health care primarily to determine which patients are at risk of developing certain conditions like diabetes asthma heart disease and other lifetime illnesses additionally sophisticated clinical decision support systems incorporate predictive analytics to support medical decision making at the point of care a working definition has been proposed by robert hayward of the centre for health evidence clinical decision support systems link health observations with health knowledge to influence health choices by clinicians for improved health care citation needed edit collection analytics every portfolio has a set of delinquent customers who do not make their payments on time the financial institution has to undertake collection activities on these customers to recover the amounts due a lot of collection resources are wasted on customers who are difficult or impossible to recover predictive analytics can help optimize the allocation of collection resources by identifying the most effective collection agencies contact strategies legal actions and other strategies to each customer thus significantly increasing recovery at the same time reducing collection costs edit cross sell often corporate organizations collect and maintain abundant data e g customer records sale transactions as exploiting hidden relationships in the data can provide a competitive advantage for an organization that offers multiple products predictive analytics can help analyze customers spending usage and other behavior leading to efficient cross sales or selling additional products to current customers 2 this directly leads to higher profitability per customer and stronger customer relationships edit customer retention with the number of competing services available businesses need to focus efforts on maintaining continuous consumer satisfaction rewarding consumer loyalty and minimizing customer attrition businesses tend to respond to customer attrition on a reactive basis acting only after the customer has initiated the process to terminate service at this stage the chance of changing the customer s decision is almost impossible proper application of predictive analytics can lead to a more proactive retention strategy by a frequent examination of a customer s past service usage service performance spending and other behavior patterns predictive models can determine the likelihood of a customer terminating service sometime in the near future 6 an intervention with lucrative offers can increase the chance of retaining the customer silent attrition the behavior of a customer to slowly but steadily reduce usage is another problem that many companies face predictive analytics can also predict this behavior so that the company can take proper actions to increase customer activity edit direct marketing when marketing consumer products and services there is the challenge of keeping up with competing products and consumer behavior apart from identifying prospects predictive analytics can also help to identify the most effective combination of product versions marketing material communication channels and timing that should be used to target a given consumer the goal of predictive analytics is typically to lower the cost per order or cost per action edit fraud detection fraud is a big problem for many businesses and can be of various types inaccurate credit applications fraudulent transactions both offline and online identity thefts and false insurance claims these problems plague firms of all sizes in many industries some examples of likely victims are credit card issuers insurance companies 11 retail merchants manufacturers business to business suppliers and even services providers a predictive model can help weed out the bads and reduce a business s exposure to fraud predictive modeling can also be used to identify high risk fraud candidates in business or the public sector nigrini developed a risk scoring method to identify audit targets he describes the use of this approach to detect fraud in the franchisee sales reports of an international fast food chain each location is scored using 10 predictors the 10 scores are then weighted to give one final overall risk score for each location the same scoring approach was also used to identify high risk check kiting accounts potentially fraudulent travel agents and questionable vendors a reasonably complex model was used to identify fraudulent monthly reports submitted by divisional controllers 12 the internal revenue service irs of the united states also uses predictive analytics to mine tax returns and identify tax fraud 11 recent when advancements in technology have also introduced predictive behavior analysis for web fraud detection this type of solution utilizes heuristics in order to study normal web user behavior and detect anomalies indicating fraud attempts edit portfolio product or economy level prediction often the focus of analysis is not the consumer but the product portfolio firm industry or even the economy for example a retailer might be interested in predicting store level demand for inventory management purposes or the federal reserve board might be interested in predicting the unemployment rate for the next year these types of problems can be addressed by predictive analytics using time series techniques see below they can also be addressed via machine learning approaches which transform the original time series into a feature vector space where the learning algorithm finds patterns that have predictive power 13 14 edit risk management when employing risk management techniques the results are always to predict and benefit from a future scenario the capital asset pricing model cap m predicts the best portfolio to maximize return probabilistic risk assessment pra when combined with mini delphi techniques and statistical approaches yields accurate forecasts and riskaoa is a stand alone predictive tool 15 these are three examples of approaches that can extend from project to market and from near to long term underwriting see below and other business approaches identify risk management as a predictive method edit underwriting many businesses have to account for risk exposure due to their different services and determine the cost needed to cover the risk for example auto insurance providers need to accurately determine the amount of premium to charge to cover each automobile and driver a financial company needs to assess a borrower s potential and ability to pay before granting a loan for a health insurance provider predictive analytics can analyze a few years of past medical claims data as well as lab pharmacy and other records where available to predict how expensive an enrollee is likely to be in the future predictive analytics can help underwrite these quantities by predicting the chances of illness default bankruptcy etc predictive analytics can streamline the process of customer acquisition by predicting the future risk behavior of a customer using application level data 3 predictive analytics in the form of credit scores have reduced the amount of time it takes for loan approvals especially in the mortgage market where lending decisions are now made in a matter of hours rather than days or even weeks proper predictive analytics can lead to proper pricing decisions which can help mitigate future risk of default edit technology and big data influences on predictive analytics big data is a collection of data sets that are so large and complex that they become awkward to work with using traditional database management tools the volume variety and velocity of big data have introduced challenges across the board for capture storage search sharing analysis and visualization examples of big data sources include web logs rfid and sensor data social networks internet search indexing call detail records military surveillance and complex data in astronomic biogeochemical genomics and atmospheric sciences thanks to technological advances in computer hardware faster cpus cheaper memory and mpp architectures and new technologies such as hadoop mapreduce and in database and text analytics for processing big data it is now feasible to collect analyze and mine massive amounts of structured and unstructured data for new insights 11 today exploring big data and using predictive analytics is within reach of more organizations than ever before edit statistical techniques the approaches and techniques used to conduct predictive analytics can broadly be grouped into regression techniques and machine learning techniques edit regression models regression models are the mainstay of predictive analytics the focus lies on establishing a mathematical equation as a model to represent the interactions between the different variables in consideration depending on the situation there is a wide variety of models that can be applied while performing predictive analytics some of them are briefly discussed below edit linear regression model the linear regression model analyzes the relationship between the response or dependent variable and a set of independent or predictor variables this relationship is expressed as an equation that predicts the response variable as a linear function of the parameters these parameters are adjusted so that a measure of fit is optimized much of the effort in model fitting is focused on minimizing the size of the residual as well as ensuring that it is randomly distributed with respect to the model predictions the goal of regression is to select the parameters of the model so as to minimize the sum of the squared residuals this is referred to as ordinary least squares ols estimation and results in best linear unbiased estimates blue of the parameters if and only if the gauss markov assumptions are satisfied once the model has been estimated we would be interested to know if the predictor variables belong in the model i e is the estimate of each variable s contribution reliable to do this we can check the statistical significance of the model s coefficients which can be measured using the t statistic this amounts to testing whether the coefficient is significantly different from zero how well the model predicts the dependent variable based on the value of the independent variables can be assessed by using the r statistic it measures predictive power of the model i e the proportion of the total variation in the dependent variable that is explained accounted for by variation in the independent variables edit discrete choice models multivariate regression above is generally used when the response variable is continuous and has an unbounded range often the response variable may not be continuous but rather discrete while mathematically it is feasible to apply multivariate regression to discrete ordered dependent variables some of the assumptions behind the theory of multivariate linear regression no longer hold and there are other techniques such as discrete choice models which are better suited for this type of analysis if the dependent variable is discrete some of those superior methods are logistic regression multinomial logit and probit models logistic regression and probit models are used when the dependent variable is binary edit logistic regression for more details on this topic see logistic regression in a classification setting assigning outcome probabilities to observations can be achieved through the use of a logistic model which is basically a method which transforms information about the binary dependent variable into an unbounded continuous variable and estimates a regular multivariate model see allison s logistic regression for more information on the theory of logistic regression the wald and likelihood ratio test are used to test the statistical significance of each coefficient b in the model analogous to the t tests used in ols regression see above a test assessing the goodness of fit of a classification model is the percentage correctly predicted edit multinomial logistic regression an extension of the binary logit model to cases where the dependent variable has more than 2 categories is the multinomial logit model in such cases collapsing the data into two categories might not make good sense or may lead to loss in the richness of the data the multinomial logit model is the appropriate technique in these cases especially when the dependent variable categories are not ordered for examples colors like red blue green some authors have extended multinomial regression to include feature selection importance methods such as random multinomial logit edit probit regression probit models offer an alternative to logistic regression for modeling categorical dependent variables even though the outcomes tend to be similar the underlying distributions are different probit models are popular in social sciences like economics a good way to understand the key difference between probit and logit models is to assume that there is a latent variable z we do not observe z but instead observe y which takes the value 0 or 1 in the logit model we assume that y follows a logistic distribution in the probit model we assume that y follows a standard normal distribution note that in social sciences e g economics probit is often used to model situations where the observed variable y is continuous but takes values between 0 and 1 edit logit versus probit the probit model has been around longer than the logit model they behave similarly except that the logistic distribution tends to be slightly flatter tailed one of the reasons the logit model was formulated was that the probit model was computationally difficult due to the requirement of numerically calculating integrals modern computing however has made this computation fairly simple the coefficients obtained from the logit and probit model are fairly close however the odds ratio is easier to interpret in the logit model practical reasons for choosing the probit model over the logistic model would be there is a strong belief that the underlying distribution is normal the actual event is not a binary outcome e g bankruptcy status but a proportion e g proportion of population at different debt levels edit time series models time series models are used for predicting or forecasting the future behavior of variables these models account for the fact that data points taken over time may have an internal structure such as autocorrelation trend or seasonal variation that should be accounted for as a result standard regression techniques cannot be applied to time series data and methodology has been developed to decompose the trend seasonal and cyclical component of the series modeling the dynamic path of a variable can improve forecasts since the predictable component of the series can be projected into the future time series models estimate difference equations containing stochastic components two commonly used forms of these models are autoregressive models ar and moving average ma models the box jenkins methodology 1976 developed by george box and g m jenkins combines the ar and ma models to produce the arma autoregressive moving average model which is the cornerstone of stationary time series analysis arima autoregressive integrated moving average models on the other hand are used to describe non stationary time series box and jenkins suggest differencing a non stationary time series to obtain a stationary series to which an arma model can be applied non stationary time series have a pronounced trend and do not have a constant long run mean or variance box and jenkins proposed a three stage methodology which includes model identification estimation and validation the identification stage involves identifying if the series is stationary or not and the presence of seasonality by examining plots of the series autocorrelation and partial autocorrelation functions in the estimation stage models are estimated using non linear time series or maximum likelihood estimation procedures finally the validation stage involves diagnostic checking such as plotting the residuals to detect outliers and evidence of model fit in recent years time series models have become more sophisticated and attempt to model conditional heteroskedasticity with models such as arch autoregressive conditional heteroskedasticity and garch generalized autoregressive conditional heteroskedasticity models frequently used for financial time series in addition time series models are also used to understand inter relationships among economic variables represented by systems of equations using var vector autoregression and structural var models edit survival or duration analysis survival analysis is another name for time to event analysis these techniques were primarily developed in the medical and biological sciences but they are also widely used in the social sciences like economics as well as in engineering reliability and failure time analysis censoring and non normality which are characteristic of survival data generate difficulty when trying to analyze the data using conventional statistical models such as multiple linear regression the normal distribution being a symmetric distribution takes positive as well as negative values but duration by its very nature cannot be negative and therefore normality cannot be assumed when dealing with duration survival data hence the normality assumption of regression models is violated the assumption is that if the data were not censored it would be representative of the population of interest in survival analysis censored observations arise whenever the dependent variable of interest represents the time to a terminal event and the duration of the study is limited in time an important concept in survival analysis is the hazard rate defined as the probability that the event will occur at time t conditional on surviving until time t another concept related to the hazard rate is the survival function which can be defined as the probability of surviving to time t most models try to model the hazard rate by choosing the underlying distribution depending on the shape of the hazard function a distribution whose hazard function slopes upward is said to have positive duration dependence a decreasing hazard shows negative duration dependence whereas constant hazard is a process with no memory usually characterized by the exponential distribution some of the distributional choices in survival models are f gamma weibull log normal inverse normal exponential etc all these distributions are for a non negative random variable duration models can be parametric non parametric or semi parametric some of the models commonly used are kaplan meier and cox proportional hazard model non parametric edit classification and regression trees main article decision tree learning classification and regression trees cart is a non parametric decision tree learning technique that produces either classification or regression trees depending on whether the dependent variable is categorical or numeric respectively decision trees are formed by a collection of rules based on variables in the modeling data set rules based on variables values are selected to get the best split to differentiate observations based on the dependent variable once a rule is selected and splits a node into two the same process is applied to each child node i e it is a recursive procedure splitting stops when cart detects no further gain can be made or some pre set stopping rules are met alternatively the data are split as much as possible and then the tree is later pruned each branch of the tree ends in a terminal node each observation falls into one and exactly one terminal node and each terminal node is uniquely defined by a set of rules a very popular method for predictive analytics is leo breiman s random forests or derived versions of this technique like random multinomial logit edit multivariate adaptive regression splines multivariate adaptive regression splines mars is a non parametric technique that builds flexible models by fitting piecewise linear regressions an important concept associated with regression splines is that of a knot knot is where one local regression model gives way to another and thus is the point of intersection between two splines in multivariate and adaptive regression splines basis functions are the tool used for generalizing the search for knots basis functions are a set of functions used to represent the information contained in one or more variables multivariate and adaptive regression splines model almost always creates the basis functions in pairs multivariate and adaptive regression spline approach deliberately overfits the model and then prunes to get to the optimal model the algorithm is computationally very intensive and in practice we are required to specify an upper limit on the number of basis functions edit machine learning techniques machine learning a branch of artificial intelligence was originally employed to develop techniques to enable computers to learn today since it includes a number of advanced statistical methods for regression and classification it finds application in a wide variety of fields including medical diagnostics credit card fraud detection face and speech recognition and analysis of the stock market in certain applications it is sufficient to directly predict the dependent variable without focusing on the underlying relationships between variables in other cases the underlying relationships can be very complex and the mathematical form of the dependencies unknown for such cases machine learning techniques emulate human cognition and learn from training examples to predict future events a brief discussion of some of these methods used commonly for predictive analytics is provided below a detailed study of machine learning can be found in mitchell 1997 edit neural networks neural networks are nonlinear sophisticated modeling techniques that are able to model complex functions they can be applied to problems of prediction classification or control in a wide spectrum of fields such as finance cognitive psychology neuroscience medicine engineering and physics neural networks are used when the exact nature of the relationship between inputs and output is not known a key feature of neural networks is that they learn the relationship between inputs and output through training there are three types of training in neural networks used by different networks supervised and unsupervised training reinforcement learning with supervised being the most common one some examples of neural network training techniques are backpropagation quick propagation conjugate gradient descent projection operator delta bar delta etc some unsupervised network architectures are multilayer perceptrons kohonen networks hopfield networks etc edit radial basis functions a radial basis function rbf is a function which has built into it a distance criterion with respect to a center such functions can be used very efficiently for interpolation and for smoothing of data radial basis functions have been applied in the area of neural networks where they are used as a replacement for the sigmoidal transfer function such networks have 3 layers the input layer the hidden layer with the rbf non linearity and a linear output layer the most popular choice for the non linearity is the gaussian rbf networks have the advantage of not being locked into local minima as do the feed forward networks such as the multilayer perceptron edit support vector machines support vector machines svm are used to detect and exploit complex patterns in data by clustering classifying and ranking the data they are learning machines that are used to perform binary classifications and regression estimations they commonly use kernel based methods to apply linear classification techniques to non linear classification problems there are a number of types of svm such as linear polynomial sigmoid etc edit na ve bayes na ve bayes based on bayes conditional probability rule is used for performing classification tasks na ve bayes assumes the predictors are statistically independent which makes it an effective classification tool that is easy to interpret it is best employed when faced with the problem of curse of dimensionality i e when the number of predictors is very high edit k nearest neighbours the nearest neighbour algorithm knn belongs to the class of pattern recognition statistical methods the method does not impose a priori any assumptions about the distribution from which the modeling sample is drawn it involves a training set with both positive and negative values a new sample is classified by calculating the distance to the nearest neighbouring training case the sign of that point will determine the classification of the sample in the k nearest neighbour classifier the k nearest points are considered and the sign of the majority is used to classify the sample the performance of the knn algorithm is influenced by three main factors 1 the distance measure used to locate the nearest neighbours 2 the decision rule used to derive a classification from the k nearest neighbours and 3 the number of neighbours used to classify the new sample it can be proved that unlike other methods this method is universally asymptotically convergent i e as the size of the training set increases if the observations are independent and identically distributed i i d regardless of the distribution from which the sample is drawn the predicted class will converge to the class assignment that minimizes misclassification error see devroy et al edit geospatial predictive modeling conceptually geospatial predictive modeling is rooted in the principle that the occurrences of events being modeled are limited in distribution occurrences of events are neither uniform nor random in distribution there are spatial environment factors infrastructure sociocultural topographic etc that constrain and influence where the locations of events occur geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences geospatial predictive modeling is a process for analyzing events through a geographic filter in order to make statements of likelihood for event occurrence or emergence edit tools historically using predictive analytics tools as well as understanding the results they delivered required advanced skills however modern predictive analytics tools are no longer restricted to it specialists as more organizations adopt predictive analytics into decision making processes and integrate it into their operations they are creating a shift in the market toward business users as the primary consumers of the information business users want tools they can use on their own vendors are responding by creating new software that removes the mathematical complexity provides user friendly graphic interfaces and or builds in short cuts that can for example recognize the kind of data available and suggest an appropriate predictive model 16 predictive analytics tools have become sophisticated enough to adequately present and dissect data problems so that any data savvy information worker can utilize them to analyze data and retrieve meaningful useful results 2 for example modern tools present findings using simple charts graphs and scores that indicate the likelihood of possible outcomes 17 there are numerous tools available in the marketplace that help with the execution of predictive analytics these range from those that need very little user sophistication to those that are designed for the expert practitioner the difference between these tools is often in the level of customization and heavy data lifting allowed notable open source predictive analytic tools include knime orange python r rapidminer weka notable commercial predictive analytic tools include angoss knowledgestudio exacaster ibm spss statistics and ibm spss modeler kxen modeler mathematica matlab oracle data mining odm pervasive sap sas and sas enterprise miner statistica tibco edit pmml in an attempt to provide a standard language for expressing predictive models the predictive model markup language pmml has been proposed such an xml based language provides a way for the different tools to define predictive models and to share these between pmml compliant applications pmml 4 0 was released in june 2009 edit see also criminal reduction utilising statistical history data mining learning analytics odds algorithm pattern recognition prescriptive analytics this article includes a list of references but its sources remain unclear because it has insufficient inline citations please help to improve this article by introducing more precise citations october 2011 edit references a b nyce charles 2007 predictive analytics white paper american institute for chartered property casualty underwriters insurance institute of america p 160 1 http www aicpcu org doc predictivemodelingwhitepaper pdf a b c eckerson wayne may 10 2007 extending the value of your data warehousing investment the data warehouse institute http tdwi org articles 2007 05 10 predictive analytics aspx sc lang en a b conz nathan september 2 2008 insurers shift to customer focused predictive analytics technologies insurance amp technology http www insurancetech com business intelligence 210600271 fletcher heather march 2 2011 the 7 best uses for predictive analytics in multichannel marketing target marketing http www targetmarketingmag com article 7 best uses predictive analytics modeling multichannel marketing 1 korn sue april 21 2011 the opportunity for predictive analytics in finance hpc wire http www hpcwire com hpcwire 2011 04 21 the opportunity for predictive analytics in finance html a b barkin eric may 2011 crm predictive analytics why it all adds up destination crm http www destinationcrm com articles editorial magazine features crm predictive analytics why it all adds up 74700 aspx das krantik vidyashankar g s july 1 2006 competitive advantage in retail through analytics developing insights creating value information management http www information management com infodirect 20060707 1057744 1 html mcdonald mich le september 2 2010 new technology taps predictive analytics to target travel recommendations travel market report http www travelmarketreport com technology articleid 4259 amp lp 1 stevenson erin december 16 2011 tech beat can you pronounce health care predictive analytics times standard http www times standard com business ci 19561141 mckay lauren august 2009 the new prescription for pharma destination crm http www destinationcrm com articles web exclusives web only bonus articles the new prescription for pharma 55774 aspx a b c schiff mike march 6 2012 bi experts why predictive analytics will continue to grow the data warehouse institute http tdwi org articles 2012 03 06 predictive analytics growth aspx page 1 nigrini mark june 2011 forensic analytics methods and techniques for forensic accounting investigations hoboken nj john wiley amp sons inc isbn 160 978 0 470 89046 2 http www wiley com wileycda wileytitle productcd 0470890460 html dhar vasant april 2011 prediction in financial markets the case for small disjuncts acm transactions on intelligent systems and technologies 2 3 http dl acm org citation cfm id 1961191 dhar vasant chou dashin and provost foster october 2000 discovering interesting patterns in investment decision making with glower a genetic learning algorithm overlaid with entropy reduction data mining and knowledge discovery 4 4 http dl acm org citation cfm id 593502 https acc dau mil communitybrowser aspx id 126070 halper fran november 1 2011 the top 5 trends in predictive analytics information management http www information management com issues 21 6 the top 5 trends in redictive an alytics 10021460 1 html maclennan jamie may 1 2012 5 myths about predictive analytics the data warehouse institute http tdwi org articles 2012 05 01 5 predictive analytics myths aspx edit further reading agresti alan 2002 categorical data analysis hoboken john wiley and sons isbn 160 0 471 36093 7 coggeshall stephen davies john jones roger and schutzer daniel intelligent security systems in freedman roy s flein robert a and lederman jess editors 1995 artificial intelligence in the capital markets chicago irwin isbn 160 1 55738 811 3 l devroye l gy rfi g lugosi 1996 a probabilistic theory of pattern recognition new york springer verlag enders walter 2004 applied time series econometrics hoboken john wiley and sons isbn 160 0 521 83919 x greene william 2000 econometric analysis prentice hall isbn 160 0 13 013297 7 guid re mathieu howard n sh argamon 2009 rich language analysis for counterterrrorism berlin london new york springer verlag isbn 160 978 3 642 01140 5 mitchell tom 1997 machine learning new york mcgraw hill isbn 160 0 07 042807 7 tukey john 1977 exploratory data analysis new york addison wesley isbn 160 0 201 07616 0 