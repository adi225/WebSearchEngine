this article may require cleanup to meet wikipedia s quality standards the specific problem is extensive use of jargon to define jargon and inconsistent use of bold and italics font styles please help improve this article if you can january 2012 this article may need to be rewritten entirely to comply with wikipedia s quality standards you can help the discussion page may contain suggestions january 2012 question answering qa is a computer science discipline within the fields of information retrieval and natural language processing nlp which is concerned with building systems that automatically answer questions posed by humans in a natural language a qa implementation usually a computer program may construct its answers by querying a structured database of knowledge or information usually a knowledge base more commonly qa systems can pull answers from an unstructured collection of natural language documents some examples of natural language document collections used for qa systems include a local collection of reference texts internal organization documents and web pages compiled newswire reports a set of wikipedia pages a subset of world wide web pages qa research attempts to deal with a wide range of question types including fact list definition how why hypothetical semantically constrained and cross lingual questions closed domain question answering deals with questions under a specific domain for example medicine or automotive maintenance and can be seen as an easier task because nlp systems can exploit domain specific knowledge frequently formalized in ontologies alternatively closed domain might refer to a situation where only a limited type of questions are accepted such as questions asking for descriptive rather than procedural information open domain question answering deals with questions about nearly anything and can only rely on general ontologies and world knowledge on the other hand these systems usually have much more data available from which to extract the answer contents 1 history 2 architecture 3 question answering methods 4 issues 5 progress 6 references 7 external links edit history two early qa systems were baseball and lunar when who citation needed baseball answered questions about the us baseball league over a period of one year lunar in turn answered questions about the geological analysis of rocks returned by the apollo moon missions both qa systems were very effective in their chosen domains in fact lunar was demonstrated at a lunar science convention in 1971 and it was able to answer 90 of the questions in its domain posed by people untrained on the system further restricted domain qa systems were developed in the following years the common feature of all these systems is that they had a core database or knowledge system that was hand written by experts of the chosen domain the language abilities of baseball and lunar used techniques similar to eliza and doctor the first chatterbot programs shrdlu was a highly successful question answering program developed by terry winograd in the late 60s and early 70s it simulated the operation of a robot in a toy world the blocks world and it offered the possibility to ask the robot questions about the state of the world again the strength of this system was the choice of a very specific domain and a very simple world with rules of physics that were easy to encode in a computer program in the 1970s knowledge bases were developed that targeted narrower domains of knowledge the qa systems developed to interface with these expert systems produced more repeatable and valid responses to questions within an area of knowledge these expert systems closely resembled modern qa systems except in their internal architecture expert systems rely heavily on expert constructed and organized knowledge bases whereas many modern qa systems rely on statistical processing of a large unstructured natural language text corpus the 1970s and 1980s saw the development of comprehensive theories in computational linguistics which led to the development of ambitious projects in text comprehension and question answering one example of such a system was the unix consultant uc developed by robert wilensky at u c berkeley in the late 1980s the system answered questions pertaining to the unix operating system it had a comprehensive hand crafted knowledge base of its domain and it aimed at phrasing the answer to accommodate various types of users another project was lilog a text understanding system that operated on the domain of tourism information in a german city the systems developed in the uc and lilog projects never went past the stage of simple demonstrations but they helped the development of theories on computational linguistics and reasoning recently specialized natural language qa systems have been developed such as eagli for health and life scientists edit architecture most modern qa systems use natural language text documents as their underlying knowledge source natural language processing techniques are used to both process the question and index or process the text corpus from which answers are extracted an increasing number of qa systems use the world wide web as their corpus of text and knowledge however many of these tools do not produce a human like answer but rather employ shallow methods keyword based techniques templates to produce a list of documents or a list of document excerpts containing the probable answer highlighted in an alternative qa implementation human users assemble knowledge in a structured database called a knowledge base similar to those employed in the expert systems of the 1970s it is also to employ a combination of structured databases and natural language text documents in a hybrid qa system such a hybrid system may employ data mining algorithms to populate a structured knowledge base that is also populated and edited by human contributors an example hybrid qa system is the wolfram alpha qa system which employs natural language processing to transform human questions into a form that is processed by a curated knowledge base current qa systems 1 typically include a question classifier module that determines the type of question and the type of answer after the question is analysed the system typically uses several modules that apply increasingly complex nlp techniques on a gradually reduced amount of text thus a document retrieval module uses search engines to identify the documents or paragraphs in the document set that are likely to contain the answer subsequently a filter preselects small text fragments that contain strings of the same type as the expected answer for example if the question is who invented penicillin the filter returns text that contain names of people finally an answer extraction module looks for further clues in the text to determine if the answer candidate can indeed answer the question edit question answering methods qa is very dependent on a good search corpus for without documents containing the answer there is little any qa system can do it thus makes sense that larger collection sizes generally lend well to better qa performance unless the question domain is orthogonal to the collection the notion of data redundancy in massive collections such as the web means that nuggets of information are likely to be phrased in many different ways in differing contexts and documents 2 leading to two benefits by having the right information appear in many forms the burden on the qa system to perform complex nlp techniques to understand the text is lessened correct answers can be filtered from false positives by relying on the correct answer to appear more times in the documents than instances of incorrect ones question answering heavily relies on reasoning and there is a number of question answering systems designed in prolog 3 edit issues in 2002 a group of researchers wrote a roadmap of research in question answering 4 the following issues were identified question classes 160 different types of questions e g what is the capital of liechtenstein vs why does a rainbow form vs did marilyn monroe and cary grant ever appear in a movie together require the use of different strategies to find the answer question classes are arranged hierarchically in taxonomies example needed question processing 160 the same information request can be expressed in various ways some interrogative who is the king of lesotho and some assertive tell me the name of the king of lesotho a semantic model of question understanding and processing would recognize equivalent questions regardless of how they are presented this model would enable the translation of a complex question into a series of simpler questions would identify ambiguities and treat them in context or by interactive clarification context and qa 160 questions are usually asked within a context and answers are provided within that specific context the context can be used to clarify a question resolve ambiguities or keep track of an investigation performed through a series of questions for example the question why did joe biden visit iraq in january 2010 might be asking why vice president biden visited and not president obama why he went to iraq and not afghanistan or some other country why he went in january 2010 and not before or after or what biden was hoping to accomplish with his visit if the question is one of a series of related questions the previous questions and their answers might shed light on the questioner s intent data sources for qa 160 before a question can be answered it must be known what knowledge sources are available and relevant if the answer to a question is not present in the data sources no matter how well the question processing information retrieval and answer extraction is performed a correct result will not be obtained answer extraction 160 answer extraction depends on the complexity of the question on the answer type provided by question processing on the actual data where the answer is searched on the search method and on the question focus and context example needed answer formulation 160 the result of a qa system should be presented in a way as natural as possible in some cases simple extraction is sufficient for example when the question classification indicates that the answer type is a name of a person organization shop or disease etc a quantity monetary value length size distance etc or a date e g the answer to the question on what day did christmas fall in 1989 the extraction of a single datum is sufficient for other cases the presentation of the answer may require the use of fusion techniques that combine the partial answers from multiple documents real time question answering 160 there is need for developing q amp a systems that are capable of extracting answers from large data sets in several seconds regardless of the complexity of the question the size and multitude of the data sources or the ambiguity of the question multilingual or cross lingual question answering 160 the ability to answer a question posed in one language using an answer corpus in another language or even several this allows users to consult information that they cannot use directly see also machine translation interactive qa 160 it is often the case that the information need is not well captured by a qa system as the question processing part may fail to classify properly the question or the information needed for extracting and generating the answer is not easily retrieved in such cases the questioner might want not only to reformulate the question but to have a dialogue with the system for example the system might ask for a clarification of what sense a word is being used or what type of information is being asked for advanced reasoning for qa 160 more sophisticated questioners expect answers that are outside the scope of written texts or structured databases to upgrade a qa system with such capabilities it would be necessary to integrate reasoning components operating on a variety of knowledge bases encoding world knowledge and common sense reasoning mechanisms as well as knowledge specific to a variety of domains example needed information clustering for qa information clustering for question answering systems is a new trend that is originated to increase the accuracy of question answering systems through search space reduction in recent years this is widely researched through development of question answering systems which support information clustering in their basic flow of process 5 user profiling for qa 160 the user profile captures data about the questioner comprising context data domain of interest reasoning schemes frequently used by the questioner common ground established within different dialogues between the system and the user and so forth the profile may be represented as a predefined template where each template slot represents a different profile feature profile templates may be nested one within another example needed edit progress qa systems have been extended in recent years to encompass additional domains of knowledge 6 for example systems have been developed to automatically answer temporal and geospatial questions questions of definition and terminology biographical questions multilingual questions and questions about the content of audio images and video current qa research topics include interactivity clarification of questions or answers answer reuse or caching knowledge representation and reasoning social media analysis with qa systems sentiment analysis 7 edit references dragomir r radev john prager and valerie samn ranking suspected answers to natural language questions using predictive annotation in proceedings of the 6th conference on applied natural language processing seattle wa may 2000 john prager eric brown anni coden and dragomir radev question answering by predictive annotation in proceedings 23rd annual international acm sigir conference on research and development in information retrieval athens greece july 2000 hirschman l amp gaizauskas r 2001 natural language question answering the view from here natural language engineering 2001 7 4 275 300 cambridge university press lin j 2002 the web as a resource for question answering perspectives and challenges in proceedings of the third international conference on language resources and evaluation lrec 2002 galitsky boris natural language question answering system technique of semantic headers advanced knowledge international australia 2003 burger j cardie c chaudhri v gaizauskas r harabagiu s israel d jacquemin c lin c y maiorano s miller g moldovan d ogden b prager j riloff e singhal a shrihari r strzalkowski t voorhees e weishedel r issues tasks and program structures to roadmap research in question answering qa perera r 2012 ipedagogy question answering system based on web information clustering maybury m t editor 2004 new directions in question answering aaai mit press bitcrawl by hobson lane edit external links question answering evaluation at ntcir question answering evaluation at trec question answering evaluation at clef v t e computable knowledge topics and concepts alphabet of human thought automated reasoning commonsense knowledge base commonsense reasoning computability formal system inference engine knowledge base knowledge based systems knowledge discovery knowledge engineering knowledge representation knowledge retrieval knowledge extraction logic programming ontology question answering semantic reasoner proposals and implementations zairja ars magna ramon llull 1300 an essay towards a real character and a philosophical language john wilkins 1688 calculus ratiocinator amp characteristica universalis gottfried leibniz 1700 dewey decimal classification melvil dewey 1876 begriffsschrift gottlob frege 1879 mundaneum paul otlet amp henri la fontaine 1910 logical atomism bertrand russell 1918 tractatus logico philosophicus ludwig wittgenstein 1921 hilbert s program david hilbert 1920s incompleteness theorem kurt g del 1931 memex vannevar bush 1945 prolog 1972 cyc 1984 true knowledge true knowledge ltd 2007 wolfram alpha wolfram research 2009 watson ibm 2011 siri apple 2011 knowledge graph google 2012 in fiction the engine gulliver s travels 1726 joe a logic named joe 1946 the librarian snow crash 1992 dr know a i artificial intelligence 2001 waterhouse the baroque cycle 2003 see also logic machines in fiction and list of fictional computers 