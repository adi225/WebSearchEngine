this see also section may contain an excessive number of suggestions please ensure that only the most relevant suggestions are given and that they are not red links and consider integrating suggestions into the article itself december 2012 search engine indexing collects parses and stores data to facilitate fast and accurate information retrieval index design incorporates interdisciplinary concepts from linguistics cognitive psychology mathematics informatics physics and computer science an alternate name for the process in the context of search engines designed to find web pages on the internet is web indexing popular engines focus on the full text indexing of online natural language documents 1 media types such as video and audio 2 and graphics 3 are also searchable meta search engines reuse the indices of other services and do not store a local index whereas cache based search engines permanently store the index along with the corpus unlike full text indices partial text services restrict the depth indexed to reduce index size larger services typically perform indexing at a predetermined time interval due to the required time and processing costs while agent based search engines index in real time contents 1 indexing 1 1 index design factors 1 2 index data structures 1 3 challenges in parallelism 1 4 inverted indices 1 5 index merging 1 6 the forward index 1 7 compression 2 document parsing 2 1 challenges in natural language processing 2 2 tokenization 2 3 language recognition 2 4 format analysis 2 5 section recognition 2 6 html priority system 2 7 meta tag indexing 3 see also 4 references 5 further reading edit indexing the purpose of storing an index is to optimize speed and performance in finding relevant documents for a search query without an index the search engine would scan every document in the corpus which would require considerable time and computing power for example while an index of 10 000 documents can be queried within milliseconds a sequential scan of every word in 10 000 large documents could take hours the additional computer storage required to store the index as well as the considerable increase in the time required for an update to take place are traded off for the time saved during information retrieval edit index design factors major factors in designing a search engine s architecture include merge factors 160 how data enters the index or how words or subject features are added to the index during text corpus traversal and whether multiple indexers can work asynchronously the indexer must first check whether it is updating old content or adding new content traversal typically correlates to the data collection policy search engine index merging is similar in concept to the sql merge command and other merge algorithms 4 storage techniques 160 how to store the index data that is whether information should be data compressed or filtered index size 160 how much computer storage is required to support the index lookup speed 160 how quickly a word can be found in the inverted index the speed of finding an entry in a data structure compared with how quickly it can be updated or removed is a central focus of computer science maintenance 160 how the index is maintained over time 5 fault tolerance 160 how important it is for the service to be reliable issues include dealing with index corruption determining whether bad data can be treated in isolation dealing with bad hardware partitioning and schemes such as hash based or composite partitioning 6 as well as replication edit index data structures search engine architectures vary in the way indexing is performed and in methods of index storage to meet the various design factors types of indices include suffix tree 160 figuratively structured like a tree supports linear time lookup built by storing the suffixes of words the suffix tree is a type of trie tries support extendable hashing which is important for search engine indexing 7 used for searching for patterns in dna sequences and clustering a major drawback is that storing a word in the tree may require space beyond that required to store the word itself 8 an alternate representation is a suffix array which is considered to require less virtual memory and supports data compression such as the bwt algorithm inverted index 160 stores a list of occurrences of each atomic search criterion 9 typically in the form of a hash table or binary tree 10 11 citation index 160 stores citations or hyperlinks between documents to support citation analysis a subject of bibliometrics ngram index 160 stores sequences of length of data to support other types of retrieval or text mining 12 document term matrix 160 used in latent semantic analysis stores the occurrences of words in documents in a two dimensional sparse matrix edit challenges in parallelism a major challenge in the design of search engines is the management of serial computing processes there are many opportunities for race conditions and coherent faults for example a new document is added to the corpus and the index must be updated but the index simultaneously needs to continue responding to search queries this is a collision between two competing tasks consider that authors are producers of information and a web crawler is the consumer of this information grabbing the text and storing it in a cache or corpus the forward index is the consumer of the information produced by the corpus and the inverted index is the consumer of information produced by the forward index this is commonly referred to as a producer consumer model the indexer is the producer of searchable information and users are the consumers that need to search the challenge is magnified when working with distributed storage and distributed processing in an effort to scale with larger amounts of indexed information the search engine s architecture may involve distributed computing where the search engine consists of several machines operating in unison this increases the possibilities for incoherency and makes it more difficult to maintain a fully synchronized distributed parallel architecture 13 edit inverted indices many search engines incorporate an inverted index when evaluating a search query to quickly locate documents containing the words in a query and then rank these documents by relevance because the inverted index stores a list of the documents containing each word the search engine can use direct access to find the documents associated with each word in the query in order to retrieve the matching documents quickly the following is a simplified illustration of an inverted index inverted index word documents the document 1 document 3 document 4 document 5 cow document 2 document 3 document 4 says document 5 moo document 7 this index can only determine whether a word exists within a particular document since it stores no information regarding the frequency and position of the word it is therefore considered to be a boolean index such an index determines which documents match a query but does not rank matched documents in some designs the index includes additional information such as the frequency of each word in each document or the positions of a word in each document 14 position information enables the search algorithm to identify word proximity to support searching for phrases frequency can be used to help in ranking the relevance of documents to the query such topics are the central research focus of information retrieval the inverted index is a sparse matrix since not all words are present in each document to reduce computer storage memory requirements it is stored differently from a two dimensional array the index is similar to the term document matrices employed by latent semantic analysis the inverted index can be considered a form of a hash table in some cases the index is a form of a binary tree which requires additional storage but may reduce the lookup time in larger indices the architecture is typically a distributed hash table 15 edit index merging the inverted index is filled via a merge or rebuild a rebuild is similar to a merge but first deletes the contents of the inverted index the architecture may be designed to support incremental indexing 16 17 where a merge identifies the document or documents to be added or updated and then parses each document into words for technical accuracy a merge conflates newly indexed documents typically residing in virtual memory with the index cache residing on one or more computer hard drives after parsing the indexer adds the referenced document to the document list for the appropriate words in a larger search engine the process of finding each word in the inverted index in order to report that it occurred within a document may be too time consuming and so this process is commonly split up into two parts the development of a forward index and a process which sorts the contents of the forward index into the inverted index the inverted index is so named because it is an inversion of the forward index edit the forward index the forward index stores a list of words for each document the following is a simplified form of the forward index forward index document words document 1 the cow says moo document 2 the cat and the hat document 3 the dish ran away with the spoon the rationale behind developing a forward index is that as documents are parsing it is better to immediately store the words per document the delineation enables asynchronous system processing which partially circumvents the inverted index update bottleneck 18 the forward index is sorted to transform it to an inverted index the forward index is essentially a list of pairs consisting of a document and a word collated by the document converting the forward index to an inverted index is only a matter of sorting the pairs by the words in this regard the inverted index is a word sorted forward index edit compression generating or maintaining a large scale search engine index represents a significant storage and processing challenge many search engines utilize a form of compression to reduce the size of the indices on disk 19 consider the following scenario for a full text internet search engine it takes 8 bits or 1 byte to store a single character some encodings use 2 bytes per character 20 21 the average number of characters in any given word on a page may be estimated at 5 wikipedia size comparisons given this scenario an uncompressed index assuming a non conflated simple index for 2 billion web pages would need to store 500 billion word entries at 1 byte per character or 5 bytes per word this would require 2500 gigabytes of storage space alone more than the average free disk space of 25 personal computers this space requirement may be even larger for a fault tolerant distributed storage architecture depending on the compression technique chosen the index can be reduced to a fraction of this size the tradeoff is the time and processing power required to perform compression and decompression notably large scale search engine designs incorporate the cost of storage as well as the costs of electricity to power the storage thus compression is a measure of cost edit document parsing document parsing breaks apart the components words of a document or other form of media for insertion into the forward and inverted indices the words found are called tokens and so in the context of search engine indexing and natural language processing parsing is more commonly referred to as tokenization it is also sometimes called word boundary disambiguation tagging text segmentation content analysis text analysis text mining concordance generation speech segmentation lexing or lexical analysis the terms indexing parsing and tokenization are used interchangeably in corporate slang natural language processing as of 2006 is the subject of continuous research and technological improvement tokenization presents many challenges in extracting the necessary information from documents for indexing to support quality searching tokenization for indexing involves multiple technologies the implementation of which are commonly kept as corporate secrets edit challenges in natural language processing word boundary ambiguity 160 native english speakers may at first consider tokenization to be a straightforward task but this is not the case with designing a multilingual indexer in digital form the texts of other languages such as chinese japanese or arabic represent a greater challenge as words are not clearly delineated by whitespace the goal during tokenization is to identify words for which users will search language specific logic is employed to properly identify the boundaries of words which is often the rationale for designing a parser for each language supported or for groups of languages with similar boundary markers and syntax language ambiguity 160 to assist with properly ranking matching documents many search engines collect additional information about each word such as its language or lexical category part of speech these techniques are language dependent as the syntax varies among languages documents do not always clearly identify the language of the document or represent it accurately in tokenizing the document some search engines attempt to automatically identify the language of the document diverse file formats 160 in order to correctly identify which bytes of a document represent characters the file format must be correctly handled search engines which support multiple file formats must be able to correctly open and access the document and be able to tokenize the characters of the document faulty storage 160 the quality of the natural language data may not always be perfect an unspecified number of documents particular on the internet do not closely obey proper file protocol binary characters may be mistakenly encoded into various parts of a document without recognition of these characters and appropriate handling the index quality or indexer performance could degrade edit tokenization unlike literate humans computers do not understand the structure of a natural language document and cannot automatically recognize words and sentences to a computer a document is only a sequence of bytes computers do not know that a space character separates words in a document instead humans must program the computer to identify what constitutes an individual or distinct word referred to as a token such a program is commonly called a tokenizer or parser or lexer many search engines as well as other natural language processing software incorporate specialized programs for parsing such as yacc or lex during tokenization the parser identifies sequences of characters which represent words and other elements such as punctuation which are represented by numeric codes some of which are non printing control characters the parser can also identify entities such as email addresses phone numbers and urls when identifying each token several characteristics may be stored such as the token s case upper lower mixed proper language or encoding lexical category part of speech like noun or verb position sentence number sentence position length and line number edit language recognition if the search engine supports multiple languages a common initial step during tokenization is to identify each document s language many of the subsequent steps are language dependent such as stemming and part of speech tagging language recognition is the process by which a computer program attempts to automatically identify or categorize the language of a document other names for language recognition include language classification language analysis language identification and language tagging automated language recognition is the subject of ongoing research in natural language processing finding which language the words belongs to may involve the use of a language recognition chart edit format analysis if the search engine supports multiple document formats documents must be prepared for tokenization the challenge is that many document formats contain formatting information in addition to textual content for example html documents contain html tags which specify formatting information such as new line starts bold emphasis and font size or style if the search engine were to ignore the difference between content and markup extraneous information would be included in the index leading to poor search results format analysis is the identification and handling of the formatting content embedded within documents which controls the way the document is rendered on a computer screen or interpreted by a software program format analysis is also referred to as structure analysis format parsing tag stripping format stripping text normalization text cleaning and text preparation the challenge of format analysis is further complicated by the intricacies of various file formats certain file formats are proprietary with very little information disclosed while others are well documented common well documented file formats that many search engines support include html ascii text files a text document without specific computer readable formatting adobe s portable document format pdf postscript ps latex usenet netnews server formats xml and derivatives like rss sgml multimedia meta data formats like id3 microsoft word microsoft excel microsoft powerpoint ibm lotus notes options for dealing with various formats include using a publicly available commercial parsing tool that is offered by the organization which developed maintains or owns the format and writing a custom parser some search engines support inspection of files that are stored in a compressed or encrypted file format when working with a compressed format the indexer first decompresses the document this step may result in one or more files each of which must be indexed separately commonly supported compressed file formats include zip zip archive file rar roshal archive file cab microsoft windows cabinet file gzip file compressed with gzip bzip file compressed using bzip2 tape archive tar unix archive file not itself compressed tar z tar gz or tar bz2 unix archive files compressed with compress gzip or bzip2 format analysis can involve quality improvement methods to avoid including bad information in the index content can manipulate the formatting information to include additional content examples of abusing document formatting for spamdexing including hundreds or thousands of words in a section which is hidden from view on the computer screen but visible to the indexer by use of formatting e g hidden div tag in html which may incorporate the use of css or javascript to do so setting the foreground font color of words to the same as the background color making words hidden on the computer screen to a person viewing the document but not hidden to the indexer edit section recognition some search engines incorporate section recognition the identification of major parts of a document prior to tokenization not all the documents in a corpus read like a well written book divided into organized chapters and pages many documents on the web such as newsletters and corporate reports contain erroneous content and side sections which do not contain primary material that which the document is about for example this article displays a side menu with links to other web pages some file formats like html or pdf allow for content to be displayed in columns even though the content is displayed or rendered in different areas of the view the raw markup content may store this information sequentially words that appear sequentially in the raw source content are indexed sequentially even though these sentences and paragraphs are rendered in different parts of the computer screen if search engines index this content as if it were normal content the quality of the index and search quality may be degraded due to the mixed content and improper word proximity two primary problems are noted content in different sections is treated as related in the index when in reality it is not organizational side bar content is included in the index but the side bar content does not contribute to the meaning of the document and the index is filled with a poor representation of its documents section analysis may require the search engine to implement the rendering logic of each document essentially an abstract representation of the actual document and then index the representation instead for example some content on the internet is rendered via javascript if the search engine does not render the page and evaluate the javascript within the page it would not see this content in the same way and would index the document incorrectly given that some search engines do not bother with rendering issues many web page designers avoid displaying content via javascript or use the noscript tag to ensure that the web page is indexed properly at the same time this fact can also be exploited to cause the search engine indexer to see different content than the viewer edit html priority system indexing often has to recognize the html tags to organize priority indexing low priority to high margin to labels like strong and link to optimize the order of priority if those labels are at the beginning of the text could not prove to be relevant some indexers like google and bing ensure that the search engine does not take the large texts as relevant source due to strong type system compatibility 22 edit meta tag indexing specific documents often contain embedded meta information such as author keywords description and language for html pages the meta tag contains keywords which are also included in the index earlier internet search engine technology would only index the keywords in the meta tags for the forward index the full document would not be parsed at that time full text indexing was not as well established nor was computer hardware able to support such technology the design of the html markup language initially included support for meta tags for the very purpose of being properly and easily indexed without requiring tokenization 23 as the internet grew through the 1990s many brick and mortar corporations went online and established corporate websites the keywords used to describe webpages many of which were corporate oriented webpages similar to product brochures changed from descriptive to marketing oriented keywords designed to drive sales by placing the webpage high in the search results for specific search queries the fact that these keywords were subjectively specified was leading to spamdexing which drove many search engines to adopt full text indexing technologies in the 1990s search engine designers and companies could only place so many marketing keywords into the content of a webpage before draining it of all interesting and useful information given that conflict of interest with the business goal of designing user oriented websites which were sticky the customer lifetime value equation was changed to incorporate more useful content into the website in hopes of retaining the visitor in this sense full text indexing was more objective and increased the quality of search engine results as it was one more step away from subjective control of search engine result placement which in turn furthered research of full text indexing technologies in desktop search many solutions incorporate meta tags to provide a way for authors to further customize how the search engine will index content from various files that is not evident from the file content desktop search is more under the control of the user while internet search engines must focus more on the full text index edit see also compound term processing concordance content analysis controlled vocabulary desktop search documentation document retrieval index database information extraction information retrieval keyword in context indexing latent semantic indexing list of search engines natural language processing search engine selection based search semantic web site map text mining text retrieval vertical search web crawler web indexing website parse template windows indexing service 24 edit references clarke c cormack g dynamic inverted indexes for a distributed full text retrieval system techrep mt 95 01 university of waterloo february 1995 www ee columbia edu dpwe papers wang03 shazam pdf charles e jacobs adam finkelstein david h salesin fast multiresolution image querying department of computer science and engineering university of washington 1995 verified dec 2006 brown e w execution performance issues in full text information retrieval computer science department university of massachusetts amherst technical report 95 81 october 1995 cutting d pedersen j optimizations for dynamic inverted index maintenance proceedings of sigir 405 411 1990 linear hash partitioning mysql 5 1 reference manual verified dec 2006 trie dictionary of algorithms and data structures u s national institute of standards and technology gusfield dan 1999 1997 algorithms on strings trees and sequences computer science and computational biology usa cambridge university press isbn 160 0 521 58519 8 black paul e inverted index dictionary of algorithms and data structures u s national institute of standards and technology oct 2006 verified dec 2006 c c foster information retrieval information storage and retrieval using avl trees proceedings of the 1965 20th national conference p 192 205 august 24 26 1965 cleveland ohio united states landauer w i the balanced tree and its utilization in information retrieval ieee trans on electronic computers vol ec 12 no 6 december 1963 google ngram datasets for sale at ldc catalog jeffrey dean and sanjay ghemawat mapreduce simplified data processing on large clusters google inc osdi 2004 grossman frieder goharian ir basics of inverted index 2002 verified aug 2011 tang hunqiang dwarkadas sandhya hybrid global local indexing for efficient peer to peer information retrieval university of rochester pg 1 http www cs rochester edu u sandhya papers nsdi04 ps tomasic a et al incremental updates of inverted lists for text document retrieval short version of stanford university computer science technical note stan cs tn 93 1 december 1993 luk r w p and w lam 2007 efficient in memory extensible inverted file information systems 32 5 733 754 doi 10 1016 j is 2006 06 001 sergey brin and lawrence page the anatomy of a large scale hypertextual web search engine stanford university 1998 verified dec 2006 h s heaps storage analysis of a compression coding for a document database 1nfor i0 i 47 61 february 1972 the unicode standard frequently asked questions verified dec 2006 storage estimates verified dec 2006 google webmaster tools hypertext markup language 5 conference for seo january 2012 berners lee t hypertext markup language 2 0 rfc 1866 network working group november 1995 krishna nareddy indexing with microsoft index server msdn library microsoft corporation january 30 1998 verified dec 2006 note that this is a commercial external link edit further reading r bayer and e mccreight organization and maintenance of large ordered indices acta informatica 173 189 1972 donald e knuth the art of computer programming volume 1 3rd ed fundamental algorithms addison wesley longman publishing co redwood city ca 1997 donald e knuth the art of computer programming volume 3 2nd ed sorting and searching addison wesley longman publishing co redwood city ca 1998 gerald salton automatic text processing addison wesley longman publishing co inc boston ma 1988 gerard salton michael j mcgill introduction to modern information retrieval mcgraw hill inc new york ny 1986 gerard salton lesk m e computer evaluation of indexing and text processing journal of the acm january 1968 gerard salton the smart retrieval system experiments in automatic document processing prentice hall inc englewood cliffs 1971 gerard salton the transformation analysis and retrieval of information by computer addison wesley reading mass 1989 baeza yates r ribeiro neto b modern information retrieval chapter 8 acm press 1999 g k zipf human behavior and the principle of least effort addison wesley 1949 adelson velskii g m landis e m an information organization algorithm dansssr 146 263 266 1962 edward h sussenguth jr use of tree structures for processing files communications of the acm v 6 n 5 p 160 272 279 may 1963 harman d k et al inverted files in information retrieval data structures and algorithms prentice hall pp 28 43 1992 lim l et al characterizing web document change lncs 2118 133 146 2001 lim l et al dynamic maintenance of web indexes using landmarks proc of the 12th w3 conference 2003 moffat a zobel j self indexing inverted files for fast text retrieval acm tis 349 379 october 1996 volume 14 number 4 mehlhorn k data structures and efficient algorithms springer verlag eatcs monographs 1984 mehlhorn k overmars m h optimal dynamization of decomposable searching problems ipl 12 93 98 1981 mehlhorn k lower bounds on the efficiency of transforming static data structures into dynamic data structures math systems theory 15 1 16 1981 koster m aliweb archie like indexing in the web computer networks and isdn systems vol 27 no 2 1994 175 182 also see proc first int l world wide web conf elsevier science amsterdam 1994 pp 160 175 182 serge abiteboul and victor vianu queries and computation on the web proceedings of the international conference on database theory delphi greece 1997 ian h witten alistair moffat and timothy c bell managing gigabytes compressing and indexing documents and images new york van nostrand reinhold 1994 a emtage and p deutsch archie an electronic directory service for the internet proc usenix winter 1992 tech conf usenix assoc berkeley calif 1992 pp 160 93 110 m gray world wide web wanderer d cutting and j pedersen optimizations for dynamic inverted index maintenance proceedings of the 13th international conference on research and development in information retrieval pp 160 405 411 september 1990 stefan b ttcher charles l a clarke and gordon v cormack information retrieval implementing and evaluating search engines mit press cambridge mass 2010 v t e internet search types web search engine list collaborative search engine metasearch engine tools local search vertical search search engine marketing search engine optimization search oriented architecture selection based search social search document retrieval text mining web crawler multisearch federated search search aggregator index web indexing focused crawler spider trap robots exclusion standard distributed web crawling web archiving website mirroring software web search query voice search natural language search engine web query classification applications image search video search engine enterprise search semantic search protocols and standards z39 50 search retrieve web service search retrieve via url opensearch representational state transfer website parse template wide area information server see also search engine desktop search online search 