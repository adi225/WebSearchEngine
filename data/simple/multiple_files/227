a focused crawler or topical crawler is a web crawler that attempts to download only web pages that are relevant to a pre defined topic or set of topics topical crawling generally assumes that only the topic is given while focused crawling also assumes that some labeled examples of relevant and not relevant pages are available topical crawling was first introduced by menczer 1 2 edit strategies a focused crawler ideally would like to download only web pages that are relevant to a particular topic and avoid downloading all others therefore a focused crawler may predict the probability that a link to a particular page is relevant before actually downloading the page a possible predictor is the anchor text of links this was the approach taken by pinkerton 3 in a crawler developed in the early days of the web in a review of topical crawling algorithms menczer et al 4 show that such simple strategies are very effective for short crawls while more sophisticated techniques such as reinforcement learning and evolutionary adaptation can give the best performance over longer crawls diligenti et al 5 propose to use the complete content of the pages already visited to infer the similarity between the driving query and the pages that have not been visited yet in another approach the relevance of a page is determined after downloading its content relevant pages are sent to content indexing and their contained urls are added to the crawl frontier pages that fall below a relevance threshold are discarded the performance of a focused crawler depends mostly on the richness of links in the specific topic being searched and focused crawling usually relies on a general web search engine for providing starting points seeds selection can be important for focused crawlers and significantly influence the crawling efficiency 6 a whitelist strategy is to start the focus crawl from a list of high quality seed urls and limit the crawling scope to the domains of these urls these high quality seeds should be selected based on a list of url candidates which are accumulated over a sufficient long period of general web crawling the whitelist should be updated periodically after it is created edit references menczer f 1997 arachnid adaptive retrieval agents choosing heuristic neighborhoods for information discovery in d fisher ed proceedings of the 14th international conference on machine learning icml97 morgan kaufmann menczer f and belew r k 1998 adaptive information agents in distributed textual environments in k sycara and m wooldridge eds proceedings of the 2nd international conference on autonomous agents agents 98 acm press pinkerton b 1994 finding what people want experiences with the webcrawler in proceedings of the first world wide web conference geneva switzerland menczer f pant g and srinivasan p 2004 topical web crawlers evaluating adaptive algorithms acm trans on internet technology 4 4 378 419 diligenti m coetzee f lawrence s giles c l and gori m 2000 focused crawling using context graphs in proceedings of the 26th international conference on very large databases vldb pages 527 534 cairo egypt jian wu pradeep teregowda juan pablo fern ndez ram rez prasenjit mitra shuyi zheng c lee giles the evolution of a crawling strategy for an academic document search engine whitelists and blacklists in proceedings of the 3rd annual acm web science conference pages 340 343 evanston il usa june 2012 edit see also v t e internet search types web search engine list collaborative search engine metasearch engine tools local search vertical search search engine marketing search engine optimization search oriented architecture selection based search social search document retrieval text mining web crawler multisearch federated search search aggregator index web indexing focused crawler spider trap robots exclusion standard distributed web crawling web archiving website mirroring software web search query voice search natural language search engine web query classification applications image search video search engine enterprise search semantic search protocols and standards z39 50 search retrieve web service search retrieve via url opensearch representational state transfer website parse template wide area information server see also search engine desktop search online search 