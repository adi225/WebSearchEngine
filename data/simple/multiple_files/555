see also pattern recognition see also classification test in machine learning and statistics classification is the problem of identifying to which of a set of categories sub populations a new observation belongs on the basis of a training set of data containing observations or instances whose category membership is known the individual observations are analyzed into a set of quantifiable properties known as various explanatory variables features etc these properties may variously be categorical e g a b ab or o for blood type ordinal e g large medium or small integer valued e g the number of occurrences of a part word in an email or real valued e g a measurement of blood pressure some algorithms work only in terms of discrete data and require that real valued or integer valued data be discretized into groups e g less than 5 between 5 and 10 or greater than 10 an example would be assigning a given email into spam or non spam classes or assigning a diagnosis to a given patient as described by observed characteristics of the patient gender blood pressure presence or absence of certain symptoms etc an algorithm that implements classification especially in a concrete implementation is known as a classifier the term classifier sometimes also refers to the mathematical function implemented by a classification algorithm that maps input data to a category in the terminology of machine learning classification is considered an instance of supervised learning i e learning where a training set of correctly identified observations is available the corresponding unsupervised procedure is known as clustering or cluster analysis and involves grouping data into categories based on some measure of inherent similarity e g the distance between instances considered as vectors in a multi dimensional vector space terminology across fields is quite varied in statistics where classification is often done with logistic regression or a similar procedure the properties of observations are termed explanatory variables or independent variables regressors etc and the categories to be predicted are known as outcomes which are considered to be possible values of the dependent variable in machine learning the observations are often known as instances the explanatory variables are termed features grouped into a feature vector and the possible categories to be predicted are classes there is also some argument over whether classification methods that do not involve a statistical model can be considered statistical other fields may use different terminology e g in community ecology the term classification normally refers to cluster analysis i e a type of unsupervised learning rather than the supervised learning described in this article contents 1 relation to other problems 2 frequentist procedures 3 bayesian procedures 4 binary and multiclass classification 5 feature vectors 6 linear classifiers 7 algorithms 8 evaluation 9 application domains 10 see also 11 references 12 external links edit relation to other problems classification and clustering are examples of the more general problem of pattern recognition which is the assignment of some sort of output value to a given input value other examples are regression which assigns a real valued output to each input sequence labeling which assigns a class to each member of a sequence of values for example part of speech tagging which assigns a part of speech to each word in an input sentence parsing which assigns a parse tree to an input sentence describing the syntactic structure of the sentence etc a common subclass of classification is probabilistic classification algorithms of this nature use statistical inference to find the best class for a given instance unlike other algorithms which simply output a best class probabilistic algorithms output a probability of the instance being a member of each of the possible classes the best class is normally then selected as the one with the highest probability however such an algorithm has numerous advantages over non probabilistic classifiers it can output a confidence value associated with its choice in general a classifier that can do this is known as a confidence weighted classifier correspondingly it can abstain when its confidence of choosing any particular output is too low because of the probabilities output probabilistic classifiers can be more effectively incorporated into larger machine learning tasks in a way that partially or completely avoids the problem of error propagation edit frequentist procedures early work on statistical classification was undertaken by fisher 1 2 in the context of two group problems leading to fisher s linear discriminant function as the rule for assigning a group to a new observation 3 this early work assumed that data values within each of the two groups had a multivariate normal distribution the extension of this same context to more than two groups has also been considered with a restriction imposed that the classification rule should be linear 3 4 later work for the multivariate normal distribution allowed the classifier to be nonlinear 5 several classification rules can be derived based on slight different adjustments of the mahalanobis distance with a new observation being assigned to the group whose centre has the lowest adjusted distance from the observation edit bayesian procedures unlike frequentist procedures bayesian classification procedures provide a natural way of taking into account any available information about the relative sizes of the sub populations associated with the different groups within the overall population 6 bayesian procedures tend to be computationally expensive and in the days before markov chain monte carlo computations were developed approximations for bayesian clustering rules were devised 7 some bayesian procedures involve the calculation of group membership probabilities these can be viewed as providing a more informative outcome of a data analysis than a simple attribution of a single group label to each new observation edit binary and multiclass classification classification can be thought of as two separate problems binary classification and multiclass classification in binary classification a better understood task only two classes are involved whereas multiclass classification involves assigning an object to one of several classes 8 since many classification methods have been developed specifically for binary classification multiclass classification often requires the combined use of multiple binary classifiers edit feature vectors most algorithms describe an individual instance whose category is to be predicted using a feature vector of individual measurable properties of the instance each property is termed a feature also known in statistics as an explanatory variable or independent variable although in general different features may or may not be statistically independent features may variously be binary male or female categorical e g a b ab or o for blood type ordinal e g large medium or small integer valued e g the number of occurrences of a particular word in an email or real valued e g a measurement of blood pressure if the instance is an image the feature values might correspond to the pixels of an image if the instance is a piece of text the feature values might be occurrence frequencies of different words some algorithms work only in terms of discrete data and require that real valued or integer valued data be discretized into groups e g less than 5 between 5 and 10 or greater than 10 the vector space associated with these vectors is often called the feature space in order to reduce the dimensionality of the feature space a number of dimensionality reduction techniques can be employed edit linear classifiers a large number of algorithms for classification can be phrased in terms of a linear function that assigns a score to each possible category k by combining the feature vector of an instance with a vector of weights using a dot product the predicted category is the one with the highest score this type of score function is known as a linear predictor function and has the following general form where x i is the feature vector for instance i k is the vector of weights corresponding to category k and score x i k is the score associated with assigning instance i to category k in discrete choice theory where instances represent people and categories represent choices the score is considered the utility associated with person i choosing category k algorithms with this basic setup are known as linear classifiers what distinguishes them is the procedure for determining training the optimal weights coefficients and the way that the score is interpreted examples of such algorithms logistic regression and multinomial logit probit regression the perceptron algorithm support vector machines linear discriminant analysis edit algorithms this article is in a list format that may be better presented using prose you can help by converting this article to prose if appropriate editing help is available may 2012 the most widely used classifiers are the neural network multi layer perceptron support vector machines k nearest neighbours gaussian mixture model gaussian naive bayes decision tree and rbf classifiers citation needed examples of classification algorithms include linear classifiers fisher s linear discriminant logistic regression naive bayes classifier perceptron support vector machines least squares support vector machines quadratic classifiers kernel estimation k nearest neighbor boosting meta algorithm decision trees random forests neural networks gene expression programming bayesian networks hidden markov models learning vector quantization proaftn edit evaluation classifier performance depends greatly on the characteristics of the data to be classified there is no single classifier that works best on all given problems a phenomenon that may be explained by the no free lunch theorem various empirical tests have been performed to compare classifier performance and to find the characteristics of data that determine classifier performance determining a suitable classifier for a given problem is however still more an art than a science the measures precision and recall are popular metrics used to evaluate the quality of a classification system more recently receiver operating characteristic roc curves have been used to evaluate the tradeoff between true and false positive rates of classification algorithms as a performance metric the uncertainty coefficient has the advantage over simple accuracy in that it is not affected by the relative sizes of the different classes 9 further it will not penalize an algorithm for simply rearranging the classes edit application domains classification problems has many applications in some of these it is employed as a data mining procedure while in others more detailed statistical modeling is undertaken computer vision medical imaging and medical image analysis optical character recognition video tracking drug discovery and development toxicogenomics quantitative structure activity relationship geostatistics speech recognition handwriting recognition biometric identification biological classification statistical natural language processing document classification internet search engines credit scoring pattern recognition this article includes a list of references but its sources remain unclear because it has insufficient inline citations please help to improve this article by introducing more precise citations january 2010 edit see also class membership probabilities classification test compound term processing data mining fuzzy logic data warehouse information retrieval artificial intelligence machine learning pattern recognition edit references fisher r a 1936 the use of multiple measurements in taxonomic problems annals of eugenics 7 179 188 fisher r a 1938 the statistical utilization of multiple measurements annals of eugenics 8 376 386 a b gnanadesikan r 1977 methods for statistical data analysis of multivariate observations wiley isbn 0 471 30845 5 p 83 86 rao c r 1952 advanced statistical methods in multivariate analysis wiley section 9c anderson t w 1958 an introduction to multivariate statistical analysis wiley binder d a 1978 bayesian cluster analysis biometrika 65 31 38 binder d a 1981 approximations to bayesian clustering rules biometrika 68 275 285 har peled s roth d zimak d 2003 constraint classification for multiclass classification and ranking in becker b thrun s obermayer k eds advances in neural information processing systems 15 proceedings of the 2002 conference mit press isbn 0 262 02550 7 peter mills 2011 efficient statistical classification of satellite measurements international journal of remote sensing doi 10 1080 01431161 2010 507795 edit external links classifier showdown a practical comparison of classification algorithms statistical pattern recognition toolbox for matlab tooldiag pattern recognition toolbox statistical classification software based on adaptive kernel density estimation pal classification suite written in java knn and potential energy applet university of leicester v t e statistics 160 descriptive statistics continuous data location mean arithmetic geometric harmonic median mode dispersion range standard deviation coefficient of variation percentile interquartile range shape variance skewness kurtosis moments l moments count data index of dispersion summary tables grouped data frequency distribution contingency table dependence pearson product moment correlation rank correlation spearman s rho kendall s tau partial correlation scatter plot statistical graphics bar chart biplot box plot control chart correlogram forest plot histogram q q plot run chart scatter plot stemplot radar chart 160 data collection designing studies effect size standard error statistical power sample size determination survey methodology sampling stratified sampling opinion poll questionnaire controlled experiment design of experiments randomized experiment random assignment replication blocking factorial experiment optimal design uncontrolled studies natural experiment quasi experiment observational study 160 statistical inference statistical theory sampling distribution sufficient statistic meta analysis bayesian inference bayesian probability prior posterior credible interval bayes factor bayesian estimator maximum posterior estimator frequentist inference confidence interval hypothesis testing likelihood ratio specific tests z test normal student s t test f test chi squared test wald test mann whitney u shapiro wilk signed rank kolmogorov smirnov test general estimation bias robustness efficiency maximum likelihood method of moments minimum distance density estimation 160 correlation and regression analysis correlation pearson product moment correlation partial correlation confounding variable coefficient of determination regression analysis errors and residuals regression model validation mixed effects models simultaneous equations models linear regression simple linear regression ordinary least squares general linear model bayesian regression non standard predictors nonlinear regression nonparametric semiparametric isotonic robust generalized linear model exponential families logistic bernoulli binomial poisson partition of variance analysis of variance anova analysis of covariance multivariate anova degrees of freedom 160 categorical multivariate time series or survival analysis categorical data cohen s kappa contingency table graphical model log linear model mcnemar s test multivariate statistics multivariate regression principal components factor analysis cluster analysis classification copulas time series analysis general decomposition trend stationarity seasonal adjustment time domain acf pacf xcf arma model arima model vector autoregression frequency domain spectral density estimation survival analysis survival function kaplan meier logrank test failure rate proportional hazards models accelerated failure time model 160 applications biostatistics bioinformatics biometrics clinical trials amp studies epidemiology medical statistics engineering statistics chemometrics methods engineering probabilistic design process amp quality control reliability system identification social statistics actuarial science census crime statistics demography econometrics national accounts official statistics population psychometrics spatial statistics cartography environmental statistics geographic information system geostatistics kriging category portal outline index 