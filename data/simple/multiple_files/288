information science general aspects information access 160 information architecture information management information retrieval information seeking 160 information society knowledge organization 160 ontology philosophy of information science technology and society related fields and sub fields bibliometrics 160 categorization censorship 160 classification computer data storage 160 cultural studies data modeling 160 informatics information technology intellectual freedom intellectual property 160 memory library and information science preservation 160 privacy portal v t e information retrieval is the activity of obtaining information resources relevant to an information need from a collection of information resources searches can be based on metadata or on full text indexing automated information retrieval systems are used to reduce what has been called information overload many universities and public libraries use ir systems to provide access to books journals and other documents web search engines are the most visible ir applications contents 1 history 1 1 timeline 2 overview 3 performance and correctness measures 3 1 precision 3 2 recall 3 3 fall out 3 4 f measure 3 5 average precision 3 6 r precision 3 7 mean average precision 3 8 discounted cumulative gain 3 9 other measures 4 model types 4 1 first dimension mathematical basis 4 2 second dimension properties of the model 5 awards in the field 6 see also 7 references 8 external links edit history but do you know that although i have kept the diary on a phonograph for months past it never once struck me how i was going to find any particular part of it in case i wanted to look it up dr seward bram stoker s dracula 1897 the idea of using computers to search for relevant pieces of information was popularized in the article as we may think by vannevar bush in 1945 1 the first automated information retrieval systems were introduced in the 1950s and 1960s by 1970 several different techniques had been shown to perform well on small text corpora such as the cranfield collection several thousand documents 1 large scale retrieval systems such as the lockheed dialog system came into use early in the 1970s in 1992 the us department of defense along with the national institute of standards and technology nist cosponsored the text retrieval conference trec as part of the tipster text program the aim of this was to look into the information retrieval community by supplying the infrastructure that was needed for evaluation of text retrieval methodologies on a very large text collection this catalyzed research on methods that scale to huge corpora the introduction of web search engines has boosted the need for very large scale retrieval systems even further the use of digital methods for storing and retrieving information has led to the phenomenon of digital obsolescence where a digital resource ceases to be readable because the physical media the reader required to read the media the hardware or the software that runs on it is no longer available the information is initially easier to retrieve than if it were on paper but is then effectively lost edit timeline before the 1900s 1801 joseph marie jacquard invents the jacquard loom the first machine to use punched cards to control a sequence of operations 1880s herman hollerith invents an electro mechanical data tabulator using punch cards as a machine readable medium 1890 hollerith cards keypunches and tabulators used to process the 1890 us census data 1920s 1930s emanuel goldberg submits patents for his statistical machine a document search engine that used photoelectric cells and pattern recognition to search the metadata on rolls of microfilmed documents 1940s 1950s late 1940s the us military confronted problems of indexing and retrieval of wartime scientific research documents captured from germans 1945 vannevar bush s as we may think appeared in atlantic monthly 1947 hans peter luhn research engineer at ibm since 1941 began work on a mechanized punch card based system for searching chemical compounds 1950s growing concern in the us for a science gap with the ussr motivated encouraged funding and provided a backdrop for mechanized literature searching systems allen kent et al and the invention of citation indexing eugene garfield 1950 the term information retrieval appears to have been coined by calvin mooers 2 1951 philip bagley conducted the earliest experiment in computerized document retrieval in a master thesis at mit 3 1955 allen kent joined case western reserve university and eventually became associate director of the center for documentation and communications research that same year kent and colleagues published a paper in american documentation describing the precision and recall measures as well as detailing a proposed framework for evaluating an ir system which included statistical sampling methods for determining the number of relevant documents not retrieved 1958 international conference on scientific information washington dc included consideration of ir systems as a solution to problems identified see proceedings of the international conference on scientific information 1958 national academy of sciences washington dc 1959 1959 hans peter luhn published auto encoding of documents for information retrieval 1960s early 1960s gerard salton began work on ir at harvard later moved to cornell 1960 melvin earl bill maron and john lary kuhns 4 published on relevance probabilistic indexing and information retrieval in the journal of the acm 7 3 216 244 july 1960 1962 cyril w cleverdon published early findings of the cranfield studies developing a model for ir system evaluation see cyril w cleverdon report on the testing and analysis of an investigation into the comparative efficiency of indexing systems cranfield collection of aeronautics cranfield england 1962 kent published information analysis and retrieval 1963 weinberg report science government and information gave a full articulation of the idea of a crisis of scientific information the report was named after dr alvin weinberg joseph becker and robert m hayes published text on information retrieval becker joseph hayes robert mayo information storage and retrieval tools elements theories new york wiley 1963 1964 karen sp rck jones finished her thesis at cambridge synonymy and semantic classification and continued work on computational linguistics as it applies to ir the national bureau of standards sponsored a symposium titled statistical association methods for mechanized documentation several highly significant papers including g salton s first published reference we believe to the smart system mid 1960s national library of medicine developed medlars medical literature analysis and retrieval system the first major machine readable database and batch retrieval system project intrex at mit 1965 j c r licklider published libraries of the future 1966 don swanson was involved in studies at university of chicago on requirements for future catalogs late 1960s f wilfrid lancaster completed evaluation studies of the medlars system and published the first edition of his text on information retrieval 1968 gerard salton published automatic information organization and retrieval john w sammon jr s radc tech report some mathematics of information storage and retrieval outlined the vector model 1969 sammon s a nonlinear mapping for data structure analysis ieee transactions on computers was the first proposal for visualization interface to an ir system 1970s early 1970s first online systems nlm s aim twx medline lockheed s dialog sdc s orbit theodor nelson promoting concept of hypertext published computer lib dream machines 1971 nicholas jardine and cornelis j van rijsbergen published the use of hierarchic clustering in information retrieval which articulated the cluster hypothesis information storage and retrieval 7 5 pp 160 217 240 december 1971 1975 three highly influential publications by salton fully articulated his vector processing framework and term discrimination model a theory of indexing society for industrial and applied mathematics a theory of term importance in automatic text analysis jasis v 26 a vector space model for automatic indexing cacm 18 11 1978 the first acm sigir conference 1979 c j van rijsbergen published information retrieval butterworths heavy emphasis on probabilistic models 1980s 1980 first international acm sigir conference joint with british computer society ir group in cambridge 1982 nicholas j belkin robert n oddy and helen m brooks proposed the ask anomalous state of knowledge viewpoint for information retrieval this was an important concept though their automated analysis tool proved ultimately disappointing 1983 salton and michael j mcgill published introduction to modern information retrieval mcgraw hill with heavy emphasis on vector models 1985 blair and maron publish an evaluation of retrieval effectiveness for a full text document retrieval system mid 1980s efforts to develop end user versions of commercial ir systems 1985 1993 key papers on and experimental systems for visualization interfaces work by donald b crouch robert r korfhage matthew chalmers anselm spoerri and others 1989 first world wide web proposals by tim berners lee at cern 1990s 1992 first trec conference 1997 publication of korfhage s information storage and retrieval 5 with emphasis on visualization and multi reference point systems late 1990s web search engines implementation of many features formerly found only in experimental ir systems search engines become the most common and maybe best instantiation of ir models research and implementation edit overview an information retrieval process begins when a user enters a query into the system queries are formal statements of information needs for example search strings in web search engines in information retrieval a query does not uniquely identify a single object in the collection instead several objects may match the query perhaps with different degrees of relevancy an object is an entity that is represented by information in a database user queries are matched against the database information depending on the application the data objects may be for example text documents images 6 audio 7 mind maps 8 or videos often the documents themselves are not kept or stored directly in the ir system but are instead represented in the system by document surrogates or metadata most ir systems compute a numeric score on how well each object in the database matches the query and rank the objects according to this value the top ranking objects are then shown to the user the process may then be iterated if the user wishes to refine the query 9 edit performance and correctness measures main article precision and recall many different measures for evaluating the performance of information retrieval systems have been proposed the measures require a collection of documents and a query all common measures described here assume a ground truth notion of relevancy every document is known to be either relevant or non relevant to a particular query in practice queries may be ill posed and there may be different shades of relevancy edit precision precision is the fraction of the documents retrieved that are relevant to the user s information need in binary classification precision is analogous to positive predictive value precision takes all retrieved documents into account it can also be evaluated at a given cut off rank considering only the topmost results returned by the system this measure is called precision at n or p n note that the meaning and usage of precision in the field of information retrieval differs from the definition of accuracy and precision within other branches of science and technology edit recall recall is the fraction of the documents that are relevant to the query that are successfully retrieved in binary classification recall is often called sensitivity so it can be looked at as the probability that a relevant document is retrieved by the query it is trivial to achieve recall of 100 by returning all documents in response to any query therefore recall alone is not enough but one needs to measure the number of non relevant documents also for example by computing the precision edit fall out the proportion of non relevant documents that are retrieved out of all non relevant documents available in binary classification fall out is closely related to specificity and is equal to it can be looked at as the probability that a non relevant document is retrieved by the query it is trivial to achieve fall out of 0 by returning zero documents in response to any query edit f measure main article f score the weighted harmonic mean of precision and recall the traditional f measure or balanced f score is this is also known as the measure because recall and precision are evenly weighted the general formula for non negative real is two other commonly used f measures are the measure which weights recall twice as much as precision and the measure which weights precision twice as much as recall the f measure was derived by van rijsbergen 1979 so that measures the effectiveness of retrieval with respect to a user who attaches times as much importance to recall as precision it is based on van rijsbergen s effectiveness measure their relationship is where edit average precision precision and recall are single value metrics based on the whole list of documents returned by the system for systems that return a ranked sequence of documents it is desirable to also consider the order in which the returned documents are presented by computing a precision and recall at every position in the ranked sequence of documents one can plot a precision recall curve plotting precision as a function of recall average precision computes the average value of over the interval from to 10 this integral is in practice replaced with a finite sum over every position in the ranked sequence of documents where is the rank in the sequence of retrieved documents is the number of retrieved documents is the precision at cut off in the list and is the change in recall from items to 10 this finite sum is equivalent to where is an indicator function equaling 1 if the item at rank is a relevant document zero otherwise 11 note that the average is over all relevant documents and the relevant documents not retrieved get a precision score of zero some authors choose to interpolate the function to reduce the impact of wiggles in the curve 12 13 for example the pascal visual object classes challenge a benchmark for computer vision object detection computes average precision by averaging the precision over a set of evenly spaced recall levels 0 0 1 0 2 1 0 12 13 where is an interpolated precision that takes the maximum precision over all recalls greater than an alternative is to derive an analytical function by assuming a particular parametric distribution for the underlying decision values for example a binormal precision recall curve can be obtained by assuming decision values in both classes to follow a gaussian distribution 14 average precision is also sometimes referred to geometrically as the area under the precision recall curve citation needed edit r precision precision at r th position in the ranking of results for a query that has r relevant documents this measure is highly correlated to average precision also precision is equal to recall at the r th position edit mean average precision mean average precision for a set of queries is the mean of the average precision scores for each query where q is the number of queries edit discounted cumulative gain main article discounted cumulative gain dcg uses a graded relevance scale of documents from the result set to evaluate the usefulness or gain of a document based on its position in the result list the premise of dcg is that highly relevant documents appearing lower in a search result list should be penalized as the graded relevance value is reduced logarithmically proportional to the position of the result the dcg accumulated at a particular rank position is defined as since result set may vary in size among different queries or systems to compare performances the normalised version of dcg uses an ideal dcg to this end it sorts documents of a result list by relevance producing an ideal dcg at position p which normalizes the score the ndcg values for all queries can be averaged to obtain a measure of the average performance of a ranking algorithm note that in a perfect ranking algorithm the will be the same as the producing an ndcg of 1 0 all ndcg calculations are then relative values on the interval 0 0 to 1 0 and so are cross query comparable edit other measures mean reciprocal rank spearman s rank correlation coefficient edit model types categorization of ir models translated from german entry original source dominik kuropka for effectively retrieving relevant documents by ir strategies the documents are typically transformed into a suitable representation each retrieval strategy incorporate a specific model for its document representation purposes the picture on the right illustrates the relationship of some common models in the picture the models are categorized according to two dimensions the mathematical basis and the properties of the model edit first dimension mathematical basis set theoretic models represent documents as sets of words or phrases similarities are usually derived from set theoretic operations on those sets common models are standard boolean model extended boolean model fuzzy retrieval algebraic models represent documents and queries usually as vectors matrices or tuples the similarity of the query vector and document vector is represented as a scalar value vector space model generalized vector space model enhanced topic based vector space model extended boolean model latent semantic indexing aka latent semantic analysis probabilistic models treat the process of document retrieval as a probabilistic inference similarities are computed as probabilities that a document is relevant for a given query probabilistic theorems like the bayes theorem are often used in these models binary independence model probabilistic relevance model on which is based the okapi bm25 relevance function uncertain inference language models divergence from randomness model latent dirichlet allocation feature based retrieval models view documents as vectors of values of feature functions or just features and seek the best way to combine these features into a single relevance score typically by learning to rank methods feature functions are arbitrary functions of document and query and as such can easily incorporate almost any other retrieval model as just a yet another feature edit second dimension properties of the model models without term interdependencies treat different terms words as independent this fact is usually represented in vector space models by the orthogonality assumption of term vectors or in probabilistic models by an independency assumption for term variables models with immanent term interdependencies allow a representation of interdependencies between terms however the degree of the interdependency between two terms is defined by the model itself it is usually directly or indirectly derived e g by dimensional reduction from the co occurrence of those terms in the whole set of documents models with transcendent term interdependencies allow a representation of interdependencies between terms but they do not allege how the interdependency between two terms is defined they relay an external source for the degree of interdependency between two terms for example a human or sophisticated algorithms edit awards in the field tony kent strix award gerard salton award edit see also adversarial information retrieval collaborative information seeking controlled vocabulary cross language information retrieval data mining european summer school in information retrieval human computer information retrieval information extraction information retrieval facility knowledge visualization multimedia information retrieval list of information retrieval libraries personal information management relevance information retrieval relevance feedback rocchio classification search index social information seeking special interest group on information retrieval subject indexing temporal information retrieval tf idf xml retrieval edit references a b singhal amit 2001 modern information retrieval a brief overview bulletin of the ieee computer society technical committee on data engineering 24 4 35 43 http singhal info ieee2001 pdf mooers calvin n theory digital handling non numerical information zator technical bulletin no 48 5 cited in information n oed online december 2011 oxford university press doyle lauren becker joseph 1975 information retrieval and processing melville pp 160 410 pp isbn 160 0 471 22151 1 maron melvin e 2008 an historical note on the origins of probabilistic indexing information processing and management 44 2 971 972 doi 10 1016 j ipm 2007 02 012 http yunus hacettepe edu tr tonta courses spring2008 bby703 maron on probabilistic 20indexing 2008 pdf korfhage robert r 1997 information storage and retrieval wiley pp 160 368 pp isbn 160 978 0 471 14338 3 http www wiley com wileycda wileytitle productcd 0471143383 desccd authorinfo html goodrum abby a 2000 image information retrieval an overview of current research informing science 3 2 foote jonathan 1999 an overview of audio information retrieval multimedia systems springer beel j ran gipp bela stiller jan olaf 2009 information retrieval on mind maps what could it be good for proceedings of the 5th international conference on collaborative computing networking applications and worksharing collaboratecom 09 washington dc ieee http www sciplore org publications en php frakes william b 1992 information retrieval data structures amp algorithms prentice hall inc isbn 160 0 13 463837 9 http www scribd com doc 13742235 information retrieval data structures algorithms william b frakes a b zhu mu 2004 recall precision and average precision http sas uwaterloo ca stats navigation techreports 04workingpapers 2004 09 pdf turpin andrew scholer falk 2006 user performance versus precision measures for simple search tasks proceedings of the 29th annual international acm sigir conference on research and development in information retrieval seattle wa august 06 11 2006 new york ny acm 11 18 doi 10 1145 1148170 1148176 isbn 160 1 59593 369 7 a b everingham mark van gool luc williams christopher k i winn john zisserman andrew june 2010 the pascal visual object classes voc challenge international journal of computer vision springer 88 2 303 338 doi 10 1007 s11263 009 0275 4 http pascallin ecs soton ac uk challenges voc pubs everingham10 pdf retrieved 2011 08 29 a b manning christopher d raghavan prabhakar sch tze hinrich 2008 introduction to information retrieval cambridge university press http nlp stanford edu ir book html htmledition evaluation of ranked retrieval results 1 html k h brodersen c s ong k e stephan j m buhmann 2010 the binormal assumption on precision recall curves proceedings of the 20th international conference on pattern recognition 4263 4266 edit external links acm sigir information retrieval special interest group bcs irsg british computer society information retrieval specialist group text retrieval conference trec forum for information retrieval evaluation fire information retrieval online book by c j van rijsbergen information retrieval wiki information retrieval facility information retrieval duth introduction to information retrieval online book by christopher d manning prabhakar raghavan and hinrich sch tze cambridge university press 2008 