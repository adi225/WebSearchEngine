this article needs additional citations for verification please help improve this article by adding citations to reliable sources unsourced material may be challenged and removed january 2010 computer organization redirects here for organizations that make computers see list of computer system manufacturers for one classification of computer architectures see flynn s taxonomy for another classification of instruction set architectures see instruction set number of operands intel core microarchitecture in computer engineering microarchitecture sometimes abbreviated to arch or uarch also called computer organization is the way a given instruction set architecture isa is implemented on a processor a given isa may be implemented with different microarchitectures 1 implementations might vary due to different goals of a given design or due to shifts in technology 2 computer architecture is the combination of microarchitecture and instruction set design contents 1 relation to instruction set architecture 2 aspects of microarchitecture 3 microarchitectural concepts 3 1 instruction cycle 3 2 increasing execution speed 3 3 instruction set choice 3 4 instruction pipelining 3 5 cache 3 6 branch prediction 3 7 superscalar 3 8 out of order execution 3 9 register renaming 3 10 multiprocessing and multithreading 4 see also 5 references 6 further reading edit relation to instruction set architecture the isa is roughly the same as the programming model of a processor as seen by an assembly language programmer or compiler writer the isa includes the execution model processor registers address and data formats among other things the microarchitecture includes the constituent parts of the processor and how these interconnect and interoperate to implement the isa the microarchitecture of a machine is usually represented as more or less detailed diagrams that describe the interconnections of the various microarchitectural elements of the machine which may be everything from single gates and registers to complete arithmetic logic units alus and even larger elements these diagrams generally separate the datapath where data is placed and the control path which can be said to steer the data 3 each microarchitectural element is in turn represented by a schematic describing the interconnections of logic gates used to implement it each logic gate is in turn represented by a circuit diagram describing the connections of the transistors used to implement it in some particular logic family machines with different microarchitectures may have the same instruction set architecture and thus be capable of executing the same programs new microarchitectures and or circuitry solutions along with advances in semiconductor manufacturing are what allows newer generations of processors to achieve higher performance while using the same isa in principle a single microarchitecture could execute several different isas with only minor changes to the microcode edit aspects of microarchitecture intel 80286 microarchitecture the pipelined datapath is the most commonly used datapath design in microarchitecture today this technique is used in most modern microprocessors microcontrollers and dsps the pipelined architecture allows multiple instructions to overlap in execution much like an assembly line the pipeline includes several different stages which are fundamental in microarchitecture designs 3 some of these stages include instruction fetch instruction decode execute and write back some architectures include other stages such as memory access the design of pipelines is one of the central microarchitectural tasks execution units are also essential to microarchitecture execution units include arithmetic logic units alu floating point units fpu load store units branch prediction and simd these units perform the operations or calculations of the processor the choice of the number of execution units their latency and throughput is a central microarchitectural design task the size latency throughput and connectivity of memories within the system are also microarchitectural decisions system level design decisions such as whether or not to include peripherals such as memory controllers can be considered part of the microarchitectural design process this includes decisions on the performance level and connectivity of these peripherals unlike architectural design where achieving a specific performance level is the main goal microarchitectural design pays closer attention to other constraints since microarchitecture design decisions directly affect what goes into a system attention must be paid to such issues as chip area cost power consumption logic complexity ease of connectivity manufacturability ease of debugging testability edit microarchitectural concepts edit instruction cycle main article instruction cycle in general all cpus single chip microprocessors or multi chip implementations run programs by performing the following steps read an instruction and decode it find any associated data that is needed to process the instruction process the instruction write the results out the instruction cycle is repeated continuously until the power is turned off edit increasing execution speed complicating this simple looking series of steps is the fact that the memory hierarchy which includes caching main memory and non volatile storage like hard disks where the program instructions and data reside has always been slower than the processor itself step 2 often introduces a lengthy in cpu terms delay while the data arrives over the computer bus a considerable amount of research has been put into designs that avoid these delays as much as possible over the years a central goal was to execute more instructions in parallel thus increasing the effective execution speed of a program these efforts introduced complicated logic and circuit structures initially these techniques could only be implemented on expensive mainframes or supercomputers due to the amount of circuitry needed for these techniques as semiconductor manufacturing progressed more and more of these techniques could be implemented on a single semiconductor chip see moore s law edit instruction set choice instruction sets have shifted over the years from originally very simple to sometimes very complex in various respects in recent years load store architectures vliw and epic types have been in fashion architectures that are dealing with data parallelism include simd and vectors some labels used to denote classes of cpu architectures are not particularly descriptive especially so the cisc label many early designs retroactively denoted cisc are in fact significantly simpler than modern risc processors in several respects however the choice of instruction set architecture may greatly affect the complexity of implementing high performance devices the prominent strategy used to develop the first risc processors was to simplify instructions to a minimum of individual semantic complexity combined with high encoding regularity and simplicity such uniform instructions were easily fetched decoded and executed in a pipelined fashion and a simple strategy to reduce the number of logic levels in order to reach high operating frequencies instruction cache memories compensated for the higher operating frequency and inherently low code density while large register sets were used to factor out as much of the slow memory accesses as possible edit instruction pipelining main article instruction pipeline one of the first and most powerful techniques to improve performance is the use of the instruction pipeline early processor designs would carry out all of the steps above for one instruction before moving onto the next large portions of the circuitry were left idle at any one step for instance the instruction decoding circuitry would be idle during execution and so on pipelines improve performance by allowing a number of instructions to work their way through the processor at the same time in the same basic example the processor would start to decode step 1 a new instruction while the last one was waiting for results this would allow up to four instructions to be in flight at one time making the processor look four times as fast although any one instruction takes just as long to complete there are still four steps the cpu as a whole retires instructions much faster risc make pipelines smaller and much easier to construct by cleanly separating each stage of the instruction process and making them take the same amount of time one cycle the processor as a whole operates in an assembly line fashion with instructions coming in one side and results out the other due to the reduced complexity of the classic risc pipeline the pipelined core and an instruction cache could be placed on the same size die that would otherwise fit the core alone on a cisc design this was the real reason that risc was faster early designs like the sparc and mips often ran over 10 times as fast as intel and motorola cisc solutions at the same clock speed and price pipelines are by no means limited to risc designs by 1986 the top of the line vax implementation vax 8800 was a heavily pipelined design slightly predating the first commercial mips and sparc designs most modern cpus even embedded cpus are now pipelined and microcoded cpus with no pipelining are seen only in the most area constrained embedded processors large cisc machines from the vax 8800 to the modern pentium 4 and athlon are implemented with both microcode and pipelines improvements in pipelining and caching are the two major microarchitectural advances that have enabled processor performance to keep pace with the circuit technology on which they are based edit cache main article cpu cache it was not long before improvements in chip manufacturing allowed for even more circuitry to be placed on the die and designers started looking for ways to use it one of the most common was to add an ever increasing amount of cache memory on die cache is simply very fast memory memory that can be accessed in a few cycles as opposed to many needed to talk to main memory the cpu includes a cache controller which automates reading and writing from the cache if the data is already in the cache it simply appears whereas if it is not the processor is stalled while the cache controller reads it in risc designs started adding cache in the mid to late 1980s often only 4 160 kb in total this number grew over time and typical cpus now have at least 512 160 kb while more powerful cpus come with 1 or 2 or even 4 6 8 or 12 160 mb organized in multiple levels of a memory hierarchy generally speaking more cache means more performance due to reduced stalling caches and pipelines were a perfect match for each other previously it didn t make much sense to build a pipeline that could run faster than the access latency of off chip memory using on chip cache memory instead meant that a pipeline could run at the speed of the cache access latency a much smaller length of time this allowed the operating frequencies of processors to increase at a much faster rate than that of off chip memory edit branch prediction main article branch predictor one barrier to achieving higher performance through instruction level parallelism stems from pipeline stalls and flushes due to branches normally whether a conditional branch will be taken isn t known until late in the pipeline as conditional branches depend on results coming from a register from the time that the processor s instruction decoder has figured out that it has encountered a conditional branch instruction to the time that the deciding register value can be read out the pipeline needs to be stalled for several cycles or if it s not and the branch is taken the pipeline needs to be flushed as clock speeds increase the depth of the pipeline increases with it and some modern processors may have 20 stages or more on average every fifth instruction executed is a branch so without any intervention that s a high amount of stalling techniques such as branch prediction and speculative execution are used to lessen these branch penalties branch prediction is where the hardware makes educated guesses on whether a particular branch will be taken in reality one side or the other of the branch will be called much more often than the other modern designs have rather complex statistical prediction systems which watch the results of past branches to predict the future with greater accuracy the guess allows the hardware to prefetch instructions without waiting for the register read speculative execution is a further enhancement in which the code along the predicted path is not just prefetched but also executed before it is known whether the branch should be taken or not this can yield better performance when the guess is good with the risk of a huge penalty when the guess is bad because instructions need to be undone edit superscalar main article superscalar even with all of the added complexity and gates needed to support the concepts outlined above improvements in semiconductor manufacturing soon allowed even more logic gates to be used in the outline above the processor processes parts of a single instruction at a time computer programs could be executed faster if multiple instructions were processed simultaneously this is what superscalar processors achieve by replicating functional units such as alus the replication of functional units was only made possible when the die area of a single issue processor no longer stretched the limits of what could be reliably manufactured by the late 1980s superscalar designs started to enter the market place in modern designs it is common to find two load units one store many instructions have no results to store two or more integer math units two or more floating point units and often a simd unit of some sort the instruction issue logic grows in complexity by reading in a huge list of instructions from memory and handing them off to the different execution units that are idle at that point the results are then collected and re ordered at the end edit out of order execution main article out of order execution the addition of caches reduces the frequency or duration of stalls due to waiting for data to be fetched from the memory hierarchy but does not get rid of these stalls entirely in early designs a cache miss would force the cache controller to stall the processor and wait of course there may be some other instruction in the program whose data is available in the cache at that point out of order execution allows that ready instruction to be processed while an older instruction waits on the cache then re orders the results to make it appear that everything happened in the programmed order this technique is also used to avoid other operand dependency stalls such as an instruction awaiting a result from a long latency floating point operation or other multi cycle operations edit register renaming main article register renaming register renaming refers to a technique used to avoid unnecessary serialized execution of program instructions because of the reuse of the same registers by those instructions suppose we have two groups of instruction that will use the same register one set of instructions is executed first to leave the register to the other set but if the other set is assigned to a different similar register both sets of instructions can be executed in parallel edit multiprocessing and multithreading main articles multiprocessing and multithreading computer architecture computer architects have become stymied by the growing mismatch in cpu operating frequencies and dram access times none of the techniques that exploited instruction level parallelism within one program could make up for the long stalls that occurred when data had to be fetched from main memory additionally the large transistor counts and high operating frequencies needed for the more advanced ilp techniques required power dissipation levels that could no longer be cheaply cooled for these reasons newer generations of computers have started to exploit higher levels of parallelism that exist outside of a single program or program thread this trend is sometimes known as throughput computing this idea originated in the mainframe market where online transaction processing emphasized not just the execution speed of one transaction but the capacity to deal with massive numbers of transactions with transaction based applications such as network routing and web site serving greatly increasing in the last decade the computer industry has re emphasized capacity and throughput issues one technique of how this parallelism is achieved is through multiprocessing systems computer systems with multiple cpus once reserved for high end mainframes and supercomputers small scale 2 8 multiprocessors servers have become commonplace for the small business market for large corporations large scale 16 256 multiprocessors are common even personal computers with multiple cpus have appeared since the 1990s with further transistor size reductions made available with semiconductor technology advances multicore cpus have appeared where multiple cpus are implemented on the same silicon chip initially used in chips targeting embedded markets where simpler and smaller cpus would allow multiple instantiations to fit on one piece of silicon by 2005 semiconductor technology allowed dual high end desktop cpus cmp chips to be manufactured in volume some designs such as sun microsystems ultrasparc t1 have reverted back to simpler scalar in order designs in order to fit more processors on one piece of silicon another technique that has become more popular recently is multithreading in multithreading when the processor has to fetch data from slow system memory instead of stalling for the data to arrive the processor switches to another program or program thread which is ready to execute though this does not speed up a particular program thread it increases the overall system throughput by reducing the time the cpu is idle conceptually multithreading is equivalent to a context switch at the operating system level the difference is that a multithreaded cpu can do a thread switch in one cpu cycle instead of the hundreds or thousands of cpu cycles a context switch normally requires this is achieved by replicating the state hardware such as the register file and program counter for each active thread a further enhancement is simultaneous multithreading this technique allows superscalar cpus to execute instructions from different programs threads simultaneously in the same cycle edit see also wikimedia commons has media related to category microarchitectures microprocessor microcontroller digital signal processor dsp cpu design hardware description language hdl hardware architecture harvard architecture von neumann architecture multi core computing datapath dataflow architecture very large scale integration vlsi vhdl verilog stream processing instruction level parallelism ilp edit references miles murdocca and vincent heuring 2007 computer architecture and organization an integrated approach wiley pp 160 151 michael j flynn 2007 computer architecture pipelined and parallel processor design jones and bartlett pp 160 1 3 a b john l hennessy and david a patterson 2006 computer architecture a quantitative approach fourth edition ed morgan kaufmann publishers inc isbn 160 0 12 370490 1 edit further reading d patterson and j hennessy 2004 08 02 computer organization and design the hardware software interface morgan kaufmann publishers inc isbn 160 1 55860 604 1 v c hamacher z g vrasenic and s g zaky 2001 08 02 computer organization mcgraw hill isbn 160 0 07 232086 9 william stallings 2002 07 15 computer organization and architecture prentice hall isbn 160 0 13 035119 9 j p hayes 2002 09 03 computer architecture and organization mcgraw hill isbn 160 0 07 286198 3 gary michael schneider 1985 the principles of computer organization wiley pp 160 6 7 isbn 160 0 471 88552 5 m morris mano 1992 10 19 computer system architecture prentice hall p 160 3 isbn 160 0 13 175563 3 mostafa abd el barr and hesham el rewini 2004 12 03 fundamentals of computer organization and architecture wiley interscience p 160 1 isbn 160 0 471 46741 3 ieee computer society pc processor microarchitecture computer architecture a minimalist perspective book webpage v t e cpu technologies architecture harvard modified harvard von neumann dataflow comparison instruction set cisc edge epic misc oisc risc vliw nisc zisc word size 1 bit 4 bit 8 bit 9 bit 10 bit 12 bit 15 bit 16 bit 18 bit 22 bit 24 bit 25 bit 26 bit 27 bit 31 bit 32 bit 33 bit 34 bit 36 bit 39 bit 40 bit 48 bit 50 bit 60 bit 64 bit 128 bit 256 bit variable pipeline instruction pipelining in order amp out of order execution branch predictor register renaming speculative execution hazards bubble parallel level bit instruction scalar superscalar data vector task threads multithreading simultaneous multithreading hyper threading super threading flynn s taxonomy sisd simd misd mimd spmd types digital signal processor microcontroller system on a chip cellular components arithmetic logic unit barrel shifter floating point unit back side bus multiplexer demultiplexer registers memory management unit translation lookaside buffer cache register file microcode control unit clock rate power management apm acpi dynamic frequency scaling dynamic voltage scaling clock gating 