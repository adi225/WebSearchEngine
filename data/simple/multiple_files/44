automatic summarization is the process of reducing a text document with a computer program in order to create a summary that retains the most important points of the original document as the problem of information overload has grown and as the quantity of data has increased so has interest in automatic summarization technologies that can make a coherent summary take into account variables such as length writing style and syntax an example of the use of summarization technology is search engines such as google document summarization is another generally there are two approaches to automatic summarization extraction and abstraction extractive methods work by selecting a subset of existing words phrases or sentences in the original text to form the summary in contrast abstractive methods build an internal semantic representation and then use natural language generation techniques to create a summary that is closer to what a human might generate such a summary might contain words not explicitly present in the original the state of the art abstractive methods are still quite weak so most research has focused on extractive methods contents 1 methods 1 1 extraction based summarization 1 2 abstraction based summarization 1 3 maximum entropy based summarization 1 4 aided summarization 2 applications 2 1 keyphrase extraction 2 1 1 task description and example 2 1 2 keyphrase extraction as supervised learning 2 1 2 1 design choices 2 1 2 1 1 what are the examples 2 1 2 1 2 what are the features 2 1 2 1 3 how many keyphrases to return 2 1 2 1 4 what learning algorithm 2 1 3 unsupervised keyphrase extraction textrank 2 1 3 1 design choices 2 1 3 1 1 what should vertices be 2 1 3 1 2 how should we create edges 2 1 3 1 3 how are the final keyphrases formed 2 1 3 2 why it works 2 2 document summarization 2 2 1 overview of supervised learning approaches 2 2 2 unsupervised approaches textrank and lexrank 2 2 2 1 design choices 2 2 2 1 1 what are the vertices 2 2 2 1 2 what are the edges 2 2 2 1 3 how are summaries formed 2 2 2 2 textrank and lexrank differences 2 2 3 why unsupervised summarization works 2 2 4 multi document summarization 2 2 4 1 incorporating diversity grasshopper algorithm 3 evaluation techniques 3 1 intrinsic and extrinsic evaluation 3 2 inter textual and intra textual 3 3 current difficulties in evaluating summaries automatically 3 4 evaluating summaries qualitatively 4 see also 5 references 5 1 further reading edit methods methods of automatic summarization include extraction based abstraction based maximum entropy based and aided summarization edit extraction based summarization two particular types of summarization often addressed in the literature are keyphrase extraction where the goal is to select individual words or phrases to tag a document and document summarization where the goal is to select whole sentences to create a short paragraph summary edit abstraction based summarization extraction techniques merely copy the information deemed most important by the system to the summary for example key clauses sentences or paragraphs while abstraction involves paraphrasing sections of the source document in general abstraction can condense a text more strongly than extraction but the programs that can do this are harder to develop as they require the use of natural language generation technology which itself is a growing field while some work has been done in abstractive summarization creating an abstract synopsis like that of a human the majority of summarization systems are extractive selecting a subset of sentences to place in a summary edit maximum entropy based summarization even though automating abstractive summarization is the goal of summarization research most practical systems are based on some form of extractive summarization extracted sentences can form a valid summary in itself or form a basis for further condensation operations furthermore evaluation of extracted summaries can be automated since it is essentially a classification task during the duc 2001 and 2002 evaluation workshops tno developed a sentence extraction system for multi document summarization in the news domain the system was based on a hybrid system using a naive bayes classifier and statistical language models for modeling salience although the system exhibited good results we wanted to explore the effectiveness of a maximum entropy me classifier for the meeting summarization task as me is known to be robust against feature dependencies maximum entropy has also been applied successfully for summarization in the broadcast news domain edit aided summarization machine learning techniques from closely related fields such as information retrieval or text mining have been successfully adapted to help automatic summarization apart from fully automated summarizers fas there are systems that aid users with the task of summarization mahs machine aided human summarization for example by highlighting candidate passages to be included in the summary and there are systems that depend on post processing by a human hams human aided machine summarization edit applications there are different types of summaries depending what the summarization program focuses on to make the summary of the text for example generic summaries or query relevant summaries sometimes called query based summaries summarization systems are able to create both query relevant text summaries and generic machine generated summaries depending on what the user needs summarization of multimedia documents e g pictures or movies is also possible some systems will generate a summary based on a single source document while others can use multiple source documents for example a cluster of news stories on the same topic these systems are known as multi document summarization systems edit keyphrase extraction edit task description and example the task is the following you are given a piece of text such as a journal article and you must produce a list of keywords or key phrases that capture the primary topics discussed in the text in the case of research articles many authors provide manually assigned keywords but most text lacks pre existing keyphrases for example news articles rarely have keyphrases attached but it would be useful to be able to automatically do so for a number of applications discussed below consider the example text from a recent news article the army corps of engineers rushing to meet president bush s promise to protect new orleans by the start of the 2006 hurricane season installed defective flood control pumps last year despite warnings from its own expert that the equipment would fail during a storm according to documents obtained by the associated press an extractive keyphrase extractor might select army corps of engineers president bush new orleans and defective flood control pumps as keyphrases these are pulled directly from the text in contrast an abstractive keyphrase system would somehow internalize the content and generate keyphrases that might be more descriptive and more like what a human would produce such as political negligence or inadequate protection from floods note that these terms do not appear in the text and require a deep understanding which makes it difficult for a computer to produce such keyphrases keyphrases have many applications such as to improve document browsing by providing a short summary also keyphrases can improve information retrieval if documents have keyphrases assigned a user could search by keyphrase to produce more reliable hits than a full text search also automatic keyphrase extraction can be useful in generating index entries for a large text corpus edit keyphrase extraction as supervised learning beginning with the turney paper many researchers have approached keyphrase extraction as a supervised machine learning problem given a document we construct an example for each unigram bigram and trigram found in the text though other text units are also possible as discussed below we then compute various features describing each example e g does the phrase begin with an upper case letter we assume there are known keyphrases available for a set of training documents using the known keyphrases we can assign positive or negative labels to the examples then we learn a classifier that can discriminate between positive and negative examples as a function of the features some classifiers make a binary classification for a test example while others assign a probability of being a keyphrase for instance in the above text we might learn a rule that says phrases with initial capital letters are likely to be keyphrases after training a learner we can select keyphrases for test documents in the following manner we apply the same example generation strategy to the test documents then run each example through the learner we can determine the keyphrases by looking at binary classification decisions or probabilities returned from our learned model if probabilities are given a threshold is used to select the keyphrases keyphrase extractors are generally evaluated using precision and recall precision measures how many of the proposed keyphrases are actually correct recall measures how many of the true keyphrases your system proposed the two measures can be combined in an f score which is the harmonic mean of the two f 160 160 2 pr p 160 160 r matches between the proposed keyphrases and the known keyphrases can be checked after stemming or applying some other text normalization edit design choices designing a supervised keyphrase extraction system involves deciding on several choices some of these apply to unsupervised too edit what are the examples the first choice is exactly how to generate examples turney and others have used all possible unigrams bigrams and trigrams without intervening punctuation and after removing stopwords hulth showed that you can get some improvement by selecting examples to be sequences of tokens that match certain patterns of part of speech tags ideally the mechanism for generating examples produces all the known labeled keyphrases as candidates though this is often not the case for example if we use only unigrams bigrams and trigrams then we will never be able to extract a known keyphrase containing four words thus recall may suffer however generating too many examples can also lead to low precision edit what are the features we also need to create features that describe the examples and are informative enough to allow a learning algorithm to discriminate keyphrases from non keyphrases typically features involve various term frequencies how many times a phrase appears in the current text or in a larger corpus the length of the example relative position of the first occurrence various boolean syntactic features e g contains all caps etc the turney paper used about 12 such features hulth uses a reduced set of features which were found most successful in the kea keyphrase extraction algorithm work derived from turney s seminal paper edit how many keyphrases to return in the end the system will need to return a list of keyphrases for a test document so we need to have a way to limit the number ensemble methods i e using votes from several classifiers have been used to produce numeric scores that can be thresholded to provide a user provided number of keyphrases this is the technique used by turney with c4 5 decision trees hulth used a single binary classifier so the learning algorithm implicitly determines the appropriate number edit what learning algorithm once examples and features are created we need a way to learn to predict keyphrases virtually any supervised learning algorithm could be used such as decision trees naive bayes and rule induction in the case of turney s genex algorithm a genetic algorithm is used to learn parameters for a domain specific keyphrase extraction algorithm the extractor follows a series of heuristics to identify keyphrases the genetic algorithm optimizes parameters for these heuristics with respect to performance on training documents with known key phrases edit unsupervised keyphrase extraction textrank while supervised methods have some nice properties like being able to produce interpretable rules for what features characterize a keyphrase they also require a large amount of training data many documents with known keyphrases are needed furthermore training on a specific domain tends to customize the extraction process to that domain so the resulting classifier is not necessarily portable as some of turney s results demonstrate unsupervised keyphrase extraction removes the need for training data it approaches the problem from a different angle instead of trying to learn explicit features that characterize keyphrases the textrank algorithm 1 exploits the structure of the text itself to determine keyphrases that appear central to the text in the same way that pagerank selects important web pages recall this is based on the notion of prestige or recommendation from social networks in this way textrank does not rely on any previous training data at all but rather can be run on any arbitrary piece of text and it can produce output simply based on the text s intrinsic properties thus the algorithm is easily portable to new domains and languages textrank is a general purpose graph based ranking algorithm for nlp essentially it runs pagerank on a graph specially designed for a particular nlp task for keyphrase extraction it builds a graph using some set of text units as vertices edges are based on some measure of semantic or lexical similarity between the text unit vertices unlike pagerank the edges are typically undirected and can be weighted to reflect a degree of similarity once the graph is constructed it is used to form a stochastic matrix combined with a damping factor as in the random surfer model and the ranking over vertices is obtained by finding the eigenvector corresponding to eigenvalue 1 i e the stationary distribution of the random walk on the graph edit design choices edit what should vertices be the vertices should correspond to what we want to rank potentially we could do something similar to the supervised methods and create a vertex for each unigram bigram trigram etc however to keep the graph small the authors decide to rank individual unigrams in a first step and then include a second step that merges highly ranked adjacent unigrams to form multi word phrases this has a nice side effect of allowing us to produce keyphrases of arbitrary length for example if we rank unigrams and find that advanced natural language and processing all get high ranks then we would look at the original text and see that these words appear consecutively and create a final keyphrase using all four together note that the unigrams placed in the graph can be filtered by part of speech the authors found that adjectives and nouns were the best to include thus some linguistic knowledge comes into play in this step edit how should we create edges edges are created based on word co occurrence in this application of textrank two vertices are connected by an edge if the unigrams appear within a window of size n in the original text n is typically around 2 10 thus natural and language might be linked in a text about nlp natural and processing would also be linked because they would both appear in the same string of n words these edges build on the notion of text cohesion and the idea that words that appear near each other are likely related in a meaningful way and recommend each other to the reader edit how are the final keyphrases formed since this method simply ranks the individual vertices we need a way to threshold or produce a limited number of keyphrases the technique chosen is to set a count t to be a user specified fraction of the total number of vertices in the graph then the top t vertices unigrams are selected based on their stationary probabilities a post processing step is then applied to merge adjacent instances of these t unigrams as a result potentially more or less than t final keyphrases will be produced but the number should be roughly proportional to the length of the original text edit why it works it is not initially clear why applying pagerank to a co occurrence graph would produce useful keyphrases one way to think about it is the following a word that appears multiple times throughout a text may have many different co occurring neighbors for example in a text about machine learning the unigram learning might co occur with machine supervised un supervised and semi supervised in four different sentences thus the learning vertex would be a central hub that connects to these other modifying words running pagerank textrank on the graph is likely to rank learning highly similarly if the text contains the phrase supervised classification then there would be an edge between supervised and classification if classification appears several other places and thus has many neighbors it is importance would contribute to the importance of supervised if it ends up with a high rank it will be selected as one of the top t unigrams along with learning and probably classification in the final post processing step we would then end up with keyphrases supervised learning and supervised classification in short the co occurrence graph will contain densely connected regions for terms that appear often and in different contexts a random walk on this graph will have a stationary distribution that assigns large probabilities to the terms in the centers of the clusters this is similar to densely connected web pages getting ranked highly by pagerank edit document summarization like keyphrase extraction document summarization hopes to identify the essence of a text the only real difference is that now we are dealing with larger text units whole sentences instead of words and phrases before getting into the details of some summarization methods we will mention how summarization systems are typically evaluated the most common way is using the so called rouge recall oriented understudy for gisting evaluation measure this is a recall based measure that determines how well a system generated summary covers the content present in one or more human generated model summaries known as references it is recall based to encourage systems to include all the important topics in the text recall can be computed with respect to unigram bigram trigram or 4 gram matching though rouge 1 unigram matching has been shown to correlate best with human assessments of system generated summaries i e the summaries with highest rouge 1 values correlate with the summaries humans deemed the best rouge 1 is computed as division of count of unigrams in reference that appear in system and count of unigrams in reference summary if there are multiple references the rouge 1 scores are averaged because rouge is based only on content overlap it can determine if the same general concepts are discussed between an automatic summary and a reference summary but it cannot determine if the result is coherent or the sentences flow together in a sensible manner high order n gram rouge measures try to judge fluency to some degree note that rouge is similar to the bleu measure for machine translation but bleu is precision based because translation systems favor accuracy a promising line in document summarization is adaptive document text summarization 2 the idea of adaptive summarization involves preliminary recognition of document text genre and subsequent application of summarization algorithms optimized for this genre first summarizes that perform adaptive summarization have been created 3 edit overview of supervised learning approaches supervised text summarization is very much like supervised keyphrase extraction basically if you have a collection of documents and human generated summaries for them you can learn features of sentences that make them good candidates for inclusion in the summary features might include the position in the document i e the first few sentences are probably important the number of words in the sentence etc the main difficulty in supervised extractive summarization is that the known summaries must be manually created by extracting sentences so the sentences in an original training document can be labeled as in summary or not in summary this is not typically how people create summaries so simply using journal abstracts or existing summaries is usually not sufficient the sentences in these summaries do not necessarily match up with sentences in the original text so it would be difficult to assign labels to examples for training note however that these natural summaries can still be used for evaluation purposes since rouge 1 only cares about unigrams edit unsupervised approaches textrank and lexrank the unsupervised approach to summarization is also quite similar in spirit to unsupervised keyphrase extraction and gets around the issue of costly training data some unsupervised summarization approaches are based on finding a centroid sentence which is the mean word vector of all the sentences in the document then the sentences can be ranked with regard to their similarity to this centroid sentence a more principled way to estimate sentence importance is using random walks and eigenvector centrality lexrank 4 is an algorithm essentially identical to textrank and both use this approach for document summarization the two methods were developed by different groups at the same time and lexrank simply focused on summarization but could just as easily be used for keyphrase extraction or any other nlp ranking task edit design choices edit what are the vertices in both lexrank and textrank a graph is constructed by creating a vertex for each sentence in the document edit what are the edges the edges between sentences are based on some form of semantic similarity or content overlap while lexrank uses cosine similarity of tf idf vectors textrank uses a very similar measure based on the number of words two sentences have in common normalized by the sentences lengths the lexrank paper explored using unweighted edges after applying a threshold to the cosine values but also experimented with using edges with weights equal to the similarity score textrank uses continuous similarity scores as weights edit how are summaries formed in both algorithms the sentences are ranked by applying pagerank to the resulting graph a summary is formed by combining the top ranking sentences using a threshold or length cutoff to limit the size of the summary edit textrank and lexrank differences it is worth noting that textrank was applied to summarization exactly as described here while lexrank was used as part of a larger summarization system mead that combines the lexrank score stationary probability with other features like sentence position and length using a linear combination with either user specified or automatically tuned weights in this case some training documents might be needed though the textrank results show the additional features are not absolutely necessary another important distinction is that textrank was used for single document summarization while lexrank has been applied to multi document summarization the task remains the same in both cases only the number of sentences to choose from has grown however when summarizing multiple documents there is a greater risk of selecting duplicate or highly redundant sentences to place in the same summary imagine you have a cluster of news articles on a particular event and you want to produce one summary each article is likely to have many similar sentences and you would only want to include distinct ideas in the summary to address this issue lexrank applies a heuristic post processing step that builds up a summary by adding sentences in rank order but discards any sentences that are too similar to ones already placed in the summary the method used is called cross sentence information subsumption csis edit why unsupervised summarization works these methods work based on the idea that sentences recommend other similar sentences to the reader thus if one sentence is very similar to many others it will likely be a sentence of great importance the importance of this sentence also stems from the importance of the sentences recommending it thus to get ranked highly and placed in a summary a sentence must be similar to many sentences that are in turn also similar to many other sentences this makes intuitive sense and allows the algorithms to be applied to any arbitrary new text the methods are domain independent and easily portable one could imagine the features indicating important sentences in the news domain might vary considerably from the biomedical domain however the unsupervised recommendation based approach applies to any domain edit multi document summarization main article multi document summarization multi document summarization is an automatic procedure aimed at extraction of information from multiple texts written about the same topic resulting summary report allows individual users such as professional information consumers to quickly familiarize themselves with information contained in a large cluster of documents in such a way multi document summarization systems are complementing the news aggregators performing the next step down the road of coping with information overload multi document summarization creates information reports that are both concise and comprehensive with different opinions being put together amp outlined every topic is described from multiple perspectives within a single document while the goal of a brief summary is to simplify information search and cut the time by pointing to the most relevant source documents comprehensive multi document summary should itself contain the required information hence limiting the need for accessing original files to cases when refinement is required automatic summaries present information extracted from multiple sources algorithmically without any editorial touch or subjective human intervention thus making it completely unbiased edit incorporating diversity grasshopper algorithm multi document extractive summarization faces a problem of potential redundancy ideally we would like to extract sentences that are both central i e contain the main ideas and diverse i e they differ from one another lexrank deals with diversity as a heuristic final stage using csis and other systems have used similar methods such as maximal marginal relevance mmr in trying to eliminate redundancy in information retrieval results there is a general purpose graph based ranking algorithm like page lex textrank that handles both centrality and diversity in a unified mathematical framework based on absorbing markov chain random walks an absorbing random walk is like a standard random walk except some states are now absorbing states that act as black holes that cause the walk to end abruptly at that state the algorithm is called grasshopper in addition to explicitly promoting diversity during the ranking process grasshopper incorporates a prior ranking based on sentence position in the case of summarization edit evaluation techniques the most common way to evaluate the informativeness of automatic summaries is to compare them with human made model summaries evaluation techniques fall into intrinsic and extrinsic 5 inter texual and intra texual 6 edit intrinsic and extrinsic evaluation an intrinsic evaluation tests the summarization system in of itself while an extrinsic evaluation tests the summarization based on how it affects the completion of some other task intrinsic evaluations have assessed mainly the coherence and informativeness of summaries extrinsic evaluations on the other hand have tested the impact of summarization on tasks like relevance assessment reading comprehension etc edit inter textual and intra textual intra texual methods assess the output of a specific summarization system and the inter texual ones focus on contrastive analysis of outputs of several summarization systems human judgement often has wide variance on what is considered a good summary which means that making the evaluation process automatic is particularly difficult manual evaluation can be used but this is both time and labor intensive as it requires humans to read not only the summaries but also the source documents other issues are those concerning coherence and coverage one of the metrics used in nist s annual document understanding conferences in which research groups submit their systems for both summarization and translation tasks is the rouge metric recall oriented understudy for gisting evaluation 3 it essentially calculates n gram overlaps between automatically generated summaries and previously written human summaries a high level of overlap should indicate a high level of shared concepts between the two summaries note that overlap metrics like this are unable to provide any feedback on a summary s coherence anaphor resolution remains another problem yet to be fully solved edit current difficulties in evaluating summaries automatically evaluating summaries either manually or automatically is a hard task the main difficulty in evaluation comes from the impossibility of building a fair gold standard against which the results of the systems can be compared furthermore it is also very hard to determine what a correct summary is because there is always the possibility of a system to generate a good summary that is quite different from any human summary used as an approximation to the correct output content selection is not a deterministic problem people are subjective and different authors would choose different sentences and individuals may not be consistent a particular person may chose different sentences at different times two distinct sentences expressed in different words can express the same meaning this phenomenon is known as paraphrasing we can find an approach to automatically evaluating summaries using paraphrases paraeval most summarization systems perform an extractive approach selecting and copying important sentences from the source documents although humans can also cut and paste relevant information of a text most of the times they rephrase sentences when necessary or they join different related information into one sentence edit evaluating summaries qualitatively the main drawback of the evaluation systems existing so far is that we need at least one reference summary and for some methods more than one to be able to compare automatic summaries with models this is a hard and expensive task much effort has to be done in order to have corpus of texts and their corresponding summaries furthermore for some methods not only do we need to have human made summaries available for comparison but also manual annotation has to be performed in some of them e g scu in the pyramid method in any case what the evaluation methods need as an input is a set of summaries to serve as gold standards and a set of automatic summaries moreover they all perform a quantitative evaluation with regard to different similarity metrics to overcome these problems we think that the quantitative evaluation might not be the only way to evaluate summaries and a qualitative automatic evaluation would be also important edit see also sentence extraction text mining multi document summarization open text summarizer an open sourced text summarizing library 4 a matlab tool for text summarization edit references rada mihalcea and paul tarau 2004 textrank bringing order into texts department of computer science university of north texas 1 yatsko v et al automatic genre recognition and adaptive text summarization in automatic documentation and mathematical linguistics 2010 volume 44 number 3 pp 111 120 unis universal summarizer g ne erkan and dragomir r radev lexrank graph based lexical centrality as salience in text summarization 2 mani i summarization evaluation an overview yatsko v a vishnyakov t n a method for evaluating modern systems of automatic text summarization in automatic documentation and mathematical linguistics 2007 v 41 no 3 p 93 103 edit further reading hercules dalianis 2003 porting and evaluation of automatic summarization roxana angheluta 2002 the use of topic segmentation for automatic summarization anne buist 2004 automatic summarization of meeting data a feasibility study annie louis 2009 performance confidence estimation for automatic summarization elena lloret and manuel palomar 2009 challenging issues of automatic summarization relevance detection and quality based evaluation andrew goldberg 2007 automatic summarization endres niggemeyer brigitte 1998 summarizing information isbn 160 3 540 63735 4 marcu daniel 2000 the theory and practice of discourse parsing and summarization isbn 160 0 262 13372 5 mani inderjeet 2001 automatic summarization isbn 160 1 58811 060 5 huff jason 2010 autosummarize http www jason huff com project autosummarize conceptual artwork using automatic summarization software in microsoft word 2008 lehmam abderrafih 2010 essential summarizer innovative automatic text summarization software in twenty languages acm digital library http portal acm org citation cfm id 1937055 1937111 amp coll dl amp dl guide amp cfid 23185814 amp cftoken 40272014 published in proceeding riao 10 adaptivity personalization and fusion of heterogeneous information cid paris france 