roc curve of three epitope predictors in signal detection theory a receiver operating characteristic roc or simply roc curve is a graphical plot which illustrates the performance of a binary classifier system as its discrimination threshold is varied it is created by plotting the fraction of true positives out of the positives tpr true positive rate vs the fraction of false positives out of the negatives fpr false positive rate at various threshold settings tpr is also known as sensitivity and fpr is one minus the specificity or true negative rate roc analysis provides tools to select possibly optimal models and to discard suboptimal ones independently from and prior to specifying the cost context or the class distribution roc analysis is related in a direct and natural way to cost benefit analysis of diagnostic decision making the roc curve was first developed by electrical engineers and radar engineers during world war ii for detecting enemy objects in battlefields and was soon introduced to psychology to account for perceptual detection of stimuli roc analysis since then has been used in medicine radiology biometrics and other areas for many decades and is increasingly used in machine learning and data mining research the roc is also known as a relative operating characteristic curve because it is a comparison of two operating characteristics tpr and fpr as the criterion changes 1 contents 1 basic concept 2 roc space 3 curves in roc space 4 further interpretations 4 1 area under the curve 4 2 other measures 5 detection error tradeoff graph 6 z transformation 7 history 8 see also 9 references 9 1 general references 10 further reading 11 external links edit basic concept terminology and derivations from a confusion matrix true positive tp eqv with hit true negative tn eqv with correct rejection false positive fp eqv with false alarm type i error false negative fn eqv with miss type ii error sensitivity or true positive rate tpr eqv with hit rate recall false positive rate fpr eqv with fall out accuracy acc specificity spc or true negative rate positive predictive value ppv eqv with precision negative predictive value npv false discovery rate fdr matthews correlation coefficient mcc f1 score source fawcett 2006 see also type i and type ii errors a classification model classifier or diagnosis is a mapping of instances between certain classes groups the classifier or diagnosis result can be a real value continuous output in which case the classifier boundary between classes must be determined by a threshold value for instance to determine whether a person has hypertension based on a blood pressure measure or it can be a discrete class label indicating one of the classes let us consider a two class prediction problem binary classification in which the outcomes are labeled either as positive p or negative n there are four possible outcomes from a binary classifier if the outcome from a prediction is p and the actual value is also p then it is called a true positive tp however if the actual value is n then it is said to be a false positive fp conversely a true negative tn has occurred when both the prediction outcome and the actual value are n and false negative fn is when the prediction outcome is n while the actual value is p to get an appropriate example in a real world problem consider a diagnostic test that seeks to determine whether a person has a certain disease a false positive in this case occurs when the person tests positive but actually does not have the disease a false negative on the other hand occurs when the person tests negative suggesting they are healthy when they actually do have the disease let us define an experiment from p positive instances and n negative instances the four outcomes can be formulated in a 2 2 contingency table or confusion matrix as follows 160 actual value 160 p n total prediction outcome p true positive false positive p n false negative true negative n total p n edit roc space the roc space and plots of the four prediction examples the contingency table can derive several evaluation metrics see infobox to draw a roc curve only the true positive rate tpr and false positive rate fpr are needed as functions of some classifier parameter the tpr defines how many correct positive results occur among all positive samples available during the test fpr on the other hand defines how many incorrect positive results occur among all negative samples available during the test a roc space is defined by fpr and tpr as x and y axes respectively which depicts relative trade offs between true positive benefits and false positive costs since tpr is equivalent with sensitivity and fpr is equal to 1 specificity the roc graph is sometimes called the sensitivity vs 1 specificity plot each prediction result or instance of a confusion matrix represents one point in the roc space the best possible prediction method would yield a point in the upper left corner or coordinate 0 1 of the roc space representing 100 sensitivity no false negatives and 100 specificity no false positives the 0 1 point is also called a perfect classification a completely random guess would give a point along a diagonal line the so called line of no discrimination from the left bottom to the top right corners regardless of the positive and negative base rates an intuitive example of random guessing is a decision by flipping coins heads or tails as the size of the sample increases a random classifier s roc point migrates towards 0 5 0 5 the diagonal divides the roc space points above the diagonal represent good classification results better than random points below the line poor results worse than random note that the output of a consistently poor predictor could simply be inverted to obtain a good predictor let us look into four prediction results from 100 positive and 100 negative instances a b c c tp 63 fp 28 91 fn 37 tn 72 109 100 100 200 tp 77 fp 77 154 fn 23 tn 23 46 100 100 200 tp 24 fp 88 112 fn 76 tn 12 88 100 100 200 tp 76 fp 12 88 fn 24 tn 88 112 100 100 200 tpr 0 63 tpr 0 77 tpr 0 24 tpr 0 76 fpr 0 28 fpr 0 77 fpr 0 88 fpr 0 12 acc 0 68 acc 0 50 acc 0 18 acc 0 82 plots of the four results above in the roc space are given in the figure the result of method a clearly shows the best predictive power among a b and c the result of b lies on the random guess line the diagonal line and it can be seen in the table that the accuracy of b is 50 however when c is mirrored across the center point 0 5 0 5 the resulting method c is even better than a this mirrored method simply reverses the predictions of whatever method or test produced the c contingency table although the original c method has negative predictive power simply reversing its decisions leads to a new predictive method c which has positive predictive power when the c method predicts p or n the c method would predict n or p respectively in this manner the c test would perform the best the closer a result from a contingency table is to the upper left corner the better it predicts but the distance from the random guess line in either direction is the best indicator of how much predictive power a method has if the result is below the line i e the method is worse than a random guess all of the method s predictions must be reversed in order to utilize its power thereby moving the result above the random guess line edit curves in roc space objects are often classified based on a continuous random variable for example imagine that the blood protein levels in diseased people and healthy people are normally distributed with means of 2 g dl and 1 g dl respectively a medical test might measure the level of a certain protein in a blood sample and classify any number above a certain threshold as indicating disease the experimenter can adjust the threshold black vertical line in the figure which will in turn change the false positive rate increasing the threshold would result in fewer false positives and more false negatives corresponding to a leftward movement on the curve the actual shape of the curve is determined by how much overlap the two distributions have edit further interpretations sometimes the roc is used to generate a summary statistic common versions are the intercept of the roc curve with the line at 90 degrees to the no discrimination line also called youden s j statistic the area between the roc curve and the no discrimination line citation needed the area under the roc curve or auc area under curve or a pronounced a prime 2 or c statistic 3 d pronounced d prime the distance between the mean of the distribution of activity in the system under noise alone conditions and its distribution under signal alone conditions divided by their standard deviation under the assumption that both these distributions are normal with the same standard deviation under these assumptions it can be proved that the shape of the roc depends only on d c concordance statistic this is a rank order statistic related to somers d statistic it is commonly used in the medical literature to quantify the capacity of the estimated risk score in discriminating among subjects with different event times it varies between 0 5 and 1 0 with higher values indicating a better predictive model for binary outcomes c is identical to the area under the receiver operating characteristic curve although bootstrapping to generate confidence intervals is possible the power of testing the differences between two or more c statistics is low and alternative methods such as logistic regression should probably be used 4 the c statistic has been generalized for use in survival analysis 5 and it is also possible to combine this with statistical weighting systems other extensions have been proposed 6 7 however any attempt to summarize the roc curve into a single number loses information about the pattern of tradeoffs of the particular discriminator algorithm edit area under the curve when using normalized units the area under the curve auc is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one assuming positive ranks higher than negative 8 it can be shown that the area under the roc curve is closely related to the mann whitney u 9 10 which tests whether positives are ranked higher than negatives it is also equivalent to the wilcoxon test of ranks 10 the auc is related to the gini coefficient by the formula where 11 in this way it is possible to calculate the auc by using an average of a number of trapezoidal approximations it is also common to calculate the area under the roc convex hull roc auch roch auc as any point on the line segment between two prediction results can be achieved by randomly using one or other system with probabilities proportional to the relative length of the opposite component of the segment 12 interestingly it is also possible to invert concavities just as in the figure the worse solution can be reflected to become a better solution concavities can be reflected in any line segment but this more extreme form of fusion is much more likely to overfit the data 13 the machine learning community most often uses the roc auc statistic for model comparison 14 however this practice has recently been questioned based upon new machine learning research that shows that the auc is quite noisy as a classification measure 15 and has some other significant problems in model comparison 16 17 a reliable and valid auc estimate can be interpreted as the probability that the classifier will assign a higher score to a randomly chosen positive example than to a randomly chosen negative example however the critical research 15 16 suggests frequent failures in obtaining reliable and valid auc estimates thus the practical value of the auc measure has been called into question 17 raising the possibility that the auc may actually introduce more uncertainty into machine learning classification accuracy comparisons than resolution one recent explanation of the problem with roc auc is that reducing the roc curve to a single number ignores the fact that it is about the tradeoffs between the different systems or performance points plotted and not the performance of an individual system as well as ignoring the possibility of concavity repair so that related alternative measures such as informedness 18 or deltap are recommended 19 these measures are essentially equivalent to the gini for a single prediction point with deltap informedness 2auc 1 whilst deltap markedness represents the dual viz predicting the prediction from the real class and their geometric mean is matthews correlation coefficient 18 alternatively roc auc may be divided into two components its certainty roc cert which corresponds to the single point auc and its consistency roc con which corresponds to multipoint auc singlepoint auc with the pair of measures roc concert being argued to capture some of the additional information that roc adds to the single point measures noting that it can also be applied to roch and should be if it is to capture the real potential of the system whose parameterization is being investigated 20 edit other measures in engineering the area between the roc curve and the no discrimination line is often preferred due to its useful mathematical properties as a non parametric statistic citation needed this area is often simply known as the discrimination in psychophysics the sensitivity index d p or deltap is the most commonly used measure 21 and is equivalent to twice the discrimination being equal also to informedness deskewed wracc and gini coefficient in the single point case single parameterization or single system 18 these measures all have the advantage that 0 represents chance performance whilst informedness 1 represents perfect performance and 1 represents the perverse case of full informedness used to always give the wrong response with informedness being proven to be the probability of making an informed decision rather than guessing 22 roc auc and auch have a related property that chance performance has a fixed value but it is 0 5 and the normalization to 2auc 1 brings this to 0 and allows informedness and gini to be interpreted as kappa statistics but informedness has been shown to have desirable characteristics for machine learning versus other common definitions of kappa such as cohen kappa and fleiss kappa 18 23 the illustration at the top right of the page shows the use of roc graphs for the discrimination between the quality of different algorithms for predicting epitopes the graph shows that if one detects at least 60 of the epitopes in a virus protein at least 30 of the output is falsely marked as epitopes sometimes it can be more useful to look at a specific region of the roc curve rather than at the whole curve it is possible to compute partial auc 24 for example one could focus on the region of the curve with low false positive rate which is often of prime interest for population screening tests 25 another common approach for classification problems in which p n common in bioinformatics applications is to use a logarithmic scale for the x axis 26 edit detection error tradeoff graph example det graph an alternative to the roc curve is the detection error tradeoff det graph which plots the false negative rate missed detections vs the false positive rate false alarms on non linearly transformed x and y axes the transformation function is the quantile function of the normal distribution i e the inverse of the cumulative normal distribution it is in fact the same transformation as zroc below except that the complement of the hit rate the miss rate or false negative rate is used this alternative spends more graph area on the region of interest most of the roc area is of little interest one primarily cares about the region tight against the y axis and the top left corner which because of using miss rate instead of its complement the hit rate is the lower left corner in a det plot the det plot is used extensively in the automatic speaker recognition community where the name det was first used the analysis of the roc performance in graphs with this warping of the axes was used by psychologists in perception studies halfway the 20th century where this was dubbed double probability paper edit z transformation if a z transformation is applied to the roc curve the curve will be transformed into a straight line 27 this z transformation is based on a normal distribution with a mean of zero and a standard deviation of one in memory strength theory one must assume that the zroc is not only linear but has a slope of 1 0 the normal distributions of targets studied objects that the subjects need to recall and lures non studied objects that the subjects attempt to recall is the factor causing the zroc to be linear the linearity of the zroc curve depends on the standard deviations of the target and lure strength distributions if the standard deviations are equal the slope will be 1 0 if the standard deviation of the target strength distribution is larger than the standard deviation of the lure strength distribution then the slope will be smaller than 1 0 in most studies it has been found that the zroc curve slopes constantly fall below 1 usually between 0 5 and 0 9 28 many experiments yielded a zroc slope of 0 8 a slope of 0 8 implies that the variability of the target strength distribution is 25 larger than the variability of the lure strength distribution 29 another variable used is d d is a measure of sensitivity for yes no recognition that can easily be expressed in terms of z values d measures sensitivity in that it measures the degree of overlap between target and lure distributions it is calculated as the mean of the target distribution minus the mean of the lure distribution expressed in standard deviation units for a given hit rate and false alarm rate d can be calculated with the following equation d z hit rate z false alarm rate although d is a commonly used parameter it must be recognized that it is only relevant when strictly adhering to the very strong assumptions of strength theory made above 30 the z transformation of a roc curve is always linear as assumed except in special situations the yonelinas familiarity recollection model is a two dimensional account of recognition memory instead of the subject simply answering yes or no to a specific input the subject gives the input a feeling of familiarity which operates like the original roc curve what changes though is a parameter for recollection r recollection is assumed to be all or none and it trumps familiarity if there were no recollection component zroc would have a predicted slope of 1 however when adding the recollection component the zroc curve will be concave up with a decreased slope this difference in shape and slope result from an added element of variability due to some items being recollected patients with anterograde amnesia are unable to recollect so their yonelinas zroc curve would have a slope close to 1 0 31 edit history the roc curve was first used during world war ii for the analysis of radar signals before it was employed in signal detection theory 32 following the attack on pearl harbor in 1941 the united states army began new research to increase the prediction of correctly detected japanese aircraft from their radar signals in the 1950s roc curves were employed in psychophysics to assess human and occasionally non human animal detection of weak signals 32 in medicine roc analysis has been extensively used in the evaluation of diagnostic tests 33 34 roc curves are also used extensively in epidemiology and medical research and are frequently mentioned in conjunction with evidence based medicine in radiology roc analysis is a common technique to evaluate new radiology techniques 35 in the social sciences roc analysis is often called the roc accuracy ratio a common technique for judging the accuracy of default probability models roc curves also proved useful for the evaluation of machine learning techniques the first application of roc in machine learning was by spackman who demonstrated the value of roc curves in comparing and evaluating different classification algorithms 36 edit see also wikimedia commons has media related to receiver operating characteristic brier score coefficient of determination constant false alarm rate detection theory false alarm gain information retrieval precision and recall edit references swets john a signal detection theory and roc analysis in psychology and diagnostics 160 collected papers lawrence erlbaum associates mahwah nj 1996 fogarty james baker ryan s hudson scott e 2005 case studies in the use of roc curve analysis for sensor based estimates in human computer interaction acm international conference proceeding series proceedings of graphics interface 2005 waterloo on canadian human computer communications society http portal acm org citation cfm id 1089530 hastie trevor tibshirani robert friedman jerome h 2009 the elements of statistical learning data mining inference and prediction 2nd ed lavalley mp 2008 logistic regression circulation 117 2395 2399 doi 10 1161 circulationaha 106 682658 heagerty pj zheng y 2005 survival model predictive accuracy and roc curves biometrics 61 92 105 gonen m heller g 2005 concordance probability and discriminatory power in proportional hazards regression biometrika 92 965 970 chambless le diao g 2006 estimation of time dependent area under the roc curve for long term risk prediction stat med 25 3474 3486 fawcett tom 2006 an introduction to roc analysis pattern recognition letters 27 861 874 hanley james a mcneil barbara j 1982 the meaning and use of the area under a receiver operating characteristic roc curve radiology 143 1 29 36 pmid 160 7063747 a b mason simon j graham nicholas e 2002 areas beneath the relative operating characteristics roc and relative operating levels rol curves statistical significance and interpretation quarterly journal of the royal meteorological society 128 2145 2166 http reia inmet gov br documentos cursoi inmet iri climate information course references mason graham 2002 pdf hand david j and till robert j 2001 a simple generalization of the area under the roc curve for multiple class classification problems machine learning 45 171 186 provost f fawcett t 2001 robust classification for imprecise environments machine learning 44 203 231 repairing concavities in roc curves 19th international joint conference on artificial intelligence ijcai 05 2005 pp 160 702 707 hanley james a mcneil barbara j 1983 09 01 a method of comparing the areas under receiver operating characteristic curves derived from the same cases radiology 148 3 839 43 pmid 160 6878708 http radiology rsnajnls org cgi content abstract 148 3 839 retrieved 2008 12 03 a b hanczar blaise hua jianping sima chao weinstein john bittner michael and dougherty edward r 2010 small sample precision of roc related estimates bioinformatics 26 6 822 830 a b lobo jorge m jim nez valverde alberto and real raimundo 2008 auc a misleading measure of the performance of predictive distribution models global ecology and biogeography 17 145 151 a b hand david j 2009 measuring classifier performance a coherent alternative to the area under the roc curve machine learning 77 103 123 a b c d powers david m w 2007 2011 evaluation from precision recall and f factor to roc informedness markedness amp correlation journal of machine learning technologies 2 1 37 63 http dl dropbox com u 27743223 201101 evaluation jmlt postprint colour pdf powers david m w 2012 the problem of area under the curve international conference on information science and technology powers david m w 2012 roc concert spring conference on engineering technology perruchet p peereman r 2004 the exploitation of distributional information in syllable processing j neurolinguistics 17 97 119 powers david m w 2003 recall and precision versus the bookmaker proceedings of the international conference on cognitive science icsc 2003 sydney australia 2003 pp 529 534 http dl dropbox com u 27743223 200302 iccs bookmaker pdf powers david m w 2012 the problem with kappa conference of the european chapter of the association for computational linguistics eacl2012 joint robus unsup workshop http dl dropbox com u 27743223 201209 eacl2012 kappa pdf mcclish donna katzman 1989 08 01 analyzing a portion of the roc curve medical decision making 9 3 190 195 doi 10 1177 0272989x8900900307 pmid 160 2668680 http mdm sagepub com cgi content abstract 9 3 190 retrieved 2008 09 29 dodd lori e pepe margaret s 2003 partial auc estimation and regression biometrics 59 3 614 623 doi 10 1111 1541 0420 00071 pmid 160 14601762 http www blackwell synergy com doi abs 10 1111 1541 0420 00071 retrieved 2007 12 18 karplus kevin 2011 better than chance the importance of null models university of california santa cruz in proceedings of the first international workshop on pattern recognition in proteomics structural biology and bioinformatics pr ps bb 2011 macmillan neil a creelman c douglas 2005 detection theory a user s guide 2nd ed mahwah nj lawrence erlbaum associates isbn 160 1 4106 1114 0 glanzer murray kisok kim hilford andy adams john k 1999 slope of the receiver operating characteristic in recognition memory journal of experimental psychology learning memory and cognition 25 2 500 513 ratcliff roger mccoon gail tindall michael 1994 empirical generality of data from recognition memory roc functions and implications for gmms journal of experimental psychology learning memory and cognition 20 763 785 zhang jun mueller shane t 2005 a note on roc analysis and non parametric estimate of sensitivity psychometrika 70 203 212 yonelinas andrew p kroll neal e a dobbins ian g lazzara michele knight robert t 1998 recollection and familiarity deficits in amnesia convergence of remember know process dissociation and receiver operating characteristic data neuropsychology 12 323 339 a b green david m swets john a 1966 signal detection theory and psychophysics new york ny john wiley and sons inc isbn 160 0 471 32420 5 zweig mark h campbell gregory 1993 receiver operating characteristic roc plots a fundamental evaluation tool in clinical medicine clinical chemistry 39 8 561 577 pmid 160 8472349 http www clinchem org content 39 4 561 full pdf pepe margaret s 2003 the statistical evaluation of medical tests for classification and prediction new york ny oxford isbn 160 0 19 856582 8 obuchowski nancy a 2003 receiver operating characteristic curves and their use in radiology radiology 229 1 3 8 doi 10 1148 radiol 2291010898 pmid 160 14519861 spackman kent a 1989 signal detection theory valuable tools for evaluating inductive learning proceedings of the sixth international workshop on machine learning san mateo ca morgan kaufmann pp 160 160 163 edit general references zhou xiao hua obuchowski nancy a mcclish donna k 2002 statistical methods in diagnostic medicine new york ny wiley amp sons isbn 160 978 0 471 34772 9 edit further reading balakrishnan narayanaswamy 1991 handbook of the logistic distribution marcel dekker inc isbn 978 0 8247 8587 1 brown christopher d and davis herbert t 2006 receiver operating characteristic curves and related decision measures a tutorial chemometrics and intelligent laboratory systems 80 24 38 fawcett tom 2004 roc graphs notes and practical considerations for researchers pattern recognition letters 27 8 882 891 gonen mithat 2007 analyzing receiver operating characteristic curves using sas sas press isbn 978 1 59994 298 1 green william h 2003 econometric analysis fifth edition prentice hall isbn 0 13 066189 9 heagerty patrick j lumley thomas and pepe margaret s 2000 time dependent roc curves for censored survival data and a diagnostic marker biometrics 56 337 344 hosmer david w and lemeshow stanley 2000 applied logistic regression 2nd ed new york ny wiley isbn 0 471 35632 8 lasko thomas a bhagwat jui g zou kelly h and ohno machado lucila 2005 the use of receiver operating characteristic curves in biomedical informatics journal of biomedical informatics 38 5 404 415 stephan carsten wesseling sebastian schink tania and jung klaus 2003 comparison of eight computer programs for receiver operating characteristic analysis clinical chemistry 49 433 439 swets john a dawes robyn m and monahan john 2000 better decisions through science scientific american october pp 160 82 87 zou kelly h o malley a james mauri laura 2007 receiver operating characteristic analysis for evaluating diagnostic tests and predictive models circulation 115 5 654 7 edit external links this article s use of external links may not follow wikipedia s policies or guidelines please improve this article by removing excessive or inappropriate external links and converting useful links where appropriate into footnote references march 2010 kelly h zou s bibliography of roc literature and articles tom fawcett s roc convex hull tutorial program and papers peter flach s tutorial on roc analysis in machine learning the magnificent roc an explanation and interactive demonstration of the connection of rocs to archetypal bi normal test result plots web based calculator for roc curves by john eng convex hull cost trade off etc 