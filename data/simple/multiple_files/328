knowledge extraction is the creation of knowledge from structured relational databases xml and unstructured text documents images sources the resulting knowledge needs to be in a machine readable and machine interpretable format and must represent knowledge in a manner that facilitates inferencing although it is methodically similar to information extraction nlp and etl data warehouse the main criteria is that the extraction result goes beyond the creation of structured information or the transformation into a relational schema it requires either the reuse of existing formal knowledge reusing identifiers or ontologies or the generation of a schema based on the source data the rdb2rdf w3c group 1 is currently standardizing a language for extraction of rdf from relational databases another popular example for knowledge extraction is the transformation of wikipedia into structured data and also the mapping to existing knowledge see dbpedia freebase and 2 contents 1 overview 2 examples 2 1 entity linking 2 2 relational databases to rdf 3 extraction from structured sources to rdf 3 1 1 1 mapping from rdb tables views to rdf entities attributes values 3 2 complex mappings of relational databases to rdf 3 3 xml 3 4 survey of methods tools 4 extraction from natural language sources 4 1 traditional information extraction ie 4 2 ontology based information extraction obie 4 3 ontology learning ol 4 4 semantic annotation sa 4 5 tools 5 knowledge discovery 5 1 input data 5 2 output formats 6 ontology learning 7 see also 8 references edit overview after the standardization of knowledge representation languages such as rdf and owl much research has been conducted in the area especially regarding transforming relational databases into rdf entity resolution knowledge discovery and ontology learning the general process uses traditional methods from information extraction and etl which transform the data from the sources into structured formats the following criteria can be used to categorize approaches in this topic some of them only account for extraction from relational databases 3 source which data sources are covered text relational databases xml csv exposition how is the extracted knowledge made explicit ontology file semantic database how can you query it synchronization is the knowledge extraction process executed once to produce a dump or is the result synchronized with the source static or dynamic are changes to the result written back bi directional reuse of vocabularies the tool is able to reuse existing vocabularies in the extraction for example the table column firstname can be mapped to foaf firstname some automatic approaches are not capable of mapping vocab automatisation the degree to which the extraction is assisted automated manual gui semi automatic automatic requires a domain ontology a pre existing ontology is needed to map to it so either a mapping is created or a schema is learned from the source ontology learning edit examples edit entity linking dbpedia spotlight opencalais the zemanta api extractiv and poolparty extractor analyze free text via named entity recognition and then disambiguates candidates via name resolution and links the found entities to the dbpedia knowledge repository 4 dbpedia spotlight web demo or poolparty extractor demo president obama called wednesday on congress to extend a tax break for students included in last year s economic stimulus package arguing that the policy provides more generous assistance as president obama is linked to a dbpedia linkeddata resource further information can be retrieved automatically and a semantic reasoner can for example infer that the mentioned entity is of the type person using foaf software and of type presidents of the united states using yago counter examples methods that only recognize entities or link to wikipedia articles and other targets that do not provide further retrieval of structured data and formal knowledge edit relational databases to rdf triplify d2r server and virtuoso rdf views are tools that transform relational databases to rdf during this process they allow reusing existing vocabularies and ontologies during the conversion process when transforming a typical relational table named users one column e g name or an aggregation of columns e g first name and last name has to provide the uri of the created entity normally the primary key is used every other column can be extracted as a relation with this entity 5 then properties with formally defined semantics are used and reused to interpret the information for example a column in a user table called marriedto can be defined as symmetrical relation and a column homepage can be converted to a property from the foaf vocabulary called foaf homepage thus qualifying it as an inverse functional property then each entry of the user table can be made an instance of the class foaf person ontology population additionally domain knowledge in form of an ontology could be created from the status id either by manually created rules if status id is 2 the entry belongs to class teacher or by semi automated methods ontology learning here is an example transformation name marriedto homepage status id peter marry http example org peters page 1 claus eva http example org claus page 2 peter marriedto marry marriedto a owl symmetricproperty peter foaf homepage lt http example org peters page gt peter a foaf person peter a student claus a teacher edit extraction from structured sources to rdf edit 1 1 mapping from rdb tables views to rdf entities attributes values when building a rdb representation of a problem domain the starting point is frequently an entity relationship diagram erd typically each entity is represented as a database table each attribute of the entity becomes a column in that table and relationships between entities are indicated by foreign keys each table typically defines a particular class of entity each column one of its attributes each row in the table describes an entity instance uniquely identified by a primary key the table rows collectively describe an entity set in an equivalent rdf representation of the same entity set each column in the table is an attribute i e predicate each column value is an attribute value i e object each row key represents an entity id i e subject each row represents an entity instance each row entity instance is represented in rdf by a collection of triples with a common subject entity id so to render an equivalent view based on rdf semantics the basic mapping algorithm would be as follows create an rdfs class for each table convert all primary keys and foreign keys into iris assign a predicate iri to each column assign an rdf type predicate for each row linking it to an rdfs class iri corresponding to the table for each column that is neither part of a primary or foreign key construct a triple containing the primary key iri as the subject the column iri as the predicate and the column s value as the object early mentioning of this basic or direct mapping can be found in tim berners lee s comparison of the er model to the rdf model 5 edit complex mappings of relational databases to rdf the 1 1 mapping mentioned above exposes the legacy data as rdf in a straightforward way additional refinements can be employed to improve the usefulness of rdf output respective the given use cases normally information is lost during the transformation of an entity relationship diagram erd to relational tables details can be found in object relational impedance mismatch and has to be reverse engineered from a conceptual view approaches for extraction can come from two directions the first direction tries to extract or learn an owl schema from the given database schema early approaches used a fixed amount of manually created mapping rules to refine the 1 1 mapping 6 7 8 more elaborate methods are employing heuristics or learning algorithms to induce schematic information methods overlap with ontology learning while some approaches try to extract the information from the structure inherent in the sql schema 9 analysing e g foreign keys others analyse the content and the values in the tables to create conceptual hierarchies 10 e g a columns with few values are candidates for becoming categories the second direction tries to map the schema and its contents to a pre existing domain ontology see also ontology alignment often however a suitable domain ontology does not exist and has to be created first edit xml as xml is structured as a tree any data can be easily represented in rdf which is structured as a graph xml2rdf is one example of an approach that uses rdf blank nodes and transforms xml elements and attributes to rdf properties the topic however is more complex as in the case of relational databases in a relational table the primary key is an ideal candidate for becoming the subject of the extracted triples an xml element however can be transformed depending on the context as a subject a predicate or object of a triple xslt can be used a standard transformation language to manually convert xml to rdf edit survey of methods tools name data source data exposition data synchronisation mapping language vocabulary reuse mapping automat req domain ontology uses gui a direct mapping of relational data to rdf relational data csv2rdf4lod csv etl static rdf true manual false false convert2rdf delimited text file etl static rdf daml true manual false true d2r server rdb sparql bi directional d2r map true manual false false dartgrid rdb own query language dynamic visual tool true manual false true datamaster rdb etl static proprietary true manual true true google refine s rdf extension csv xml etl static none semi automatic false true krextor xml etl static xslt true manual true false maponto rdb etl static proprietary true manual true false metamorphoses rdb etl static proprietary xml based mapping language true manual false true mappingmaster csv etl static mappingmaster true gui false true odemapster rdb etl static proprietary true manual true true ontowiki csv importer plug in datacube amp tabular csv etl static the rdf data cube vocaublary true semi automatic false true poolparty extraktor ppx xml text linkeddata dynamic rdf skos true semi automatic true false rdbtoonto rdb etl static none false automatic the user furthermore has the chance to fine tune results false true rdf 123 csv etl static false false manual false true rdote rdb etl static sql true manual true true relational owl rdb etl static none false automatic false false t2ld csv etl static false false automatic false false the rdf data cube vocabulary multidimensional statistical data in spreadsheets data cube vocabulary true manual false topbraid composer csv etl static skos false semi automatic false true triplify rdb linkeddata dynamic sql true manual false false virtuoso rdf views rdb sparql dynamic meta schema language true semi automatic false true virtuoso sponger structured and semi structured data sources sparql dynamic virtuoso pl amp xslt true semi automatic false false visavis rdb rdql dynamic sql true manual true true xlwrap spreadsheet to rdf csv etl static trig syntax true manual false false xml to rdf xml etl static false false automatic false false edit extraction from natural language sources the biggest portion of information contained in business documents even about 80 11 is encoded in natural language and therefore unstructured because unstructured data are rather badly suited to extract knowledge from it it is necessary to apply more complex methods which nevertheless generally supply worse results than it would be possible for structured data the massive acquisition of extracted knowledge should compensate the increased complexity and decreased quality of extraction in the following natural language sources are understood as sources of information where the data are given in an unstructured fashion as plain text but the text can be additionally embedded in a markup document e g html document because the most of the systems remove the markup elements automatically edit traditional information extraction ie the traditional information extraction 12 is a technology of natural language processing which extracts information from typically natural language texts and structures these in a suitable manner the kinds of information to be identified must be specified in a model before beginning the process which is why the whole process of traditional information extraction is domain dependent the ie is split in the following five subtasks named entity recognition ner coreference resolution co template element construction te template relation construction tr template scenario production st the task of named entity recognition is to recognize and to categorize all named entities contained in a text assignment of a named entity to a predefined category this works by application of grammar based methods or statistical models the coreference resolution identifies equivalent by ner recognized entities within a text there are two relevant kinds of equivalence relationships the first one relates to the relationship between two different represented entities e g ibm europe and ibm and the second one to the relationship between an entity and their anaphoric references e g it and ibm both kinds should be recognized by the coreference resolution at the template element construction the ie system identifies descriptive properties of entities recognized by ner and co these properties correspond to ordinary qualities like red or big the template relation construction identifies relations which exist between the template elements these relations can be of several kinds such as works for or located in with the restriction that both domain and range correspond to entities in the template scenario production events which are described in the text will be identified and structured with respect to the entities recognized by ner and co and relations identified by tr edit ontology based information extraction obie the ontology based information extraction 11 is a subfield of information extraction with which at least one ontology is used to guide the process of information extraction from natural language text though the obie system uses methods of traditional information extraction to identify concepts instances and relations of the used ontologies in the text which will be structured to an ontology after the process thus the input ontologies constitute the model of information to be extracted edit ontology learning ol it has been suggested that ontology learning be merged into this article or section discuss proposed since august 2012 with ontology learning 13 whole ontologies from natural language text are semi automatically extracted therefore it can be applied to support ontology engineering it is usually split into the following eight subtasks which are not necessarily supported by all ontology learning ol systems domain terminology extraction concept discovery concept hierarchy derivation learning of non taxonomic relations rule discovery ontology population concept hierarchy extension frame and event detection at the domain terminology extraction domain specific terms are extracted which are used in the following concept discovery to derive concepts relevant terms can be determined e g by calculation of the tf idf values or by application of the c value nc value method the resulted list of terms has to be filtered by a domain expert subsequent similarly to coreference resolution in ie the ol system determines synonyms because they share the same meaning and therefore correspond to the same concept the most common methods therefor are clustering and the application of statistical similarity measures in the concept discovery terms are grouped to meaning bearing units which correspond to an abstraction of the world and therefore to concepts the grouped terms are these domain specific terms and their synonyms which were identified in the domain terminology extraction in the concept hierarchy derivation the ol system tries to arrange the extracted concepts in a taxonomic structure this is mostly achieved by unsupervised hierarchical clustering methods because the result of such methods is often noisy a supervision e g by evaluation by the user is integrated a further method for the derivation of a concept hierarchy exists in the usage of several patterns which should indicate a sub or supersumption relationship pattern like x what is a y or x is a y indicate that x is a subclass of y such pattern can be analyzed efficiently but they occur too infrequent to extract enough sub or supersumption relationships instead bootstrapping methods are developed which learn these patterns automatically and therefore ensure a higher coverage at the learning of non taxonomic relations relationships are extracted which don t express any sub or supersumption such relationships are e g works for or located in there are two common approaches to solve this subtask the first one bases upon the extraction of anonymous associations which are named appropriate in a second step the second approach extracts verbs which indicate a relationship between the entities represented by the surrounding words but the result of both approaches has to be evaluated by an ontologist in the rule discovery 14 axioms formal description of concepts are generated for the extracted concepts this can be achieved e g by analyzing the syntactic structure of a natural language definition and the application of transformation rules on the resulting dependency tree the result of this process is a list of axioms which is afterward comprehended to a concept description this one has to be evaluated by an ontologist at the ontology population the ontology is augmented with instances of concepts and properties for the augmentation with instances of concepts methods which are based on the matching of lexico syntactic patterns are used instances of properties are added by application of bootstrapping methods which collect relationtuples in the concept hierarchy extension the ol system tries to extend the taxonomic structure of an existing ontology with further concepts this can be realized supervised by an trained classifier or unsupervised by the application of similarity measures in frame event detection the ol system tries to extract complex relationships from text e g who departed from where to what place and when approaches range from applying svm with kernel methods to semantic role labelling srl 15 to deep semantic parsing techniques 16 edit semantic annotation sa at the semantic annotation 17 of natural language text this one is augmented with metadata often represented in rdfa which should make the semantics of contained terms machine understandable at this process which is generally semi automatic knowledge is extracted in the sense that a link between lexical terms and e g concepts from ontologies is established thus the knowledge is also won which meaning of a term in the processed context was intended the semi automatic semantic annotation can be split in the following two subtasks terminology extraction entity linking at the terminology extraction lexical terms from the text are extracted for this purpose a tokenizer determines at first the word boundaries and solves abbreviations afterward terms from the text which correspond to a concept are extracted with the help of a domain specific lexicon to link these at entity linking at entity linking 18 a link between the extracted lexical terms from the source text and the concepts from an ontology is established for this candidate concepts are detected appropriate to the several meanings of a term with the help of a lexicon closing the context of the terms is analyzed to determine the most appropriate disambiguation to assign the term to the correct concept edit tools the following criteria can be used to categorize tools which extract knowledge from natural language text source which input formats can be processed by the tool e g plain text html or pdf access paradigm can the tool query the data source or uses it a whole dump for the extraction process data synchronization is the result of the extraction process synchronized with the source uses output ontology does the tool link the result with an ontology mapping automation how automated is the extraction process manual semi automtic or automatic requires ontology does the tool need an ontology for the extraction uses gui does the tool offer a graphical user interface approach which approach ie obie ol or sa is used by the tool extracted entities which types of entities e g named entities concepts or relationships can be extracted by the tool applied techniques which techniques are applied e g nlp statistical methods clustering or machine learning output model which model is used to represent the result of the tool e g rdf or owl supported domains which domains are supported e g economy or biology supported languages which languages can be processed e g english or german the following table characterizes some tools for knowledge extraction from natural language sources name source access paradigm data synchronization uses output ontology mapping automation requires ontology uses gui approach extracted entities applied techniques output model supported domains supported languages aerotext 19 plain text html xml sgml dump no yes automatic yes yes ie named entities relationships events linguistic rules proprietary domain independent english spanish arabic chinese indonesian alchemyapi 20 plain text html automatic yes sa multilingual annie 21 plain text dump yes yes ie finite state algorithms multilingual asium 22 plain text dump semi automatic yes ol concepts concept hierarchy nlp clustering attensity exhaustive extraction 23 automatic ie named entities relationships events nlp dbpedia spotlight 24 plain text html dump sparql yes yes automatic no yes sa annotation to each word annotation to non stopwords nlp statistical methods machine learning rdfa domain independent english fred plain text dump no yes automatic no yes ol ie sa concepts concept hierarchy frames events relationships named entities nlp drt heuristical rules rdf owl domain independent english idocument 25 html pdf doc sparql yes yes obie instances property values nlp personal business netowl extractor 26 plain text html xml sgml pdf ms office dump no yes automatic yes yes ie named entities relationships events nlp xml rdf owl others multiple domains english arabic chinese simplified and traditional french korean persian farsi and dari russian spanish ontogen 27 semi automatic yes ol concepts concept hierarchy non taxonomic relations instances nlp machine learning clustering ontolearn 28 plain text html dump no yes automatic yes no ol concepts concept hierarchy instances nlp statistical methods proprietary domain independent english ontolearn reloaded plain text html dump no yes automatic yes no ol concepts concept hierarchy instances nlp statistical methods proprietary domain independent english ontosyphon 29 html pdf doc dump search engine queries no yes automatic yes no obie concepts relations instances nlp statistical methods rdf domain independent english ontox 30 plain text dump no yes semi automatic yes no obie instances datatype property values heuristic based methods proprietary domain independent language independent opencalais plain text html xml dump no yes automatic yes no sa annotation to entities annotation to events annotation to facts nlp machine learning rdf domain independent english french spanish poolparty extractor 31 plain text html doc odt dump no yes automatic yes yes obie named entities concepts relations concepts that categorize the text enrichments nlp machine learning statistical methods rdf owl domain independent english german spanish french scoobie plain text html dump no yes automatic no no obie instances property values rdfs types nlp machine learning rdf rdfa domain independent english german semtag 32 33 html dump no yes automatic yes no sa machine learning database record domain independent language independent smart fix plain text html pdf doc e mail dump yes no automatic no yes obie named entities nlp machine learning proprietary domain independent english german french dutch polish text2onto 34 plain text html pdf dump yes no semi automatic yes yes ol concepts concept hierarchy non taxonomic relations instances axioms nlp statistical methods machine learning rule based methods owl deomain independent english german spanish text to onto 35 plain text html pdf postscript dump semi automatic yes yes ol concepts concept hierarchy non taxonomic relations lexical entities referring to concepts lexical entities referring to relations nlp machine learning clustering statistical methods german the wiki machine 36 plain text html pdf doc dump no yes automatic yes yes sa annotation to proper nouns annotation to common nouns machine learning rdfa domain independent english german spanish french portuguese italian russian thingfinder 37 ie named entities relationships events multilingual zemanta plain text html dump yes no automatic no yes sa named entities concepts nlp statistical methods rdf domain independent english edit knowledge discovery knowledge discovery describes the process of automatically searching large volumes of data for patterns that can be considered knowledge about the data 38 it is often described as deriving knowledge from the input data knowledge discovery developed out of the data mining domain and is closely related to it both in terms of methodology and terminology 39 the most well known branch of data mining is knowledge discovery also known as knowledge discovery in databases kdd just as many other forms of knowledge discovery it creates abstractions of the input data the knowledge obtained through the process may become additional data that can be used for further usage and discovery another promising application of knowledge discovery is in the area of software modernization weakness discovery and compliance which involves understanding existing software artifacts this process is related to a concept of reverse engineering usually the knowledge obtained from existing software is presented in the form of models to which specific queries can be made when necessary an entity relationship is a frequent format of representing knowledge obtained from existing software object management group omg developed specification knowledge discovery metamodel kdm which defines an ontology for the software assets and their relationships for the purpose of performing knowledge discovery of existing code knowledge discovery from existing software systems also known as software mining is closely related to data mining since existing software artifacts contain enormous value for risk management and business value key for the evaluation and evolution of software systems instead of mining individual data sets software mining focuses on metadata such as process flows e g data flows control flows amp call maps architecture database schemas and business rules terms process edit input data databases relational data database document warehouse data warehouse software source code configuration files build scripts text concept mining graphs molecule mining sequences data stream mining learning from time varying data streams under concept drift web edit output formats data model metadata metamodels ontology knowledge representation knowledge tags business rule knowledge discovery metamodel kdm business process modeling notation bpmn intermediate representation resource description framework rdf software metrics edit ontology learning main article ontology learning this section is empty you can help by adding to it june 2011 edit see also clustering data archaeology data mining data mining in agriculture etl information extraction knowledge representation and reasoning edit references rdb2rdf working group website http www w3 org 2001 sw rdb2rdf charter http www w3 org 2009 08 rdb2rdf charter r2rml rdb to rdf mapping language http www w3 org tr r2rml k nakayama m pei m erdmann m ito m shirakawa t hara s nishio wikipedia mining wikipedia as a corpus for knowledge extraction proc of wikimania jul 2008 http wikipedia lab org en images 0 06 wikimania2008 pdf lod2 eu deliverable 3 1 1 knowledge extraction from structured sources http static lod2 eu deliverables deliverable 3 1 1 pdf life in the linked data cloud www opencalais com http www opencalais com node 9501 retrieved 2009 11 10 wikipedia has a linked data twin called dbpedia dbpedia has the same structured information as wikipedia but translated into a machine readable format a b tim berners lee 1998 relational databases on the semantic web retrieved february 20 2011 hu et al 2007 discovering simple mappings between relational database schemas and ontologies in proc of 6th international semantic web conference iswc 2007 2nd asian semantic web conference aswc 2007 lncs 4825 pages 225 238 busan korea 11 15 november 2007 http citeseerx ist psu edu viewdoc download doi 10 1 1 97 6934 amp rep rep1 amp type pdf r ghawi and n cullot 2007 database to ontology mapping generation for semantic interoperability in third international workshop on database interoperability interdb 2007 http le2i cnrs fr img publications interdb07 ghawi pdf li et al 2005 a semi automatic ontology acquisition method for the semantic web waim volume 3739 of lecture notes in computer science page 209 220 springer http dx doi org 10 1007 11563952 19 tirmizi et al 2008 translating sql applications to the semantic web lecture notes in computer science volume 5181 2008 database and expert systems applications http citeseer ist psu edu viewdoc download jsessionid 15e8ab2a37bd06dae59255a1ac3095f0 doi 10 1 1 140 3169 amp rep rep1 amp type pdf farid cerbah 2008 learning highly structured semantic repositories from relational databases the semantic web research and applications volume 5021 of lecture notes in computer science springer berlin heidelberg http www tao project eu resources publications cerbah learning highly structured semantic repositories from relational databases pdf a b wimalasuriya daya c dou dejing 2010 ontology based information extraction an introduction and a survey of current approaches journal of information science 36 3 p 306 323 http ix cs uoregon edu dou research papers jis09 pdf retrieved 18 06 2012 cunningham hamish 2005 information extraction automatic encyclopedia of language and linguistics 2 p 665 677 http gate ac uk sale ell2 ie main pdf retrieved 18 06 2012 cimiano philipp v lker johanna studer rudi 2006 ontologies on demand a description of the state of the art applications challenges and trends for ontology learning from text information wissenschaft und praxis 57 p 315 320 http people aifb kit edu pci publications iwp06 pdf retrieved 18 06 2012 v lker johanna hitzler pascal cimiano philipp 2007 acquisition of owl dl axioms from lexical resources proceedings of the 4th european conference on the semantic web p 670 685 http smartweb dfki de vortraege lexo 2007 pdf retrieved 18 06 2012 coppola b gangemi a gliozzo a picca d presutti v 2009 frame detection over the semantic web proceedings of the european semantic web conference eswc2009 springer 2009 presutti v draicchio f gangemi a 2009 knowledge extraction based on discourse representation theory and linguistic frames proceedings of the conference on knowledge engineering and knowledge management ekaw2012 lncs springer 2012 erdmann m maedche alexander schnurr h p staab steffen 2000 from manual to semi automatic semantic annotation about ontology based text annotation tools proceedings of the coling http www ida liu se ext epa cis 2001 002 paper pdf retrieved 18 06 2012 rao delip mcnamee paul dredze mark 2011 entity linking finding extracted entities in a knowledge base multi source multi lingual information extraction and summarization http www cs jhu edu delip entity linking pdf retrieved 18 06 2012 rocket software inc 2012 technology for extracting intelligence from text http www rocketsoftware com products aerotext retrieved 18 06 2012 orchestr8 2012 alchemyapi overview http www alchemyapi com api retrieved 18 06 2012 the university of sheffield 2011 annie a nearly new information extraction system http gate ac uk sale tao splitch6 html chap annie retrieved 18 06 2012 ilp network of excellence asium lri http www ai ijs si ilpnet2 systems asium html retrieved 18 06 2012 attensity 2012 exhaustive extraction http www attensity com products technology semantic server exhaustive extraction retrieved 18 06 2012 mendes pablo n jakob max garcia s lva andr s bizer christian 2011 dbpedia spotlight shedding light on the web of documents proceedings of the 7th international conference on semantic systems p 1 8 http www wiwiss fu berlin de en institute pwo bizer research publications mendes jakob garciasilva bizer dbpediaspotlight isem2011 pdf retrieved 18 06 2012 adrian benjamin maus heiko dengel andreas 2009 idocument using ontologies for extracting information from text http www dfki uni kl de maus dok adrianmausdengel09 pdf retrieved 18 06 2012 sra international inc 2012 netowl extractor http www sra com netowl entity extraction retrieved 18 06 2012 fortuna blaz grobelnik marko mladenic dunja 2007 ontogen semi automatic ontology editor proceedings of the 2007 conference on human interface part 2 p 309 318 http analytics ijs si blazf papers ontogen2 hcii2007 pdf retrieved 18 06 2012 missikoff michele navigli roberto velardi paola 2002 integrated approach to web ontology learning and engineering computer 35 11 p 60 63 http wwwusers di uniroma1 it velardi ieee c pdf retrieved 18 06 2012 mcdowell luke k cafarella michael 2006 ontology driven information extraction with ontosyphon proceedings of the 5th international conference on the semantic web p 428 444 http turing cs washington edu papers iswc2006mcdowell final pdf retrieved 18 06 2012 yildiz burcu miksch silvia 2007 ontox a method for ontology driven information extraction proceedings of the 2007 international conference on computational science and its applications 3 p 660 673 http publik tuwien ac at files pub inf 4769 pdf retrieved 18 06 2012 semanticweb org 2011 poolparty extractor http semanticweb org wiki poolparty extractor retrieved 18 06 2012 dill stephen eiron nadav gibson david gruhl daniel guha r jhingran anant kanungo tapas rajagopalan sridhar tomkins andrew tomlin john a zien jason y 2003 semtag and seeker bootstraping the semantic web via automated semantic annotation proceedings of the 12th international conference on world wide web p 178 186 http www2003 org cdrom papers refereed p831 p831 dill html retrieved 18 06 2012 uren victoria cimiano philipp iria jos handschuh siegfried vargas vera maria motta enrico ciravegna fabio 2006 semantic annotation for knowledge management requirements and a survey of the state of the art web semantics science services and agents on the world wide web 4 1 p 14 28 http staffwww dcs shef ac uk people j iria iria jws06 pdf retrieved 18 06 2012 cimiano philipp v lker johanna 2005 text2onto a framework for ontology learning and data driven change discovery proceedings of the 10th international conference of applications of natural language to information systems 3513 p 227 238 http www cimiano de publications 2005 nldb05 nldb05 pdf retrieved 18 06 2012 maedche alexander volz raphael 2001 the ontology extraction amp maintenance framework text to onto proceedings of the ieee international conference on data mining http users csc calpoly edu fkurfess events dm km 01 volz pdf retrieved 18 06 2012 machine linking we connect to the linked open data cloud http thewikimachine fbk eu html index html retrieved 18 06 2012 inxight federal systems 2008 inxight thingfinder and thingfinder professional http inxightfedsys com products sdks tf retrieved 18 06 2012 frawley william f et al 1992 knowledge discovery in databases an overview ai magazine vol 13 no 3 57 70 online full version http www aaai org ojs index php aimagazine article viewarticle 1011 fayyad u et al 1996 from data mining to knowledge discovery in databases ai magazine vol 17 no 3 37 54 online full version http www aaai org ojs index php aimagazine article viewarticle 1230 v t e semantic web background databases hypertext internet ontologies semantic networks world wide web sub topics data web dataspaces dereferenceable uris hyperdata linked data rule based systems applications semantic advertising semantic analytics semantic broker semantic computing semantic mapper semantic matching semantic publishing semantic reasoner semantic search semantic service oriented architecture semantic wiki related topics collective intelligence description logic folksonomy geotagging information architecture knowledge extraction knowledge management library 2 0 metadata mind mapping odbc references topic maps web 2 0 web science trust standards syntax and supporting technologies http rdf rdf xml notation3 turtle n triples sparql uri xml schemas ontologies and rules common logic owl rdfs rule interchange format semantic web rule language semantic annotation erdf grddl microformats rdfa sawsdl common vocabularies dublin core foaf sioc skos umbel v t e computable knowledge topics and concepts alphabet of human thought automated reasoning commonsense knowledge base commonsense reasoning computability formal system inference engine knowledge base knowledge based systems knowledge discovery knowledge engineering knowledge representation knowledge retrieval knowledge extraction logic programming ontology question answering semantic reasoner proposals and implementations zairja ars magna ramon llull 1300 an essay towards a real character and a philosophical language john wilkins 1688 calculus ratiocinator amp characteristica universalis gottfried leibniz 1700 dewey decimal classification melvil dewey 1876 begriffsschrift gottlob frege 1879 mundaneum paul otlet amp henri la fontaine 1910 logical atomism bertrand russell 1918 tractatus logico philosophicus ludwig wittgenstein 1921 hilbert s program david hilbert 1920s incompleteness theorem kurt g del 1931 memex vannevar bush 1945 prolog 1972 cyc 1984 true knowledge true knowledge ltd 2007 wolfram alpha wolfram research 2009 watson ibm 2011 siri apple 2011 knowledge graph google 2012 in fiction the engine gulliver s travels 1726 joe a logic named joe 1946 the librarian snow crash 1992 dr know a i artificial intelligence 2001 waterhouse the baroque cycle 2003 see also logic machines in fiction and list of fictional computers 