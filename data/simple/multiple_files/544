a spearman correlation of 1 results when the two variables being compared are monotonically related even if their relationship is not linear in contrast this does not give a perfect pearson correlation when the data are roughly elliptically distributed and there are no prominent outliers the spearman correlation and pearson correlation give similar values the spearman correlation is less sensitive than the pearson correlation to strong outliers that are in the tails of both samples in statistics spearman s rank correlation coefficient or spearman s rho named after charles spearman and often denoted by the greek letter rho or as is a nonparametric measure of statistical dependence between two variables it assesses how well the relationship between two variables can be described using a monotonic function if there are no repeated data values a perfect spearman correlation of 1 or 1 occurs when each of the variables is a perfect monotone function of the other spearman s coefficient like any correlation calculation is appropriate for both continuous and discrete variables including ordinal variables 1 2 contents 1 definition and calculation 2 related quantities 3 interpretation 4 example 5 determining significance 6 correspondence analysis based on spearman s rho 7 see also 8 references 8 1 further reading 9 external links edit definition and calculation the spearman correlation coefficient is defined as the pearson correlation coefficient between the ranked variables 3 for a sample of size n the n raw scores are converted to ranks and is computed from these identical values rank ties or value duplicates are assigned a rank equal to the average of their positions in the ascending order of the values in the table below notice how the rank of values that are the same is the mean of what their ranks would otherwise be variable position in the ascending order rank 0 8 1 1 1 2 2 1 2 3 2 3 4 4 18 5 5 in applications where duplicate values ties are known to be absent a simpler procedure can be used to calculate 3 4 differences between the ranks of each observation on the two variables are calculated and is given by edit related quantities main article correlation and dependence there are several other numerical measures that quantify the extent of statistical dependence between pairs of observations the most common of these is the pearson product moment correlation coefficient which is a similar correlation method to spearman s rank that measures the linear relationships between the raw numbers rather than between their ranks an alternative name for the spearman rank correlation is the grade correlation 5 in this the rank of an observation is replaced by the grade in continuous distributions the grade of an observation is by convention always one half less than the rank and hence the grade and rank correlations are the same in this case more generally the grade of an observation is proportional to an estimate of the fraction of a population less than a given value with the half observation adjustment at observed values thus this corresponds to one possible treatment of tied ranks while unusual the term grade correlation is still in use 6 edit interpretation a positive spearman correlation coefficient corresponds to an increasing monotonic trend between x and y a negative spearman correlation coefficient corresponds to a decreasing monotonic trend between x and y the sign of the spearman correlation indicates the direction of association between x the independent variable and y the dependent variable if y tends to increase when x increases the spearman correlation coefficient is positive if y tends to decrease when x increases the spearman correlation coefficient is negative a spearman correlation of zero indicates that there is no tendency for y to either increase or decrease when x increases the spearman correlation increases in magnitude as x and y become closer to being perfect monotone functions of each other when x and y are perfectly monotonically related the spearman correlation coefficient becomes 1 a perfect monotone increasing relationship implies that for any two pairs of data values x i 160 y i and x j 160 y j that x i 160 160 x j and y i 160 160 y j always have the same sign a perfect monotone decreasing relationship implies that these differences always have opposite signs the spearman correlation coefficient is often described as being nonparametric this can have two meanings first the fact that a perfect spearman correlation results when x and y are related by any monotonic function can be contrasted with the pearson correlation which only gives a perfect value when x and y are related by a linear function the other sense in which the spearman correlation is nonparametric in that its exact sampling distribution can be obtained without requiring knowledge i e knowing the parameters of the joint probability distribution of x and y edit example in this example we will use the raw data in the table below to calculate the correlation between the iq of a person with the number of hours spent in front of tv per week iq hours of tv per week 106 7 86 0 100 27 101 50 99 28 103 29 97 20 113 12 112 6 110 17 first we must find the value of the term to do so we use the following steps reflected in the table below sort the data by the first column create a new column and assign it the ranked values 1 2 3 n next sort the data by the second column create a fourth column and similarly assign it the ranked values 1 2 3 n create a fifth column to hold the differences between the two rank columns and create one final column to hold the value of column squared iq hours of tv per week rank rank 86 0 1 1 0 0 97 20 2 6 4 16 99 28 3 8 5 25 100 27 4 7 3 9 101 50 5 10 5 25 103 29 6 9 3 9 106 7 7 3 4 16 110 17 8 5 3 9 112 6 9 2 7 49 113 12 10 4 6 36 with found we can add them to find the value of n is 10 so these values can now be substituted back into the equation which evaluates to 160 160 29 165 160 160 0 175757575 with a p value 0 6864058 using the t distribution this low value shows that the correlation between iq and hours spent watching tv is very low in the case of ties in the original values this formula should not be used instead the pearson correlation coefficient should be calculated on the ranks where ties are given ranks as described above edit determining significance one approach to testing whether an observed value of is significantly different from zero r will always maintain 1 r 1 is to calculate the probability that it would be greater than or equal to the observed r given the null hypothesis by using a permutation test an advantage of this approach is that it automatically takes into account the number of tied data values there are in the sample and the way they are treated in computing the rank correlation another approach parallels the use of the fisher transformation in the case of the pearson product moment correlation coefficient that is confidence intervals and hypothesis tests relating to the population value can be carried out using the fisher transformation if f r is the fisher transformation of r the sample spearman rank correlation coefficient and n is the sample size then is a z score for r which approximately follows a standard normal distribution under the null hypothesis of statistical independence 160 160 0 7 8 one can also test for significance using which is distributed approximately as student s t distribution with n 160 160 2 degrees of freedom under the null hypothesis 9 a justification for this result relies on a permutation argument 10 a generalization of the spearman coefficient is useful in the situation where there are three or more conditions a number of subjects are all observed in each of them and it is predicted that the observations will have a particular order for example a number of subjects might each be given three trials at the same task and it is predicted that performance will improve from trial to trial a test of the significance of the trend between conditions in this situation was developed by e b page 11 and is usually referred to as page s trend test for ordered alternatives edit correspondence analysis based on spearman s rho classic correspondence analysis is a statistical method that gives a score to every value of two nominal variables in this way the pearson correlation coefficient between them is maximized there exists an equivalent of this method called grade correspondence analysis which maximizes spearman s rho or kendall s tau 12 edit see also statistics portal kendall tau rank correlation coefficient chebyshev s sum inequality rearrangement inequality these two articles may shed light on the mathematical properties of spearman s edit references http en wikipedia org wiki level of measurement the theory of scale types jmp for basic univariate and multivariate statistics a step by step guide ann lehman p 123 a b myers jerome l well arnold d 2003 research design and statistical analysis 2nd ed lawrence erlbaum pp 160 508 isbn 160 0 8058 4037 0 maritz j s 1981 distribution free statistical methods chapman amp hall isbn 0 412 15940 6 page 217 yule g u and kendall m g 1950 an introduction to the theory of statistics 14th edition 5th impression 1968 charles griffin amp co page 268 piantadosi j howlett p boland j 2007 matching the grade correlation coefficient using a copula with maximum disorder journal of industrial and management optimization 3 2 305 312 choi s c 1977 test of equality of dependent correlations biometrika 64 3 pp 160 645 647 fieller e c hartley h o pearson e s 1957 tests for rank correlation coefficients i biometrika 44 pp 160 470 481 press vettering teukolsky and flannery 1992 numerical recipes in c the art of scientific computing 2nd edition page 640 kendall m g stuart a 1973 the advanced theory of statistics volume 2 inference and relationship griffin isbn 0 85264 215 6 sections 31 19 31 21 page e b 1963 ordered hypotheses for multiple treatments a significance test for linear ranks journal of the american statistical association 58 301 216 230 doi 10 2307 2282965 kowalczyk t pleszczy ska e ruland f eds 2004 grade models and methods for data analysis with applications for the analysis of data populations studies in fuzziness and soft computing vol 151 berlin heidelberg new york springer verlag isbn 160 978 3 540 21120 4 edit further reading corder gw foreman di 2009 nonparametric statistics for non statisticians a step by step approach hoboken n j wiley isbn 160 978 0 470 4546 19 oclc 160 276228975 spearman c 1904 the proof and measurement of association between two things amer j psychol 15 72 101 kendall mg 1970 rank correlation methods 4th ed london griffin isbn 160 978 0 852 6419 96 oclc 160 136868 hollander m wolfe da 1973 nonparametric statistical methods new york wiley isbn 160 978 0 471 40635 8 oclc 160 520735 caruso jc cliff n 1997 empirical size coverage and power of confidence intervals for spearman s rho ed and psy meas 57 637 654 edit external links wikiversity has learning materials about spearman s rank correlation coefficient understanding correlation vs copulas in excel by eric torkia technology partnerz 2011 table of critical values of for significance with small samples a calculator that shows the working out for spearman s correlation spearman s rank online calculator chapter 3 part 1 shows the formula to be used when there are ties spearman s rank correlation simple notes for students with an example of usage by biologists and a spreadsheet for microsoft excel for calculating it a part of materials for a research methods in biology course v t e statistics 160 descriptive statistics continuous data location mean arithmetic geometric harmonic median mode dispersion range standard deviation coefficient of variation percentile interquartile range shape variance skewness kurtosis moments l moments count data index of dispersion summary tables grouped data frequency distribution contingency table dependence pearson product moment correlation rank correlation spearman s rho kendall s tau partial correlation scatter plot statistical graphics bar chart biplot box plot control chart correlogram forest plot histogram q q plot run chart scatter plot stemplot radar chart 160 data collection designing studies effect size standard error statistical power sample size determination survey methodology sampling stratified sampling opinion poll questionnaire controlled experiment design of experiments randomized experiment random assignment replication blocking factorial experiment optimal design uncontrolled studies natural experiment quasi experiment observational study 160 statistical inference statistical theory sampling distribution sufficient statistic meta analysis bayesian inference bayesian probability prior posterior credible interval bayes factor bayesian estimator maximum posterior estimator frequentist inference confidence interval hypothesis testing likelihood ratio specific tests z test normal student s t test f test chi squared test wald test mann whitney u shapiro wilk signed rank kolmogorov smirnov test general estimation bias robustness efficiency maximum likelihood method of moments minimum distance density estimation 160 correlation and regression analysis correlation pearson product moment correlation partial correlation confounding variable coefficient of determination regression analysis errors and residuals regression model validation mixed effects models simultaneous equations models linear regression simple linear regression ordinary least squares general linear model bayesian regression non standard predictors nonlinear regression nonparametric semiparametric isotonic robust generalized linear model exponential families logistic bernoulli binomial poisson partition of variance analysis of variance anova analysis of covariance multivariate anova degrees of freedom 160 categorical multivariate time series or survival analysis categorical data cohen s kappa contingency table graphical model log linear model mcnemar s test multivariate statistics multivariate regression principal components factor analysis cluster analysis classification copulas time series analysis general decomposition trend stationarity seasonal adjustment time domain acf pacf xcf arma model arima model vector autoregression frequency domain spectral density estimation survival analysis survival function kaplan meier logrank test failure rate proportional hazards models accelerated failure time model 160 applications biostatistics bioinformatics biometrics clinical trials amp studies epidemiology medical statistics engineering statistics chemometrics methods engineering probabilistic design process amp quality control reliability system identification social statistics actuarial science census crime statistics demography econometrics national accounts official statistics population psychometrics spatial statistics cartography environmental statistics geographic information system geostatistics kriging category portal outline index 